[
  {
    "paper_id": "meme_interpret",
    "chunk_id": 0,
    "text": "MemeInterpret: Towards an All-in-One Dataset for Meme Understanding\nJeongsikPark1*,KhoiP.N.Nguyen2*,JihyungPark3,MinseokKim2,JaeheonLee2,\nJaeWonChoi1,KalyaniGanta4,PhalgunAshritKasu2,RohanSarakinti3,\nSanjanaVipperla2,SaiSathanapalli2,NishanVaghani2,andVincentNg2\n1UniversityofSouthernCalifornia 2UniversityofTexasatDallas\n3UniversityofTexasatAustin 4VirginiaTech\njeongsik@usc.edu khoi.nguyen6@utdallas.edu vince@hlt.utdallas.edu\nAbstract\nMemecaptioning,thetaskofgeneratingasen-\ntencethatdescribesthemeaningofameme,is\nboth challenging and important in advancing\nComputationalMemeUnderstanding(CMU).\nHowever, existing research has not explored\nitsdecompositionintosubtasksoritsconnec- (a) (b)\ntions to other CMU tasks. To address this\nFigure1: ExamplememesfromKielaetal.(2020)(a)\ngap, we introduce MemeInterpret, a meme\nandSharmaetal.(2020)(b).\ncorpuscontainingmemecaptionstogetherwith\ncorrespondingsurfacemessagesandrelevant\nadopted the same methodology for tackling each\nbackground knowledge. Strategically built\nnewly-proposed task: (1) annotate a corpus of\nupon the Facebook Hateful Memes dataset,\nMemeInterpretisthelastpieceinasetofcor- memeswithtask-specificlabelsand(2)fine-tune\nporathatunifiesthreemajorcategoriesofCMU aVision-LanguageModel(VLM)ontheresulting\ntasksforthefirsttime. Extensiveexperiments corpus. While there is nothing inherently wrong\nonMemeInterpretandconnecteddatasetssug-\nwiththismethodology,itisnotnecessarilyhealthy\ngest strong relationships between meme cap-",
    "char_length": 1487
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 1,
    "text": "forthelong-termdevelopmentofCMUresearch:\ntioning, its two proposed subtasks, and the\nasafield,existingCMUtasksarebeingtackledas\nothertwokeycategoriesofCMUtasks:classifi-\niftheyhavenothingtodowitheachother.\ncationandexplanation. Tostimulatefurtherre-\nsearchonCMU,wemakeourdatasetpublicly In light of this concern, we believe we should\navailable at https://github.com/npnkhoi/ startthinkingaboutdevelopingtask-agnosticrather\nMemeInterpret.1 thantask-specificrepresentationsofmemes. The\nquestion, then, is: what task-agnostic representa-\n1 Introduction\ntioncanbesharedbyandthereforebenefitarange\nMemes, which are user-created combinations of ofCMUtasks? Asmanymeme-basedNLPtasks\nimagesoverlaidwithtext,havebecomeaprevalent requireanunderstandingofthemeaningofameme\nmeansofonlinecommunication(Joshietal.,2024). (i.e.,whatthememeauthortriestoconvey)rather\nTheyarecreatedwithavarietyofpurposes: while than its form (i.e., how the meaning is conveyed\nsomememesaresimplyusedtoexpresspersonal throughthevisualsandtext),agoodstartingpoint\nopinions, othermemescanbemalicious, such as wouldbetoexperimentwithusingthemeaningof\ninciting hatred or spreading manipulative propa-\namemeasitstask-agnosticrepresentation.2\nganda. Assuch,recentyearshaveseenincreasing For this reason, we believe that it is important\ninterestwithinNLPintheemergingareaofCompu- to examine an under-studied but important cate-\ntationalMemeUnderstanding(CMU),atermthat gory of CMU tasks, meme interpretation, which",
    "char_length": 1474
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 2,
    "text": "we coined to refer to research on the automated is referred to as meme captioning by Hwang and\ncomprehensionofmemes(NguyenandNg,2024).\n2We are by no means claiming that this representation\nWhilenumerousCMUtaskshavebeenproposed\nwouldbeusefulforallCMUtasks. Forinstance,ifthegoal\ninthepastfewyears,researchershaveessentially istoidentifythepersuasionstrategiesusedinameme,then\ntheformofthememewouldmatter. Notealsothatthisis\n*Theseauthorscontributedequallytothiswork. anunstructuredrepresentation,asweexpressmeaninginthe\n1Forillustrationpurposes,weshowinthispapermemes form of natural language. We leave the development of a\nfromMemeInterpret,someofwhichcouldbeoffensive. structuredmeaningrepresentationtofuturework.\n16073\nFindingsoftheAssociationforComputationalLinguistics:EMNLP2025,pages16073–16087\nNovember4-9,2025©2025AssociationforComputationalLinguistics\nShwartz(2023)andintentdescriptiongeneration Caucasianmansittinginfrontofawindowwitha\nby Park et al. (2024). Both tasks concern gener- stunnedface,wearingahatthatsays‘VIETNAM\natingadescriptionthatcapturesthemeaningofa VETERAN’.Theauthordescribestheimageas‘me:\nmeme. Given the meme in Figure 1a, the meme putsbagofpopcornintothemicrowave. everyone\ncaption would be \"this meme maliciously makes else at the senior center’.\" This SM captures the\nfunofthetraumaoftheVietnamWarveterans\". informationontheimagethatenablesthecorrectin-\nMemecaptioningcouldbenefitarangeofCMU terpretationofthememe(e.g.,thetext\"VIETNAM",
    "char_length": 1469
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 3,
    "text": "tasks. For example, given the aforementioned VETERAN\"couldhavebeeneasilyignoredbya\nmemecaption,aHatefulMemeDetection(HMD) typical image captioner). Furthermore, it merges\nsystemcaneasilydeterminethatthismemeishate- the information from the text and the image in a\nful. Weemphasize,however,thatthesignificance coherentmannerbyresolving\"me\"totheauthor.3\nofmemecaptionsliesinthefactthatmemesthat To advance research in meme captioning, we\nhavedifferentformsbutconveythesamemeaning proposeMemeInterpret,amemecorpusinwhich\narebeingmappedtothesamememecaption. This each meme is manually annotated with its meme\nhelpsreducedatasparsityandremoveinformation captionand,giventheaforementionedchallenges\nirrelevanttothemeaning. Therefore,whentraining associatedwithmemecaptioning,itssurfacemes-\ntask-specificmodelsfordownstreamCMUtasks, sage and the relevant background knowledge. In\namodelthattakesmemecaptions(ratherthanthe previous work, each meme in MemeInterpret is\noriginal memes) as input can potentially be fine- already labeled with whether they are hateful or\ntunedonasmalleramountoftask-specificdatato not(acategorizationtask),andasubsetofthehate-\nachieveagivenlevelofperformance. ful memes is additionally labeled with an expla-\nMeme captioning, however, is challenging for nation of why it is hateful (an explanation task).\natleastthreereasons. First, formanymemes, es- Therefore, MemeInterpret is the first meme cor-",
    "char_length": 1420
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 4,
    "text": "peciallythosethataremalicious(e.g.,theauthor’s pus that bridges together three major categories\nintentistomanipulatepublicopinion),themean- of CMU tasks, namely categorization, explana-\ning of the meme is typically not explicitly stated tion, and interpretation (see Section 2). Our em-\nandthereforecanonlybeinferred. pirical studies showed that surface message and\nSecond,memecaptioningreliesonbackground background knowledge annotations significantly\nknowledge(BK),whichbydefinitionisnotexplic- improved the performance on meme captioning.\nitlystatedinthememeeither. TakeFigure1aasan Moreover,strongermemecaptioningsystemscan\nexample. Toproperlyunderstandtheterms\"pop- advance the performance in meme classification\ncorn\", \"senior\", and \"Vietnam veteran\" and their andexplanation. Giventheseresults,weenvision\nrelationships in the meme, one needs to possess that MemeInterpret can spark a new avenue of\nthe BK that (1) \"the Vietnam war was a highly researchinCMUthatinvolvesstudyinghowdiffer-\ntraumaticperiodforUSsoldierswhoarenowold ent categories of tasks interact with and possibly\nveterans mostly living in senior centers\", and (2) benefitfromeachother.\n\"thesoundofpopcornpoppinginthemicrowave\n2 RelatedWork\ncan remind them of the gunfire sound during the\nwar\", but (3) \"generally, that sound is not to be Inthissection,wereviewthreecategoriesoftasks\nscared of because there is no apparent danger\".\nin CMU. For a more comprehensive overview of",
    "char_length": 1450
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 5,
    "text": "Whilelargelanguagemodels(LLMs)possesslots CMUresearch,seeNguyenandNg(2024).\nofknowledge,whatischallengingisthegeneration\nInterpretation Interpretation,whichiswhatwe\noftheBKrelevanttoagivenmeme.\nfocus on, involves generating a description that\nThird,evenifamodelcanidentifyrelevantBK,\n3A surface message is different from an image caption.\nasuccessfulmemecaptionerneedstoaddressan-\nTheimagecaptionforthememeinFigure1acouldbe\"It\nother challenging task that we refer to as surface isanimageofamanwithalongbeardsittinginfrontofa\nmessage (SM) generation, which involves gener- window. Heiswearingadark-colorhatwithajacket. The\nscene outside the window is blurry.\" This description fails\nating a sentence to (1) capture the details of the\ntoidentifycrucialinformationontheimagethatenablesthe\nmemethatarecrucialforitsinterpretationby(2) correctunderstandingofthememe,suchasthetextsaying\ncombiningthememe’simageandtextinacoher- \"VIETNAMVETERAN\",whichsuggeststhatthemanwasa\nveteranoftheVietnamWar,aswellastheemotionalexpres-\nent manner. Returning to Figure 1a, a good SM\nsionofthemanviahisfaceandhands,whichsuggestsfear\nfor this meme is \"It is an image of a 70-year-old andtrauma.Also,thecaptionignoresthetextinthememe.\n16074\nDataset Size AnnotationType AnnotationQuality Topics\nHatRed 3228 Hatefulnessexplanation Two-stage Collect-And- HatefulmemesfromtheFace-\nJudgeprocedure bookHatefulMemesdataset.\nExHVV 4680 Roleofentitiesexplanation Two-stage Collect-And- COVID-19 and US Politics.",
    "char_length": 1479
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 6,
    "text": "Judgeprocedure Allmemesareharmful.\nMemeCap 6387 Memecaption No explicit quality control, Only non-offensive memes\nreliedonpriorperformance fromReddit.\nofMTurkers\nMemeIntent 950 Intentdescription Two-stageCollect-and-Edit Politics, healthcare, and gen-\nprocedure derequalityonFacebook\nMemeInterpret 6810 Surface message, background Three-stage Collect-Edit- Both hateful and non-hateful\nknowledge,memecaption Judgeprocedure memesfromFacebookHateful\nMemesdataset\nTable1: ComparisonbetweenMemeInterpretandotherfree-textannotationdatasetsonmemes.\ncaptures the meaning of a meme. Research on boththehatefulandnon-hatefulmemesoccurring\nmemeinterpretationisinitsinfancy: sofarithas in the wild, covering a wider variety of memes\nonlybeenstudiedbyHwangandShwartz(2023) than existing corpora. As such, MemeInterpret\nand Park et al. (2024). As noted above, Hwang contributes to the set of much-needed corpora re-\nand Shwartz proposed the meme captioning task gardingfree-textannotationsforCMUresearch.\nandcreatedMemeCap,adatasetwhereeachmeme\nCaregorization Categorization tasks involve\nis annotated with its meme caption. Park et al.\nclassifying memes along various dimensions.\nproposed the intent description generation task,\nThesetaskscanbebroadlydividedintotwocate-\nwhichisessentiallythememecaptioningtask,and\ngories. The first group is composed of tasks that\ncreated MemeIntent. Nevertheless, these authors\ninvolve detecting malignity in memes, including\nfailed to realize the potential of meme captions",
    "char_length": 1498
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 7,
    "text": "offensiveness (Suryawanshi et al., 2020a), trolls\nas a task-agnostic representation that can benefit\n(Suryawanshi et al., 2020b), hate (Kiela et al.,\na range of CMU tasks. While MemeIntent, like\n2020),antisemistism(Chandraetal.,2021),harm\nMemeInterpret,iscomposedofbothhatefuland\n(Pramanicketal.,2021a,b),andmisogyny(Fersini\nnon-hateful memes, MemeCap excludes hateful\netal.,2022). Thesecondgroupcontainstasksthat\nmemes,whichisakeyweaknessgiventheimpor-\ncategorizememesalongotherdimensionssuchas\ntantroleplayedbyhatefulmemesinCMU(Kiela\ntypes of persuasion techniques (Dimitrov et al.,\net al., 2020), and does not annotate surface mes-\n2021),typesoffigurativelanguage(e.g.,irony,al-\nsagesandbackgroundknowledge.\nlusion, irony, sarcasm, and contrast) (Liu et al.,\nExplanation Explanationtasksinvolvegenerat- 2022), entities’ roles (e.g., hero, villain, or vic-\ningadescriptionofwhyamemeshouldbeassigned tim)(Sharmaetal.,2022),emotions(e.g.,humor)\na particular label (e.g., sarcastic). For instance, (Sharma et al., 2020), and attacked target groups\nif our task involves explaining why the meme in (e.g.,religion,race,sex,nationality,anddisability)\nFigure 1b is sarcastic, the explanation would be (Mathiasetal.,2021).\n\"languages used for people who fear long words\naresupposedtobeshort,butthemedicalnamefor 3 TheMemeInterpretDataset\nthefearisactuallylong.\"Sofar,onlytwomeme\n3.1 MemeSource\ncorporahavebeenproducedforexplanationtasks,",
    "char_length": 1431
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 8,
    "text": "namely, HatRed (Hee et al., 2023) and ExHVV To assemble MemeInterpret, we sample the\n(Sharmaetal.,2023). memesfromtheFacebookHatefulMemedataset\nTable 1 compares MemeInterpret with the (FHM) (Kiela et al., 2020). Specifically, when\nabovecorpora,whicharetheonlymemecorpora assemblingMemeInterpret,weinherittheentire\nwithfree-textannotations,alongfourdimensions. training set and the test \"seen\" set from FHM,\nAscanbeseen,MemeInterpret(1)isthelargest which has 8500 and 1000 memes, respectively.\nmemecorpuscontainingfree-textannotations;(2) 42%ofthememesinMemeInterpretarehateful.\nsupportsmultipleannotationtypesratherthanjust WechoseFHMfortworeasons. First,andper-\nonetypeofannotations;(3)employsastricteranno- haps most importantly, each meme in FHM was\ntationprotocol,namelyathree-stageCollect-Edit- alreadylabeledashateful(Kielaetal.,2020)anda\nJudgeprocedure(seeSection3.2);and(4)contains subsetofthehatefulmemeswereannotatedwith\n16075\nexplanationsofwhythememeswerehateful(Hee Stage2: Edit Toincreaselinguisticdiversityand\netal.,2023). Therefore,ouradditionalannotations reduce annotator bias, we implemented an \"edit\"\nonthememessampledfromFHMwillenableus stage. Given the annotation results from Stage 1,\ntostudyhowthethreecategoriesofCMUtasks— five new annotators conducted edits on the three\nnamelyinterpretation(memecaptioning),explana- fieldsandindicatedwhethertheyagreedwiththe\ntion(hatefulnessexplanation),andcategorization Stage1annotations. Theseeditorscouldselectone",
    "char_length": 1478
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 9,
    "text": "(hatefulmemedetection)—interactwithandpos- offouroptionsduringtheireditingprocess: Agree\nsiblybenefitfromeachother. Second,thememes (theeditorsemanticallyagreeswiththeannotation;\ncoveravarietyoftopicsencounteredineveryday onlyeditsfortoneorgrammarerrorsareneeded),\nlife,includingpolitics,raceandethnicity,sexand Disagree(theeditorsemanticallydisagreeswiththe\nrelationships,foodandeatinghabits,animalsand annotation;editsarenecessary),Add (theannota-\npets, historical events, social issues, religion and tionisinsufficient;mustaddmoreinformation),or\nbeliefs,lifestyleanddailylife,stereotypesandprej- Cut(theannotationistooverbose;mustshorten).\nudices,aswellashobbiesandinterests. Editorswereallowedtoskipmemestheydidnot\nunderstand. Additionally,iftheStage-1annotator\n3.2 AnnotationProcedure indicatedalackofconfidenceandtheeditoralso\nchosetoskip,thememewouldbediscardeddueto\nRecallthatinadditiontothememecaption(MC),\nalackofclearmeaningandintent.\nwe annotate each meme in MemeInterpret with\nStage3: Judge Foureditorsthemselvesserved\ntwokindsofsupportingannotations,surfacemes-\nas judges, with each instance assigned to two\nsage(SM)andbackgroundknowledge(BK)(Fig-\njudges. Toavoidbias,nooneevaluatedtheirown\nure 2). Below we describe our annotation proce-\nannotation. Arandom10%-subsetofthetraining\ndure.\nsetand100%ofthetestsetwerejudged.\nAccordingtoWiegreffeandMarasovic(2021),\nConsistentwithrelatedworkinfree-textanno-\nthe currently most advanced procedures for the",
    "char_length": 1465
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 10,
    "text": "tation on memes (Hee et al., 2023; Sharma et al.,\nform of our annotations — the free-text form —\n2023;Parketal.,2024),SMsandMCswereeval-\nare Collect-And-Judge and Collect-And-Edit. In\nuatedontwometrics: TextualCompleteness(i.e.,\nbothapproaches,\"collect\"meanstheinitialround\nwhetherthetexthascompleteEnglishwritingwith\noffree-textannotation. Afterthat,onemay\"judge\"\ngoodgrammar)andCorrectness(i.e.,whetherthe\ntheannotationsbygivingratingsor\"edit\"theanno-\ntextissemanticallycorrect). Meanwhile,BKwas\ntationstomakecorrectionsandimprovetheanno-\nevaluatedonfourmetrics: TextualCompleteness,\ntations. Judgingallowsdetectingpoorlyannotated\nFactuality(i.e.,whetheritisfactuallycorrect),Rel-\ninstancesandshowingmeasurementsofannotation\nevance(i.e.,whetheritisrelevanttoinferringthe\nqualitywhileeditingincreaseslinguisticdiversity\nmemecaption),andSufficiency(i.e.,takentogether,\nbyallowingmultipleannotatorsperinstance.\nwhetheritcoversalltheknowledgeneededtoprop-\nTo combine the strengths of both approaches,\nerlyinferthememecaption). Allmetricsareevalu-\nwe employed a three-stage \"Collect-Edit-Judge\"\natedonthe5-pointLikertscale(Likert,1932).\nprocedureasfollows:\nStage1: Collect Weaskedfourannotatorswho 3.3 FinalDataset\narenativeEnglishspeakers4 toannotatethethree After filtering (to ensure high annotator confi-\nfields (i.e., SM, BK, and MC) according to our dence),wehad5,810examplesinthetrainingset\nannotationguidelines(seeAppendixB),andindi- and 1,000 examples in the test set. In addition,",
    "char_length": 1488
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 11,
    "text": "cateiftheyareconfidentwiththeirunderstanding. 1,927,509,and447memesinthetraining,devel-\nAnnotators have access to the entire Web for ref- opment,andtestsetscontainmorethantwoBKs,\nerence and were encouraged to provide multiple and 31, 7, and 11 contain more than two MCs,\nBKentriesandMCsforameme. Ifanannotator respectively.\ndidnotunderstandamemeorbelievedtheyhada As we used the Collect-Edit-Judge approach,\nbias(e.g.,politicalorreligiousbias),theywerein- inter-rateragreementisnolongerapplicable. How-\nstructedtoskipthememe,andthisinstancewould ever, to provide a rough idea of ‘agreement’, we\nbereassignedtoanotherannotator. measuredthemodificationratesduringtheediting\nprocess(Table2). SMshavethelowestmodifica-\n4Detailsonannotatorrecruitmentandtrainingcanbefound\ninAppdendixA. tionratesof24%,whileBKandMCshavehigher\n16076\nFigure2: Annotationexamples.\nField Agree Disagree Add Cut Wordcount annotations,and(2)empiricallyverifyourhypothe-\nsesaboutmemecaptioninganditsrelationshipwith\nSM 76% 6% 12% 6% 17.45\nBK 62% 19% 11% 8% 21.61 downstreamCMUtasks.\nMC 55% 31% 4% 10% 9.93\n4.1 ImplementationDetails\nTable 2: Statistics of the fields in MemeInterpret.\nModel WeconductedexperimentswithLLaVA\nTypes of edits include \"Disagree\" (serious disagree-\nment),\"Add\"(annotationcontainsinadequate/missing\n1.5-7b6(Liuetal.,2024),oneofthetop-performing\ninformation;changesinvolveaddinginformation)and open-sourcevision-languagemodels. ItusesCLIP-",
    "char_length": 1434
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 12,
    "text": "\"Cut\"(descriptionistooverbose;changesinvolvedelet- ViT-L-336pxasthevisionencoderandVicunav1.5\ning information). \"Word Count\" shows the average 13BastheLLM.Thetwomodalitiesare\"bridged\"\nnumberofwords.\nusingamulti-layerperceptron. Theconnectorwas\npre-trained with a subset of the CC3M dataset\nrates of 38% and 45%, respectively. These num- (Sharma et al., 2018), and the whole model was\nbers indicate the increasing annotation difficulty fine-tunedinanend-to-endfashionusingacademic-\nfromSMstoBKtoMCsandofferaroughideaof task-orientedVisualQuestionAnsweringdata.7\nhowoftendisagreementshaveoccurred.5\nTrainingandhyperparametertuning Weused\nThejudgingresultsindicateahighlevelofqual-\nParameter Efficient Fine Tuning (PEFT) by at-\nity in all the annotation fields. On Textual Com-\ntaching and training a LoRA adapter (Hu et al.,\npleteness,SM,BK,andMCgotscoresof5,4.97,\n2022) to all linear modules in the base model.\nand 4.98 respectively. On Correctness, SM, and\nWe reserved 20% of our training set as de-\nMCgotscoresof4.91and4.79,respectively. BK\nvelopment data. Across all PEFT runs, we\nfurthergotRelevance,Sufficiency,andFactuality setlr=1e-5,lora_alpha=8,lora_dropout=0.1,\nscoresof4.91,4.77,and4.94,respectively. num_epochs=3, batch_size=2, and r=8, and se-\nlected the best checkpoint based on the perfor-\n4 EmpiricalStudies\nmanceonthedevelopmentset. Forevaluationon\nWe conducted a broad range of experiments on\n6https://huggingface.co/llava-hf/llava-1.",
    "char_length": 1452
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 13,
    "text": "MemeInterpretto(1)gaugetheusefulnessofour 5-7b-hf\n7Inourexperiments,wealwaysfedboththetextextracted\n5ThemajorsourcesofdisagreementarediscussedinAp- fromamemeandtheimagetoLLaVA,leveragingitsvisual\npendixC. understandingcapability.\n16077\ngenerationtasks,wesetmax_new_tokens=100and\nHuman Automatic\nTaskSetup\nusedgreedygeneration.\nCor. Flu. Rel. Suf. BLE ROUBER NLI\nPrompttemplates Weprovidetheprompttem- Z 2.38 3.87 - - .001 .051 .804 .162\nMC\nplatesusedintheexperimentsinAppendixD. FT 2.37 4.60 - - .015 .189 .889 .265\nEvaluationmetrics Weconductedbothhuman BK Z 3.10 3.83 2.13 2.08 .006 .152 .845 .234\nFT 3.88 3.88 3.57 3.46 .017 .142 .830 .336\nandautomaticevaluations. Forhumanevaluation,\nZ 2.45 3.66 - - .018 .230 .897 .281\nwehadannotatorsmanuallyreviewthegenerated SM\nFT 3.38 3.81 - - .172 .370 .877 .385\noutputsofallmodelson250randomtestsamples,\nwhich is 25% of the test set. The outputs were Table3: LLaVA’sresultsonmemecaptioning(MC),\nscoredonthe5-pointLikertscalew.r.t.Correctness backgroundknowledgegeneration(BK),andsurface\n(i.e.,howclosethegeneratedcaptionsemantically messagegeneration(SM).\"Z\"and\"FT\"refertothe\nisfromthegroundtruth)andFluency(i.e.,whether zero-shotandfine-tunedsettings,respectively. Thebest\nresultforeachtaskandeachsettingisboldfaced.\ntheoutputisingoodEnglishlanguage). ForBK,\nowingtoitsnatureasalisting,weaddedtwomore\nResults AscanbeseeninTable3,fine-tuningthe\nmetrics,Relevance(i.e.,whethertheBKisrelevant\nmodelonSM,BK,andMCannotationsyielded",
    "char_length": 1472
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 14,
    "text": "tothememe)andSufficiency(i.e.,whethertheBK\nbetterresultsacrossallmetrics. Thereareafew\nis sufficient for someone from a different culture\ncases where the fine-tuned models scored lower\nto make sense of the meme). Each model output\nthanthezero-shotmodels,butthedifferenceisneg-\nwas rated by two independent annotators and the\nligiblecomparedtothesignificantoutperformance\nmodel’snameswerenotshowntothem.\nonmostofthemetrics. Whilethefine-tunedresults\nFor automatic evaluation, we evaluated each\narebetterthanthezero-shotresults,wecanseethat\nmodel variant on the entire test setusing popular\ntheyarestillfarfromperfect.\nmetrics: BLEU-4(Papinenietal.,2002),ROUGE-\nL(Lin,2004),BERTScore(Zhangetal.,2020),and\n4.3 UsingBKandSMforMemeCaptioning\ntheentailmentscorefromanNLImodel8(Manakul\nSinceBKandSMaremeanttosupportmemecap-\netal.,2023). Whilethefirsttwometricsarebased\ntioning,ournextexperimentinvolvesdetermining\nonn-gramoverlaps,whichtendtomeasuretextual\ntheusefulnessofthesetwotypesofannotations.\nfluency,thelasttwomeasurethesemanticsimilar-\nityofthegeneratedandground-truthtexts. 4.3.1 UsingGoldBKandSMAnnotations\nWefirstevaluatetheusefulnessofgoldBKandSM\n4.2 SanityChecks\nannotationsformemecaptioning,withthegoalof\nThegoalsofourfirstexperimentaretwo-fold. First, obtainingupper-boundperformanceonMCgener-\nwe check whether our annotations are useful by ationgivenperfectSMandBKinformation.\ncomparingresultsofmodelsfine-tunedonouran- Setup We trained three models. First, to deter-",
    "char_length": 1478
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 15,
    "text": "notationswiththecorrespondingzero-shotresults.9\nmine whether BK and SM are useful for meme\nSecond,wegaugethedifficultyofgeneratinggood captioningwhenappliedincombination,wefine-\nMCs,BK,andSMs. tunedLLaVAusingbothSMandBKintheprompt.\nSetup LLaVA was evaluated on three tasks — Next,todeterminewhetherBKandSMareuseful\nSM generation, BK generation and meme cap- whenappliedinisolation,weconductedablation\ntioning — under two settings: the zero-shot set- experimentsinwhichwefine-tunedLLaVAusing\nting, where no data from MemeInterpret was exactlyoneofthetwoknowledgesources. Inthese\nused to train LLaVA, and the fine-tuned setting, experiments, gold BK and SM annotations were\nwherewefine-tunedLLaVAonthetrainingsplitof used.\nMemeInterpret with the hyperparameters tuned Results Rows 1-2 of Table 4 show the results.\nonthedevelopmentset. The fine-tuned LLaVA with both inputs achieves\nbetter performance across all metrics except Flu-\n8https://huggingface.co/potsawee/\nency. ThissuggeststhatBKandSM,whenapplied\ndeberta-v3-large-mnli\n9Thischeckismotivatedbytheexperimentsconductedon incombination,canimproveMCgenerationexcept\nMemeCapbyHwangandShwartz(2023),whoshowedthat thattheoutputsareslightlylessfluent.\ntheirfine-tunedresultsonmemecaptioningwereworsethan\nAninterestingquestionis: isitmorechallenging\ntheirzero-shotresultsbutdidnotprovideanyexplanationsfor\ntheirunexpectedresults. togenerateMCsforhatefulmemesornon-hateful\n16078\nHuman Automatic modelshowninrow2ofTable4wasusedtogen-\n# Inputs",
    "char_length": 1490
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 16,
    "text": "eratememecaptionsbyreplacingthegoldBKand\nCor. Flu. BLE ROU BER NLI\nSM annotations with the automatic BK and SM\nMCpredictionwithoutBKandSM\nannotations. Forthejointmodel,wefine-tunedit\n1 Memeonly 2.37 4.60 .015 .189 .889 .265\ntogeneratetheconcatenationofSM,BK,andMC.\nPipelineMCpredictionwithgoldannotations\nResults Results of MC generation using these\n2 Meme+BK+SM 3.54 4.49 .041 .280 .898 .507\ntwomodelsareshowninrows5and6ofTable4. A\n3 Meme+SM 2.68 3.61 .004 .090 .824 .382\n4 Meme+BK 2.92 3.41 .007 .102 .824 .462 fewpointsdeservemention. First,thejointmodel\n(row6)outperformsthepipelinemodelw.r.t.allof\nPipelineMCpredictionwithpredictedinputs\nthemetricsusedinbothhumanandautomaticeval-\n5 Meme+AutoBK&SM1.95 2.37 .002 .054 .778 .213\nuations. Thisisperhapsnotsurprising,aspipeline\nJointMC,SM,andBKprediction\nmodels are known to suffer from error propaga-\n6 Memeonly 2.90 4.65 .013 .186 .877 .364\ntion. Second,thejointmodeloutperformsthebasic\nmodel(row1)onbothhumanevaluationmetrics,\nTable4: Fine-tunedLLaVA’sresultsonmemecap-\nwith a wide margin on Correctness (0.53). This\ntioningwithvaryinginputs. Forcomparisonpurposes,\nrow1showsthefine-tunedresultsformemecaptioning shows that even noisily computed SMs and BKs\nthatweretakenverbatimfromTable3. Thebestresult canbenefitMCprediction. Perhapsimpressively,\nforeachmetricisboldfaced. thejointmodelachievedahigherCorrectnessscore\nthanoneofthemodelsthathasaccesstogoldSM",
    "char_length": 1415
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 17,
    "text": "memes? Toanswerthisquestion,weexaminedthe duringtesttime(row3)whileachievingthehighest\nMCgenerationperformanceofthebest-performing Fluency score overall. This result shows that the\nmodel (row 2) separately on the hateful and non- ideaoftrainingMCgeneratorswithSMandBKis\nhateful memes. While the model scored slightly verypromising.\nloweronthehatefulmemesacrossallmetrics,the\ndifferencesarestatisticallyindistinguishable.10 4.4 EvaluationonHatefulMemeDetection\nAblationresultsareshowninrows3and4. Com- Wehypothesizethatmemecaptions,beingthecore\nparingthemwiththeresultsinrow2,weseethat taskinCMU,togetherwiththesurfacemessages\nremovingeitherknowledgesourcecausesconsid- and background knowledge, could be profitably\nerableprecipitationinMCgenerationperformance. exploitedfordownstreamCMUtasks. Inournext\nThese results suggest that both BK and SM con- experiment,wetestedthishypothesisonHMD,the\ntributepositivelytoMCgenerationperformance. task of classifying whether a meme is hateful or\nnot, using the hatefulness labels provided by the\n4.3.2 UsingAutomaticallyGeneratedBKand\nFHMdataset(SeeSection3.1fordetails).\nSMAnnotations\nStateoftheart ThetophalfofTable5summa-\nWhenapplyingmemecaptioningmodels,itisnot\nrizesthestate-of-the-art(SOTA)resultsonHMD,\npractical to assume that gold BK and SM anno-\nwhich are expressed in terms of AUROC and ac-\ntations exist. Hence, we examined the impact of\ncuracy.11 The current best systems are PaLI-X-\nautomatically generated BK and SM annotations",
    "char_length": 1483
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 18,
    "text": "VPD (Hu et al., 2024), which has an AUROC of\non MC generation. Note that our goal is not to\n0.892,andRGCLHateCLIPper(Meietal.,2024),\ndesignnewBKandSMgenerationmodels. Rather,\nwhichhasanaccuracyof0.788. Theyarefollowed\nwe seek to understand whether the BK and SM\nbyFlamingo80B(Alayracetal.,2022)andHate-\nannotationsgeneratedbyexistingmodelscanbene-\nCLIPer(KumarandNandakumar,2022). Among\nfitMCgeneration,thusestablishinglower-bound\nthese top-performing HMD systems, only Hate-\nperformanceonMCgeneration.\nCLIPerhaspubliclyavailablesourcecode.\nSetup WeexperimentedwithtwoMCgeneration\nOursystems Todeterminetheusefulnessofour\nmodelsthatexploitBKandSM,apipelinemodel\nannotationsforHMD,weusedthemtoconstruct\nandajointmodel. Thepipelinemodeloperatesas\nfive HMD systems. The first four are fine-tuned\nfollows. Wefirstusedthefine-tunedBKandSM\nLLaVA models, which differ in terms of what is\ngenerationmodelsinTable3toproduceautomatic\nBKandSMannotations. ThentheMCgeneration 11https://paperswithcode.com/sota/\nmeme-classification-on-hateful-memes (retrieved\n10FurtherdetailsareshowninAppendixE. inOctober2024)\n16079\nPerformances Human Automatic\nModel Model\nAUROC Acc. Cor. Flu. BLE ROU BER NLI\n1 PaLI-X-VPD(55B) 0.892 - T5Large 2.44 3.80 .033 .135 .420 .401\n2 RGCLHateCLIPper 0.870 0.788 LLaVA-FT-GoldAll 2.53 3.75 .024 .161 .800 .435\n3 Flamingo80B 0.866 - LLaVA-FT-AutoAll 2.30 3.90 .036 .200 .827 .364\n4 Hate-CLIPper 0.858 0.740\n5 LLaVA-AutoMC 0.724 0.668 Table6: Systemperformancesonhatefulmemeex-",
    "char_length": 1490
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 19,
    "text": "6 LLaVA-AutoAll 0.739 0.662 planation. Thebestperformancesareboldfaced.\n7 LLaVA-GoldMC 0.856 0.771\n8 LLaVA-GoldAll 0.876 0.786\n9 LLaVA-GoldAll Hate-CLIPper 0.890 0.800 theircounterparts. Thisperformancedropshould\n×\nnotbesurprisingsince(1)themodelsweusedto\nTable5: Resultsofthestate-of-the-artmodels(top) generatethesepredictedoutputsareverysimplistic\nandoursystems(bottom)onHatefulMemeDetec-\nand (2) errors from the MC/SM/BK predictions\ntion. The symbolindicatesajointinferencesystem.\n× propagatetoHMDastheseHMDmodelsareeffec-\nFor each metric, the best result is boldfaced and the\ntivelypipelinemodels.\nsecond-bestresultisunderlined.\n4.5 EvaluationonExplainingHatefulMemes\nfed to the model beside the meme — \"MC\" only\nFinally, to complete the study of CMU task in-\nor\"All\"(SM+BK+MC),aswellaswhetherthose\nteraction,wealsodemonstratedtheusefulnessof\ninputsaregold(\"Gold\")orpredicted(\"Auto\")an-\nMemeInterpret’sannotationsinhatefulmemeex-\nnotations. Next, to determine if our annotations\nplanation. ProposedbyHeeetal.(2023),thistask\ncan be used to improve a SOTA HMD system,\naskssystemstogenerateatextualexplanationfor\nwe employa modelthat performsjoint inference\nwhyagivenmemeishateful. Theyalsoreleased\noverLLaVA-GoldAllandHateCLIPper(theonly\nHatReD,asetofhatefulmemeexplanationanno-\nopen-sourced SOTA HMD model shown above).\ntations for the images in the FHM dataset. This\nIndoingso,wefirstreplicatedthefine-tuningpro-\nallowsustoagainexaminetheeffectsofouranno-",
    "char_length": 1461
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 20,
    "text": "cedureofHateCLIPperonourtrainingset. During\ntationsonthisdownstreamtask.\ninference, let p and p be the probabilities that\n1 2 Compared to MemeInterpret, HatReD covers\nHateCLIPper and LLaVA-GoldAll predict as the\na different subset of the FHM dataset. As a re-\nhatefulnessprobabilityoftheinputmemerespec-\nsult,MemeInterpretandHatReDoverlapononly\ntively. Thecombined predictionfrombothmodels\n2,359 images. Thus, in this experiment, we split\nis then p = tp + (1 t)p , where the weight\n1 2\n− their intersection into 60% for training, 20% for\nt [0;1]ischosenusingthedevelopmentset.12\n∈ development,and20%fortesting. Inthatway,all\nResults Table5showstheresultsoffourSOTA imagesinvolvedhaveSM,BK,MC,andexplana-\nmodels (rows 1–4) and our five HMD systems\ntionannotations. Tomakethetestsetchallenging,\n(rows 5–9). As can be seen, LLaVA-GoldAll\nall memes with multiple social targets (based on\n× Hate-CLIPper, our strongest model, provision-\nHatReD’sannotations)wereputintothatsplit.\nally achieved SOTA performance in terms of ac-\nSetup Similar to previous generative tasks, we\ncuracy and was competitive with the strongest\nfine-tuned two LLaVA-based models to generate\nmodelinAUROC(only0.0025pointless). Note\ntheexplanationgivenallthreeannotationtypesas\nthat this system has only 7.5 billion parameters,\ninput. Thefirstoneusedgoldinputsandthesecond\nwhile PaLI-X-VPD is roughly seven times larger\noneusedpredictedinputs. Theprompttemplatefor\nin size. Furthermore, LLaVA-GoldAll alone has",
    "char_length": 1478
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 21,
    "text": "thistaskcanbefoundinAppendixD.5.\nhigher performance than all but the best model\nResults ResultsareshowninTable6. Forcom-\nontheleaderboardintermsofAUROC.Thesere-\nparison purposes, we replicated the best system\nsults showcase the effectiveness of our annota-\nin Hee et al. (2023) on our dataset split, which\ntions in HMD, predicting that improvements in\nis T5 Large. We see that the system using the\nmodeling SM, BK, and MC can enhance HMD\ngoldinputs(row2)outperformedtheSOTAmodel\nsystems. Asofnow, theresultsofthemodelsus-\n(row1),whilethesimplepipelinesystem(row3)\ningpredictedinputs,LLaVA-AutoMCandLLaVA-\nestablishedastronglowerbound. Thisfurtherun-\nAutoAll(rows5and6),areabout11%awayfrom\nderlinesthattheannotationsinMemeInterpretare\n12Thefinalmixingweightwas0.2452. agoodrepresentationofthememes’meaning.\n16080\nFigure3: Errorsmadebythetopmodelvariants.\n5 ErrorAnalysis forthemodeltoexhibitmoreadvancedreasoning\ncapabilities.\nTogainfurtherinsightsintothechallengesinmod-\nelingmemeinterpretations,weanalyzedtheerrors\n6 ConclusionandFutureWork\nmadebyourbestperformingmodels,whicharethe\nfine-tunedBKgenerationmodel(row4,Table3),\nIn light of the fact that existing CMU tasks are\nthefine-tunedSMgenerationmodel(row6,Table\nlargely tackled independently of each other, we\n3),andthefine-tunedMCgenerationmodelwith\ntookthefirststeptowardssuggestingthatthiscur-\ngoldSMandBKinputs(row5,Table4). Figure3\nrentresearchpracticecanpossiblybereshapedby\nshowsexamplesoftheirfailuremodes.",
    "char_length": 1470
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 22,
    "text": "proposingatask-agnosticrepresentationofmemes\nSM Weobservedthatthemodelfrequentlyomits basedonmeaningratherthanform. Subsequently,\nspecificdetailsinitsdescriptions,suchastheover- we(1)advocatedtheimportanceofadvancingre-\nlaid text, group names, race, celebrities, age, or search on the under-studied task of meme cap-\ndisabilities. Forexample,inFigure3a,themodel tioning,(2)identifiedtwochallengingsubtasksof\nfailedtoidentifytheentity\"KKKgroup\"andthe memecaptioning,backgroundknowledgegenera-\noverlaidtext. Inthiscase,themodelfailedtopick tionandsurfacemessagegeneration,and(3)pro-\nupthehintsfromthetext,whichreferstotheactiv- posedMemeInterpret,whichcouldsparkresearch\nitiesoftheKKKgroup. Subsequently,itproduced onstudyingtheinteractionsofdifferentcategories\nagenericimagecaptionthatexcludesmeaningful of CMU tasks. Extensive experiments showed\ndetails of the meme. This selective vision issue that(1)theMemeInterpretannotationsareuseful,\nremainsanopenquestionforimageunderstanding as the fine-tuned results are better than the zero-\ningeneral(Chungetal.,2024). shot results; (2) meme captioning could benefit\nBK Thefine-tunedBKgenerationmodelsome- othercategoriesofCMUtasks,includingclassifica-\ntimesproducedknowledgethatisirrelevanttothe tionandexplanationtasks;and(3)MemeInterpret\nmeme. InFigure3b,themodelincorrectlyincluded couldfacilitatethedevelopmentofaunifiedframe-\nFreyDammer,acharacterunrelatedtothememe, workthatcansimultaneouslyaddressallthreecat-",
    "char_length": 1462
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 23,
    "text": "and failed to capture the significance of \"Jeffrey egoriesofCMUtasks.\nDahmer\". This error perhaps stemmed from the Asthefine-tunedmodelsstillhavealotofroom\nlimitedtextrecognitioncapabilityofLLaVA1.5. forimprovement,webelievefutureworkshouldin-\nMC A common error in MC generation is the clude(1)thedevelopmentofnovelmodelsthatcan\nmererepetitionofBKorSMfromtheinput. For betterexploitourannotations,especiallyjointmod-\ninstance,inFigure3c,theMCmerelyregurgitates els that allow interaction of multiple CMU tasks\ntheBKwithoutattemptingtounpacktheimplica- and(2)anexplorationofwhetherourannotations\ntionbehindthememe. Thisunderscorestheneed canbenefitadditionaldownstreamCMUtasks.\n16081\nLimitations own judgement. They also gave consent for the\ncollecteddatatobeusedforresearchpurposes.\nGiventhatMemeInterpretcoverstopicsonUSso-\nTermsofuse Thisdatasetisconsistentwiththe\ncialmedia,itisnotexpectedtogeneralizetoother\ntermsofuseandtheintellectualpropertyandpri-\ncultures. Outside of the American context, there\nvacy right of people with the Facebook Hateful\nhasbeenworkinBengali(Ahsanetal.,2024)and\nMeme dataset. The dataset was licensed from\nTamil (Suryawanshi et al., 2020b). Future work\n©GettyImages. Thereisnothingaboutthecompo-\nshouldconsiderconstructingmulticulturalmeme\nsitionofthedatasetorthewayitwascollectedand\ndatasetbycombiningexistingdatasetsandcollect-\npreprocessed/cleaned/labeledthatmightimpactfu-\ningnewmemesforunderrepresentedcultures.\ntureuses.",
    "char_length": 1458
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 24,
    "text": "Besides, our findings are based on an open-\nsourced model. Future work should extend the Datadistribution Weopen-sourcedthedatapro-\ninvestigationtoclose-sourcedmodelstodeepenour duced from this work at https://github.com/\nunderstanding of CMU task interactions in these\nnpnkhoi/MemeInterpret.\ntypesofsystems.\nEthicsStatement References\nShawlyAhsan,EftekharHossain,OmarSharif,Avishek\nBroaderimplications Asmentionedbefore,the\nDas, Mohammed Moshiul Hoque, and M. Dewan.\nsolutiontothememecaptioningtaskisofpractical\n2024. A multimodal framework to detect target\nsignificance. Fromapracticalperspective,knowl- awareaggressioninmemes. InProceedingsofthe\nedge of the meaning being conveyed in a meme 18thConferenceoftheEuropeanChapteroftheAs-\n(and its caption) could be useful for other meme- sociationforComputationalLinguistics(Volume1:\nLongPapers),pages2487–2500,St.Julian’s,Malta.\nrelated processing tasks. For instance, knowing\nAssociationforComputationalLinguistics.\nwhatthemeaningiscouldfacilitatethedetermina-\ntionofwhetheramemecontainsharmfulcontent. Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc,\nAntoine Miech, Iain Barr, Yana Hasson, Karel\nTheoreticallyspeaking,beingabletogeneratemes-\nLenc,ArthurMensch,KatherineMillican,Malcolm\nsages like humans requires that a machine read\nReynolds, Roman Ring, Eliza Rutherford, Serkan\nbetween the lines and achieve a deeper level of Cabi,TengdaHan,ZhitaoGong,SinaSamangooei,",
    "char_length": 1423
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 25,
    "text": "understanding of perceptual input, enabling ma- Marianne Monteiro, Jacob L. Menick, Sebastian\nchine perception to get one step closer to human Borgeaud,AndyBrock,AidaNematzadeh,Sahand\nSharifzadeh,MikołajBin´kowski,RicardoBarreira,\nperception.\nOriol Vinyals, Andrew Zisserman, and Karén Si-\nEthicalconsiderations Havingsaidthat,weare monyan.2022. Flamingo: Avisuallanguagemodel\nallawarethatsomememescontainharmfulcontent, forfew-shotlearning. InAdvancesinNeuralInfor-\nmationProcessingSystems,volume35,pages23716–\nso when our models are applied to these harmful\n23736,NewOrlanes,LA,USA.\nmemes, they will generate harmful captions that\ncouldhaveanegativepsychologicalimpactonthe Mohit Chandra, Dheeraj Pailla, Himanshu Bhatia,\nusers,especiallyiftheyarethetargetoftheharm- AadilmehdiSanchawala,ManishGupta,ManishShri-\nvastava,andPonnurangamKumaraguru.2021. “Sub-\nfulcontent. Therefore,aswithmanyotherAI/NLP\nvertingtheJewtocracy”: Onlineantisemitismdetec-\ntechnologies,ourmodelsshouldbeusedwithcare.\ntion using multimodal deep learning. In Proceed-\nWe should emphasize that our intent is to build ingsofthe13thACMWebScienceConference2021,\nmodels for interpreting memes, hoping that read- WebSci’21, pages148–157, NewYork, NY,USA.\nersofmemeswilllesslikelybemanipulatedafter AssociationforComputingMachinery.\nunderstandingtheintentionofthememeauthors.\nJiwanChung,SungjaeLee,MinseoKim,SeungjuHan,\nSteps taken to protect annotators from harm- AshkanYousefpour,JackHessel,andYoungjaeYu.",
    "char_length": 1477
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 26,
    "text": "ful content All annotators were provided with 2024. Selective vision is the challenge for visual\nreasoning: Abenchmarkforvisualargumentunder-\nathoroughinstructionaltrainingsessioninwhich\nstanding. InProceedingsofthe2024Conferenceon\nthey were instructed on how to annotate the data\nEmpiricalMethodsinNaturalLanguageProcessing,\nandhowtogoaboutthewholetask. Duringtrain- pages2423–2451,Miami,Florida,USA.Association\ning, annotators were shown the types of memes forComputationalLinguistics.\nthattheywillworkwithsothattheyhaveanidea\nDimitarDimitrov,BishrBinAli,ShadenShaar,Firoj\nof the dataset’s nature. The annotators have full\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nautonomy to withdraw from the project at their Nakov, and Giovanni Da San Martino. 2021.\n16082\nSemEval-2021task6: Detectionofpersuasiontech- RensisLikert.1932. Atechniqueforthemeasurement\nniques in texts and images. In Proceedings of the ofattitudes. ArchivesofPsychology,140:1–55.\n15thInternationalWorkshoponSemanticEvaluation\n(SemEval-2021),pages70–98,Online.Association Chin-Yew Lin. 2004. ROUGE: A package for auto-\nforComputationalLinguistics. maticevaluationofsummaries. InTextSummariza-\ntionBranchesOut,pages74–81,Barcelona,Spain.\nElisabetta Fersini, Francesca Gasparini, Giulia Rizzi, AssociationforComputationalLinguistics.\nAuroraSaibene,BertaChulvi,PaoloRosso,Alyssa\nLees, and Jeffrey Sorensen. 2022. SemEval-2022 Chen Liu, Gregor Geigle, Robin Krebs, and Iryna",
    "char_length": 1445
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 27,
    "text": "task 5: Multimedia automatic misogyny identifi- Gurevych. 2022. FigMemes: A dataset for figura-\ncation. In Proceedings of the 16th International tivelanguageidentificationinpolitically-opinionated\nWorkshoponSemanticEvaluation(SemEval-2022), memes. InProceedingsofthe2022Conferenceon\npages533–549,Seattle,UnitedStates.Association EmpiricalMethodsinNaturalLanguageProcessing,\nforComputationalLinguistics. pages7069–7086,AbuDhabi,UnitedArabEmirates.\nAssociationforComputationalLinguistics.\nMing Shan Hee, Wen-Haw Chong, and Roy Ka-Wei\nLee. 2023. Decoding the underlying meaning of\nHaotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae\nmultimodal hateful memes. In Proceedings of the\nLee.2024. Improvedbaselineswithvisualinstruc-\nThirty-SecondInternationalJointConferenceonAr-\ntiontuning. InProceedingsoftheIEEE/CVFCon-\ntificialIntelligence,pages5995–6003,Macau,SAR\nferenceonComputerVisionandPatternRecognition,\nChina.InternationalJointConferencesonArtificial\npages26286–26296,Seattle,WA,USA.\nIntelligenceOrganization.\nEdward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan PotsaweeManakul,AdianLiusie,andMarkGales.2023.\nAllen-Zhu,YuanzhiLi,SheanWang,LuWang,and SelfCheckGPT:Zero-resourceblack-boxhallucina-\nWeizhuChen.2022. LoRA:Low-rankadaptationof tiondetectionforgenerativelargelanguagemodels.\nlargelanguagemodels. InProceedingsoftheTenth In Proceedings of the 2023 Conference on Empiri-\nInternational Conference on Learning Representa- calMethodsinNaturalLanguageProcessing,pages",
    "char_length": 1472
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 28,
    "text": "tions,Virtual. 9004–9017, Singapore. Association for Computa-\ntionalLinguistics.\nYushiHu,OtiliaStretcu,Chun-TaLu,Krishnamurthy\nViswanathan,KenjiHata,EnmingLuo,RanjayKr- Lambert Mathias, Shaoliang Nie, Aida\nishna,andArielFuxman.2024. Visualprogramdis- Mostafazadeh Davani, Douwe Kiela, Vinodku-\ntillation: Distillingtoolsandprogrammaticreason- mar Prabhakaran, Bertie Vidgen, and Zeerak\ningintovision-languagemodels. InProceedingsof Waseem. 2021. Findings of the WOAH 5 shared\ntheIEEE/CVFConferenceonComputerVisionand task on fine grained hateful memes detection. In\nPatternRecognition,pages9590–9601,Seattle,WA, Proceedings of the 5th Workshop on Online Abuse\nUSA. andHarms(WOAH2021),pages201–206,Online.\nAssociationforComputationalLinguistics.\nEunJeongHwangandVeredShwartz.2023. MemeCap:\nA dataset for captioning and interpreting memes. JingbiaoMei,JinghongChen,WeizheLin,BillByrne,\nIn Proceedings of the 2023 Conference on Empir- andMarcusTomalin.2024. Improvinghatefulmeme\nicalMethodsinNaturalLanguageProcessing,pages detectionthroughretrieval-guidedcontrastivelearn-\n1433–1445, Singapore. Association for Computa- ing. InProceedingsofthe62ndAnnualMeetingof\ntionalLinguistics. theAssociationforComputationalLinguistics(Vol-\nume1: LongPapers),pages5333–5347,Bangkok,\nSauravJoshi,FilipIlievski,andLucaLuceri.2024. Con-\nThailand.AssociationforComputationalLinguistics.\ntextualizinginternetmemesacrosssocialmediaplat-\nforms. InCompanionProceedingsoftheACMWeb\nKhoiP.N.NguyenandVincentNg.2024. Computa-",
    "char_length": 1500
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 29,
    "text": "Conference2024,pages1831–1840,Singapore.\ntionalmemeunderstanding: Asurvey. InProceed-\nDouweKiela,HamedFirooz,AravindMohan,Vedanuj ingsofthe2024ConferenceonEmpiricalMethodsin\nGoswami, Amanpreet Singh, Pratik Ringshia, and NaturalLanguageProcessing,pages21251–21267,\nDavideTestuggine.2020. TheHatefulMemesChal- Miami,Florida,USA.AssociationforComputational\nlenge: Detectinghatespeechinmultimodalmemes. Linguistics.\nInAdvancesinNeuralInformationProcessingSys-\ntems,volume33,pages2611–2624,Virtual.Curran KishorePapineni,SalimRoukos,ToddWard,andWei-\nAssociates,Inc. JingZhu.2002. Bleu: amethodforautomaticevalu-\nationofmachinetranslation. InProceedingsofthe\nGokulKarthikKumarandKarthikNandakumar.2022. 40thAnnualMeetingoftheAssociationforCompu-\nHate-CLIPper: Multimodalhatefulmemeclassifica- tational Linguistics, pages 311–318, Philadelphia,\ntionbasedoncross-modalinteractionofCLIPfea- Pennsylvania,USA.AssociationforComputational\ntures. In Proceedings of the Second Workshop on Linguistics.\nNLPforPositiveImpact(NLP4PI),pages171–183,\nAbuDhabi,UnitedArabEmirates(Hybrid).Associa- JeongsikPark,KhoiP.N.Nguyen,TerrenceLi,Suyesh\ntionforComputationalLinguistics. Shrestha, MeganKimVu, JerryYiningWang, and\n16083\nVincentNg.2024. MemeIntent: Benchmarkingin- Shardul Suryawanshi, Bharathi Raja Chakravarthi,\ntentdescriptiongenerationformemes. InProceed- PranavVerma,MihaelArcan,JohnPhilipMcCrae,\nings of the 25th Annual Meeting of the Special In- andPaulBuitelaar.2020b. Adatasetfortrollclas-",
    "char_length": 1483
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 30,
    "text": "terestGrouponDiscourseandDialogue,pages631– sification of TamilMemes. In Proceedings of the\n643, Kyoto, Japan. Association for Computational WILDRE5–5thWorkshoponIndianLanguageData:\nLinguistics. Resources and Evaluation, pages 7–13, Marseille,\nFrance.EuropeanLanguageResourcesAssociation\nShraman Pramanick, Dimitar Dimitrov, Rituparna\n(ELRA).\nMukherjee, Shivam Sharma, Md. Shad Akhtar,\nPreslavNakov,andTanmoyChakraborty.2021a. De-\nSarahWiegreffeandAnaMarasovic.2021. Teachmeto\ntecting harmful memes and their targets. In Find-\nexplain: Areviewofdatasetsforexplainablenatural\ningsoftheAssociationforComputationalLinguis-\nlanguageprocessing. InProceedingsoftheNeural\ntics: ACL-IJCNLP2021,pages2783–2796,Online.\nInformationProcessingSystemsTrackonDatasets\nAssociationforComputationalLinguistics.\nandBenchmarks,volume1,Virtual.\nShraman Pramanick, Shivam Sharma, Dimitar Dim-\nitrov,Md.ShadAkhtar,PreslavNakov,andTanmoy\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nChakraborty. 2021b. MOMENTA: A multimodal\nWeinberger, and Yoav Artzi. 2020. BERTScore:\nframework for detecting harmful memes and their\nEvaluating text generation with BERT. In Inter-\ntargets. InFindingsoftheAssociationforComputa-\nnational Conference on Learning Representations,\ntionalLinguistics: EMNLP2021,pages4439–4455,\nAddisAbaba,Ethiopia.\nPunta Cana, Dominican Republic. Association for\nComputationalLinguistics.\nA AnnotatorRecruitmentandTraining\nChhavi Sharma, Deepesh Bhageria, William Scott,",
    "char_length": 1465
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 31,
    "text": "SrinivasPYKL,AmitavaDas,TanmoyChakraborty,\nWe started with 15 annotator candidates who are\nViswanath Pulabaigari, and Björn Gambäck. 2020.\nSemEval-2020task8: Memotionanalysis-thevisuo- all undergraduate students in computer science13\nlingual metaphor! In Proceedings of the Four- atourinstitutionandprovidedthemwithonehour\nteenthWorkshoponSemanticEvaluation,pages759–\nof training before assigning them a sample task\n773,Barcelona(online).InternationalCommitteefor\ninvolving30annotations. Theninecandidateswho\nComputationalLinguistics.\nmettherequiredstandards(regardingTextualCom-\nPiyush Sharma, Nan Ding, Sebastian Goodman, and\npleteness and Correctness) were recruited. They\nRaduSoricut.2018. Conceptualcaptions: Acleaned,\nparticipated in this project as part of the \"Under-\nhypernymed,imagealt-textdatasetforautomaticim-\nagecaptioning. InProceedingsofthe56thAnnual graduate Research in Computer Science\" course\nMeeting of the Association for Computational Lin- theysignedupfor,duringwhichtheyacquiredex-\nguistics(Volume1: LongPapers),pages2556–2565, perience and skills involved in a research project\nMelbourne,Australia.AssociationforComputational\ninvolvingdataannotationandmodeltraining. No\nLinguistics.\nadditionalcompensationwasthusprovidedtothese\nShivam Sharma, Siddhant Agarwal, Tharun Suresh, students. Amongthenineparticipants,therewere\nPreslav Nakov, Md. Shad Akhtar, and Tanmoy\nfourAmericans,fourKoreans,andoneIndian. As\nChakraborty. 2023. What do you MEME? Gener-",
    "char_length": 1476
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 32,
    "text": "forthegenderdistribution,twoparticipantswere\natingexplanationsforvisualsemanticrolelabelling\ninmemes. ProceedingsoftheAAAIConferenceon femalesandsevenweremales. Fourofthemserved\nArtificialIntelligence,37(8):9763–9771. asannotators(duringtheCollectstage)whilefive\nacted as editors and judges. These participants\nShivamSharma,TharunSuresh,AtharvaKulkarni,Hi-\nmanshi Mathur, Preslav Nakov, Md. Shad Akhtar, providedfullconsenttotheannotationprocess.\nand Tanmoy Chakraborty. 2022. Findings of the\nWhen the participants first started annotating,\nCONSTRAINT 2022 shared task on detecting the\nthe two first authors discussed the results of the\nhero, thevillain, andthevictiminmemes. InPro-\nceedingsoftheWorkshoponCombatingOnlineHos- first100instanceswithboththeannotatorsandthe\ntilePostsinRegionalLanguagesduringEmergency editors. Throughouttheprocess,wealsoconducted\nSituations,pages1–11,Dublin,Ireland.Association bi-weeklyone-hourmeetingswhereallparticipants\nforComputationalLinguistics.\nannotated the same five instances and reviewed\nShardulSuryawanshi,BharathiRajaChakravarthi,Mi- themtogethertobetterunderstandtheguidelines.\nhaelArcan,andPaulBuitelaar.2020a. Multimodal\nmemedataset(MultiOFF)foridentifyingoffensive\n13Whileweagreethatitwouldbeidealforsocialscience\ncontent in image and text. In Proceedings of the\nstudentstoconductthisannotationtask,wenotedthatmemes\nSecondWorkshoponTrolling,AggressionandCyber- arecommonlyencounteredbyusersineverydaysocialmedia,",
    "char_length": 1462
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 33,
    "text": "bullying,pages32–41,Marseille,France.European andtheirinterpretationsareperformedbypeoplewhodonot\nLanguageResourcesAssociation(ELRA). necessarilyhavetraininginsocialsciences.\n16084\nopinionsonthememe’smeaning(e.g.,duetothe\ndifferences in cultural backgrounds and personal\nbeliefs),allannotationswereconsideredreasonable\nandaddedtothedataset. Thisfinalcaseisveryrare\n— outof nearly7K memes, only 49memes have\nmorethanonememecaption(lessthan1%).\nD PromptTemplatesandImplementation\nDetails\nD.1 PromptsfortheSanityCheck\nExperiments\n(a) (b)\nThepromptformemecaptioningis:\nFigure4: Twoexamplememes.\nYou will be provided with a meme. Your task is\nto infer the message that the author is trying\nB AnnotationGuidelines to convey through the meme. The message must\nbe in one single short sentence. The final\nmessage of this meme is:\nTheannotationguidelinesthatweprovidedtothe\nannotatorsareshowninTable7. Thepromptforsurfacemessagegenerationis:\nYou will be provided with a meme. Your task\nC SourcesofAnnotatorDisagreement\nis to identify the explicit or surface-level\nmessage conveyed by the meme. The surface\nTogaininsightsintothesourcesofdisagreement, message is what the meme is saying directly,\nwe further inspected the typical edits our editors including any text, images, or symbols\npresent. Describe this surface-level message\nmade. For SM, edits mostly involved adding or\nas simply and clearly as possible without\ncorrecting information about celebrities and the interpretation of deeper meaning. Surface",
    "char_length": 1499
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 34,
    "text": "message must be in one single short sentence.\ncontext of the image (e.g., the first annotator did\n### Surface message:\nnot know or misrecognized the character in the\nimage, which was later corrected by the editor). Thepromptforbackgroundknowledgegenera-\nForBK,editsmostlyinvolvedaddingnewpieces tionis:\nof information that the second annotator deemed You will be provided with a meme. Your task\nnecessary to interpret the meme, with occasional is to infer the background knowledge that a\nreader of the meme needs to possess before\ndisagreementsaboutthefactualaccuracyofthepre-\nthey can understand the ultimate intent\nviousBK.ForMC,editsvariedandcouldsimply behind the creation or sharing of a meme,\nbe about the specificity of the caption, or as seri- as perceived by its audience. Background\nknowledge is the minimum amount of knowledge\nousasdisagreementsaboutthetargetofthememe\nthat is missing from the meme. It is the\nand the sentiment of the meme toward the target. knowledge that needs to be combined with\nvisual and textual cues from the meme in order\nFigure4andTable8illustratetwoexamplememes\nto understand its meaning. Give me background\nandtheirannotationsbeforeandafterediting.\nknowledge in the form of a list. For example:\nWeobservedthatthedisagreementsintheMCs ’1. Soccer is the sports that children likes a\nlot. 2. There are two main political parties\nweretypicallyaccompaniedbyalackofknowledge\nin the US: Democratic and Republican.’ Each",
    "char_length": 1452
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 35,
    "text": "or an overlook by the annotators. In such cases, background knowledge must be in one single\nSM and BK annotations came in handy as they short sentence.\n### Background knowledge:\nhelpedtheeditorsunderstandtheviewpointofthe\nannotator and conduct fact-checking on the BK\nD.2 PromptforMemeCaptioningwith\nwhenappropriate. Onoccasionswhentheeditors\nvaryinginputs\nwereunsureabouthowtoedittheannotations,they\nraised the meme instance in the annotator group Belowisthepromptformatformemecaptioning\nfordiscussion. Whenaconsensuswasreachedin withSMandBKintheinputs. Notethat[SM]and\nthegroup,theeditorwentaheadandmadetheedit. [BK]weresubstitutedwiththeactualSMandBK\nOtherwise,ifthegroupasawholedidnothavea ground truth annotations. Whenever an input is\ngoodideaofthememe’smeaning,thememewould absent,thecorrespondingline(startingwith###)\nbediscarded. Finally,iftherearemultiplestrong wasremoved.\n16085\nGuideline\nThememeoriginallyhastwocomponents:theImageandtheText.\nAsurfacemessageisacompleteandstandalonerepresentation(1-3sentences)ofthewholememe,describingboththe\nImageandtheText. Itincludesanyidentifiableinformationaboutraces,religions,genders,sexualorientations,specific\ncelebrities,andanyothercharacteristicsofpeopleinthememe. Itmuststartwith\"It is an image about ...\",\"In\nthe image, ...\"orasimilarstructure. Ifamemehasmultipleimages,youcanwrite\"It is two images. The top\nimage is ..., and the bottom is ...\"Finally,dependingonhowthetextfitsintotheimage,itcanbewrittenas",
    "char_length": 1465
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 36,
    "text": "(1)\"{Description of the image}. The author describes the image as {Text}.\",(2)\"{Description of the\nimage}. The character in the meme says that {Text}.\",or(3)someotherstructurethatappropriatelycombines\ntheTextwiththeimagecaption.\nForFigure1a:Itisanimageofa70-year-oldCaucasianmansittinginfrontofawindowwithastunnedface,wearingahat\nthatsays\"VIETNAMVETERAN\".Theauthordescribestheimageas\"me:putsbagofpopcornintothemicrowave.every\noneelseattheseniorcenter:\"\nBackgroundknowledgeisadditionalknowledgeyouneededtousetoderivethememecaptionbeyondthesurfacemessage.\nYoucanwritemultiplesentences,representingmultiplepiecesofknowledge.\nForFigure1a:(1)TheVietnamWar,alsoknownastheSecondIndochinaWar,wasaprotractedandhighlycontroversial\nconflictthattookplaceinVietnam,Laos,andCambodiafromNovember1,1955,toApril30,1975.(2)Thesoundofpopcorn\npoppinginthemicrowavecanremindveteransofthegunfiresoundduringthewar. (3)Thepopcornpoppingsoundisa\nsatisfyingsoundthatisnottobescaredof.\nAmemecaptionisamessagetheauthorintendstoconveythroughthememe.Therecanbemultiplememecaptions.\nTable7: Annotationguidelines.\nField Agree. Before After Reason\nFigure4a\nSM Cut Thetextontopisalistspokenbytheau- It is an image of a Caucasian man with a changed the\nthorandthebottomtextisspokenbythe beard and mustache. The text on top is a format and\ncharacterintheimage. listnarratedbytheauthor,reading,\"BrettKa- madeitmore\nvanaugh,17.ChristinaFord,15.\"Thebottom detailed.\ntextisspokenbythecharacterintheimage,",
    "char_length": 1465
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 37,
    "text": "reading,\"I’lltakeshitthatneverhappened\nfor1000.\"\nBK Agree ThisrequiresunderstandingtheChristine 1.ThisrequiresunderstandingtheChristine changed the\nFordandBrettKavanaughcase,whichin- Ford and Brett Kavanaugh case, which in- formatbyin-\nvolvedsexualassaultallegationsagainstKa- volvedsexualassaultallegationsagainstKa- dexingBKs.\nvanaughduringhisSupremeCourtnomina- vanaughduringhisSupremeCourtnomina-\ntionprocessandanunderstandingthatJeop- tionprocessandanunderstandingthatJeop-\nardyisagameshowwherepeoplechoose ardy is a game show where people choose\ncategoriesandpointamounts. categoriesandpointamounts.\nMC Cut Kavanaugh and Ford had no sexual rela- TheauthorimpliesthattheChristineBlasey madeitmore\ntions. FordandBrettKavanaughcasewasafarce, detailed.\nmeantonlytoattackKavanaugh’scharacter\nduringhisSupremeCourtnomination. The\nmessagebrushesoffFord’sallegationsofsex-\nualassaultagainstKavanaugh,andinsultsher\nabilitytoprovidetruthfultestimony.\nFigure4b\nSM Agree 2picturessidebysideofPopeFrancisand 2picturessidebysideofPopeFrancisanda NaN\naMuslimmanwithabeard.Thecharacter Muslimmanwithabeard..Thecharacterin\ninthememesaysthat‘i’llhave72virgins thememesaysthat‘i’llhave72virginswhen\nwhenidiei’llhave72virginsbeforeidie.’ idiei’llhave72virginsbeforeidie.’\nBK Cut 1. Knowledge of Pope Francis and his 1.KnowledgeofPopeFrancisandhisroleas madeitmore\nrole as the head of the Catholic Church. theheadoftheCatholicChurch.2.Thereis detailed.",
    "char_length": 1438
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 38,
    "text": "2. KnowledgeoftheIslamicbeliefin72 anIslamicbeliefthatthereare72virginsin\nvirginsinparadise. 3. Knowledgeofthe paradise. 3. TheCatholicChurchhasbeen\nmisconductoftheCatholicChurchwithmo- associatedwithmolestingchildren. 4. The\nlestation. samestatementmeanscompletelydifferent\nthingsdependingonwhoissayingit.\nMC Agree Thepopewillmolestvirginsbeforehedies. ThePopewillmolestvirginsbeforehedies. NaN\nTable8: TheannotationsofthetwomemesshowninFigure4beforeandafterediting.\n16086\nYou will be provided with a meme, a\nCor. Flu. BLE ROU BER NLI\ndescription of its text and image, and\nthe background knowledge that a reader of Non-Hate 3.51 4.47 .035 .274 .897 .496\nthe meme needs to possess before they can Hate 3.58 4.51 .046 .286 .898 .518\nunderstand the message. Your task is to\np-value 0.65 0.69 0.27 0.44 0.76 0.41\ninfer the message that the author is trying\nto convey through the meme. The message must\nbe in one single sentence. Table9: Comparisonofnon-hatefulandhatefulmemes\n### Description of its text and image: [SM]. in performance of the fine-tuned meme captioning\n### Background knowledge: [BK]. model. Unpairedt-testswereconductedtodetermine\n### Message:\nwhethertheperformancedifferencesarestatisticallysig-\nnificant,withthep-valuesshowninthelastrow.\nD.5 PromptforHatefulMemeExplanation\nD.3 PromptforJointModelingofSM,BK,\nandMC Below is the prompt used to instruct LLaVA to\nperformthehatefulmemeexplanationtask.\nWeusedthefollowingprompttofine-tuneLLaVA\nYou will be provided with a meme, a",
    "char_length": 1494
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 39,
    "text": "togeneratetheconcatenationofSM,BK,andMC: description of its text and image, the\nbackground knowledge that a reader of the meme\nYou will be provided with a meme. Generate a needs to possess before they can understand\nsurface message (SM), background knowledge the message, and the message conveyed by\n(BK), and a meme caption (MC) for the the meme. Your task is to explain why the\nmeme. A surface message is defined as meme is hateful. The explanation must be\n\"what the meme is saying directly, including in one of the form (i) ’<verb> <target>\nany text, images, or symbols present, and <predicate>’ or (ii) ’use of derogatory\nexcluding interpretation of deeper meaning.\" terms against <target> <predicate>’, where\nA background knowledge list is defined as <target> represents the attacked social\n\"the minimum list of factual statements target and <predicate> highlights the hateful\nthat is missing from the meme. It is the implication.\nknowledge that needs to be combined with ### Description of its text and image: [SM].\nvisual and textual cues from the meme in order ### Background knowledge: [BK].\nto understand the meme’s meaning.\" A meme ### Message: [MC]\ncaption is defined as \"the message that the ### Explanation:\nauthor is trying to convey through the meme,\nwritten in one single short sentence.\" Format\nyour answers as \"<SM_start> Your SM <SM_end> E PerformanceDifferencesonHatefulvs.\n<BK_start> Your BK <BK_end> <MC_start> Your Non-HatefulMemes\nMC <MC_end>\"",
    "char_length": 1469
  },
  {
    "paper_id": "meme_interpret",
    "chunk_id": 40,
    "text": "We investigated the difference in effects of hate-\nful and non-hateful memes on meme captioning\nD.4 DetailsofHatefulMemeDetection performance. Amongthe250manuallyevaluated\nExperiments examples, we selected the output from the best\nsetupbasedonhumanandautomaticevaluation—\nBelow is the prompt used to instruct LLaVA to thefine-tunedMCgenerationmodelwithgoldSM\nperformHMDdetectiongivenSM,BK,andMC andBKinputs(row5,Table4). Then,wedivided\nasinputs. Duringevaluation,onlyonenewtoken them into two groups — 120 hateful memes and\nwas generated and evaluated against a \"0\" or \"1\" 130non-hatefulmemes,andcalculatedthemetrics\nlabel. for each (Table 9). We can see that non-hateful\nmemeshaveslightlylowerscoresthantheirhateful\nYou will be provided with a meme, a\ndescription of its text and image, and the counterparts,thoughthedifferencesarenotstatisti-\nbackground knowledge that a reader of the meme callysignificant(unpairedt-testswithp < 0.05).\nneeds to possess before they can understand\nthe message. Your task is to determine\nwhether the meme is hateful or not. Format\nyour answer as a binary classification, where\n1 indicates that the meme is hateful and 0\nindicates that the meme is not hateful. Only\nreturn the number.\n### Description of its text and image: [SM].\n### Background knowledge: [BK].\n### Message: [MC]\nIs this meme hateful? (0/1)\n16087",
    "char_length": 1347
  }
]