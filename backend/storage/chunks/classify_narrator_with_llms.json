[
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 0,
    "text": "5202\nnuJ\n11\n]LC.sc[\n1v13201.6052:viXra\nClassifying Unreliable Narrators with Large Language Models\nAnnelieseBrei1* KatharineHenry1† AbhisheikSharma2∗\nShashankSrivastava1∗ SnigdhaChaturvedi1∗\n1UNCChapelHill 2VirginiaPolytechnicInstituteandStateUniversity\nabrei@cs.unc.edu, katharinehenry@alumni.unc.edu, abhisharma@vt.edu,\n{ssrivastava, snigdha} @cs.unc.edu\nAbstract\nOftenwhenweinteractwithafirst-personac-\ncount of events, we consider whether or not\nthe narrator, the primary speaker of the text,\nis reliable. In this paper, we propose using\ncomputationalmethodstoidentifyunreliable\nnarrators, i.e. thosewhounintentionallymis-\nrepresentinformation. Borrowingliterarythe-\noryfromnarratologytodefinedifferenttypes\nofunreliablenarratorsbasedonavarietyoftex-\ntualphenomena,wepresentTUNA,ahuman-\nannotateddatasetofnarrativesfrommultiple\ndomains,includingblogposts,subredditposts,\nhotelreviews,andworksofliterature. Wede-\nFigure 1: Real-world text with first-person narrators,\nfine classification tasks for intra-narrational,\nsuchasthenarrativeshown(left),canbeanalyzedto\ninter-narrational, and inter-textual unreliabil-\ndetermine the unreliability of the narrator. We sepa-\nities and analyze the performance of popular\nratelyclassifythreetypesofunreliability(right): intra-\nopen-weight and proprietary LLMs for each.\nnarrational,inter-narrational,andinter-textual.\nWeproposelearningfromliteraturetoperform\nunreliablenarratorclassificationonreal-world\ntext data. To this end, we experiment with",
    "char_length": 1489
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 1,
    "text": "read, and your family differs on how reliable the\nfew-shot, fine-tuning, and curriculum learn-\ncandidateactuallyis. Foreachofthesesituations,\ning settings. Our results show that this task\nisverychallenging, andthereispotentialfor it would be useful to have an automatic tool that\nusing LLMs to identify unreliable narrators. identifiesunreliability.\nWe release our expert-annotated dataset and Readersofpersonalaccounts,suchasreviews,\ncode at https://github.com/adbrei/unreliable-\nonlinecomments,coverletters,andcollegeapplica-\nnarratorsandinvitefutureresearchinthisarea.\ntionessays,oftenimplicitlyquestionthereliability\nofthenarrator: CanItrusthowthisnarratorhas\n1 Introduction\nperceivedandisdescribingtheevent? Meanwhile,\nImaginethatyouareonsocialmediawarningyour writers who wish to defend their points are con-\nfriends about a recent shopping experience, and cernedabouthowtheytextualizetheirideas: AmI\nbeforesubmittingthepost,youwonderifthepre- sharinginformationinareliableway? Answering\nsentation of your writing undermines your credi- suchquestionsiscriticalforthesafetransmission\nbility. Inanotherwindow,youarewritingacover ofinformation(Nünning,2015).\nletter. You recount a critical learning experience However,answeringthesequestionsisnotasim-\nfromyourpastjobandwonderifyourpresentvoice ple task. That is because unreliability cues are\nsoundsreliabletothereader. Inthenextroom,your oftensubtleandcontext-dependent(Hansen,2007).",
    "char_length": 1439
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 2,
    "text": "familyisdiscussingthedebatetranscriptbetween Theymightbescatteredacrossthetextorinvolve\npoliticalcandidates. Yoursisterthinksoneofthe adeeperunderstandingbeyondwhatisexplicitly\ncandidates speaks like a villain from a novel she stated. Sometimesitisnecessarytodrawabstract\ninferencesabouttheemotionalandmentalstateof\n*DepartmentofComputerScience\n†DepartmentofEnglishandComparativeLiterature thenarrator. Also,atextmighthavemanyreaders,\nsomeofwhomfocusondifferentaspectsofthese not another. It is valuable to analyze narrators in\ncues. From a writer’s perspective, it is important thiswaybecauseitprovidesin-depthviewsofthe\nto pay attention to all of these cues to ensure the narratorfromlexicaltoabstractcontextuallevels.\nwritingsoundsreliabletoallreaders. Determiningnarratorunreliabilityultimatelycon-\nNarratologyhasexploredthesequestionsbyat- sidersallthreeformssincetogethertheyprovidea\ntemptingtodefinetheunreliablenarrator,afirst- morecompletepicture.\nperson speaker who unintentionally describes\nInthiswork,weborrowthesedefinitionsfrom\nsituations misleadingly (Booth, 1961). Hansen\nnarratologyandintroducethetaskofautomatically\n(2007)considersleadingdefinitionsandobserves\nidentifyingthreeformsofunreliablenarrators. We\n“theunreliablenarratorisaconceptcoveringvery\npose this problem as a set of binary/multi-class\ndiversetextualphenomena”andaccordinglypro-\nclassificationscorrespondingtothethreetypesof\nposes a taxonomy containing different forms of\nunreliability(shownintherightofFigure1). We",
    "char_length": 1500
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 3,
    "text": "unreliablenarratorswith“conceptualdistinction.”\nproposethattheseideasfromthetheoreticalfield\nThese forms include intra-narrational, inter-\nofnarratologycanbeusedmorebroadlytoidentify\nnarrational,andinter-textualunreliability. Thefirst\nunreliabilityacrossdiversereal-worlddomains.\nform,intra-narrationalunreliabilityistheclassi-\ncaldefinitionthatfocusesonthepresenceofverbal We observe that as of date there has been no\ntics(textualcuesthatindicateuncertainty). Theleft workonanalyzingnarratorunreliabilitywithauto-\nhalfofFigure1showsanexample: anexcerptfrom maticmethods,andtherearenoavailableresources\nablogpostwherethewriternarratesanexperience orlabeleddatasets. Hence,weintroduce TUNA,a\nwithanotherperson,Dorian,atabar. Thetextin collectionofpersonalanecdotesfromblogposts,\norangefontindicatescontentthatisnarratedinan subreddit posts, online reviews, and fiction. We\nintra-narrationallyunreliablemannerbecausethe hireexpertannotatorsobtaininghonorsundergrad-\nnarratoradmitshavingtroublerememberingdetails uate or graduate degrees in English literature to\nduetobeinginebriated. Consequentlytheirnarra- annotatetheseaccountsforthethreeformsofunre-\ntionispossiblyunreliable. Thesecondform,inter- liabilitymentionedabove.\nnarrationalunreliabilityoccurswhenasecondary\nTo identify unreliable narrators automatically,\nvoicepresentsacontrastingversionofevents. For\nweexploreusinglargelanguagemodels(LLMs).\nexample, in Figure 1, highlighted in green, Do-\nWe conduct experiments with 6 open and closed-",
    "char_length": 1498
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 4,
    "text": "riandoesnotagreewiththenarratorregardingthe\nsourceLLMsofavarietyofsizes. Wetryzero/few-\nwhereaboutsofanotebook. Suchacontradiction\nshotsettings,fine-tuning,andcurriculumlearning\nindicatesthateitherthenarratororDorianmustbe\n(Bengio et al., 2009). With these methods, we\nwrong and raises reader’s doubts about the relia-\nattempttolearnfromlabeleddatafromfictionand\nbilityofthenarrator. Thethirdform,inter-textual\ngeneralizethisknowledgetoreal-worldtext. We\nunreliabilityinvolvespattern-matchingthenarrator\nobserve that classifying unreliable narrators is a\nwith established unreliable character tropes (Rig-\nvery difficult task and encourage future research\ngan Jr, 1978). In Figure 1, highlighted in purple,\ntofurtherexploreitsnuancesandchallenges. Our\nthe reader questions the narrator’s reliability be-\ncontributionsareasfollows:\ncausetheyseemcunningastheybribethebartender\n(fittingthetropeofpícaro). Moredetaileddefini- • Weintroducethetaskofautomaticallyidentify-\ntions of each type of unreliability are outlined in ingunreliablenarrators;\nSection3. • We borrow narratological definitions for unre-\nIdentifyingthesethreeformsofunreliablenarra- liable narrator (i.e., we consider three diverse\ntorsrequirespickinguponsubtlecuesthatrange andincreasinglyabstractforms: intra-narrational,\nfrom specific lexical choices (e.g., a direct state- inter-narrational,andinter-textual);\nmentsuchas“it’shardtoremember”)toincreas- • WeintroduceTUNA,anexpertannotateddataset",
    "char_length": 1463
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 5,
    "text": "inglyabstractinferences(e.g.,drawinginferences ofunreliablefirst-personaccountsspanningfour\nthroughstatementsandactionsthatanarratorhas differenttextdomains;\ncunningandself-interest). Theseformsmaycon- • Weexperimentwithmultiplemethodsthatlearn\ntainoverlappingcharacteristics;however,theyare how to identify unreliable narrators in snippets\nclassifiedanddeterminedseparately. Hence,anar- fromfictionandtransferthisknowledgetocom-\nratormightbeunreliableinoneoftheseformsbut montextreadineverydaysituations.\n2 BackgroundandRelatedWork personnarratorsandconsideraspectsofnarrative\nbelievability. However,Booth(1961)drawsaclear\nTheterm“unreliablenarrator”isoriginallydefined distinctionbydeterminingthatconsciouslyingis\nbyBooth(1961): “Forlackofbetterterms,Ihave notacharacteristicofunreliablenarrators;instead\ncalledanarratorreliablewhenhespeaksfororacts unreliabilityis“amatterof[whatiscalled]incon-\ninaccordancewiththenormsofthework(which science; the narrator is mistaken, or he believes\nis to say, the implied author’s norms), unreliable himselftohavequalitieswhichtheauthordenies\nwhen he does not.” The vagueness of this defini- him.” WefollowBooth’sreasoninganddonotcon-\ntionhasencouragedmorerecentnarratologiststo sidernarratorswhodeliberatelyintendtomislead\nattempt to define the unreliable narrator in more readersbutonlythosewhosoundunreliable.\ncertainterms(Cannings,2023;Jacke,2018;Heyd,\n2006;Olson,2003;Fludernik,2000;Currie,1995;\n3 DefinitionsofUnreliability",
    "char_length": 1469
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 6,
    "text": "RigganJr,1978). Culler(1997)states,“Narrators\nare sometimes termed unreliable when they pro-\nvideenoughinformationaboutsituationsandclues In choosing our definitions of unreliability, we\nabouttheirownbiasestomakeusdoubttheirinter- make two assumptions. Firstly, given a text, we\npretationsofevents...” Hansen(2007)buildsupon assumethatitcontainsexplicitorimplicitinforma-\ntheworkofCullerandothersalientnarratologists tionthatcanbeleveragedtoascertainthenarrator’s\ntoproposeataxonomywithdefinitionsofmultiple unreliability (Chatman, 1990). By explicit infor-\naspectsofnarratorunreliability. Inthiswork,we mation, we refer to statements that directly state\nadoptthesedefinitionsandtaxonomy. thatanaccountmaybeunreliable(e.g.,thenarrator\nadmits to being inebriated during the time of the\nTothebestofourknowledge,thereiscurrently\ndescribedevents,asdemonstratedinthenarrative\nnoexistingliteraturethatexploresautomatedap-\ninFigure1). Byimplicit information,wereferto\nproachesforidentifyingunreliablenarrators. We\nless direct details (e.g., patterns exhibited by the\nnote recent efforts to automatically understand\nnarratorthatresembleunreliablecharactertropes).\notheraspectsofprotagonists,whoaresometimes\nSecondly,followingWall(1994),weassumeanar-\ndepicted in first-person (Yuan et al., 2024; Jang\nratorisreliableuntilthereadernoticesexplicitor\nandJung,2024;Brahmanetal.,2021;Huangetal.,\nimplicitinformationindicatingunreliability.\n2021; Bamman et al., 2013). Additionally, some",
    "char_length": 1473
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 7,
    "text": "works attempt to analyze the emotions of protag- We borrow definitions from the taxonomy for\nonists (Brahman and Chaturvedi, 2020; Rahim- unreliablenarrationintroducedbyHansen(2007).\ntoroghietal.,2017)ortheirrelationshipswithother Wenotethistaxonomy, proposedastheculmina-\ncharacters (Vijjini et al., 2022; Kim and Klinger, tionofabroadrangeofpriordefinitions,provides\n2019; Chaturvedi et al., 2017; Iyyer et al., 2016; adiversesetoftoolsforanalyzingnarratorsfrom\nSrivastavaetal.,2016). Suchworksindicatethat differentperspectivesandlevelsofdifficulty. We\nusingautomaticmethodsisareasonableapproach usethreeformsthatanalyzetraitswithincreasingly\nforaddressingourtask. abstractconceptionsofunreliability,asdescribed\nClassifying unreliable narrators is to a limited in the next three subsections. Examples for each\nextentrelatedtotaskssuchastheautomaticidentifi- oftheseunreliableformsfromthedifferenttextual\ncationofmisinformation(Saeidniaetal.,2025;Jar- domainsaregiveninAppendixA.\nrahiandSafari,2023)andrumors(Heetal.,2025;\nKwaoetal.,2025). Itisalsodistantlyrelatedtode-\n3.1 Intra-narrationalUnreliability\nceptiondetection,definedbyBurgoonandBuller\n(1994)astheidentificationofnarratorswhointend In intra-narrational unreliability the narrator ex-\ntocommitdeception,“adeliberateactperpetrated hibits verbal tics, “small interjections and com-\nby a sender to engender in a receiver beliefs con- ments that hint at an uncertainty in the narrator’s",
    "char_length": 1446
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 8,
    "text": "trarytowhatthesenderbelievesistruetoputthe relatingoftheevents”,suchas“Ithink”or“itwas\nreceiveratadisadvantage”(HazraandMajumder, solongago,it’shardtoremember.” (Hansen,2007).\n2024; Constâncio et al., 2023; Sarzynska-Wawer Table1showsvarioustypesofverbalticsandcor-\netal.,2023;Fornaciarietal.,2021;VanderWalt respondingexamples. Ifatleastonetypeofverbal\netal.,2018;Eloffetal.,2015;Almelaetal.,2013). tic is present in a text, its narrator is considered\nThesetasksaresimilarbecausetheyanalyzefirst- intra-narrationallyunreliable.\nType Example\nAdmissionoffaultorbias:Explicitadmissionofmistakes,biases,miss- “Itendtoseethingsfromauniquepointofview.”,\ningdetails,orreportingdetailsfromanotherlikelyunreliablecharacter. “Likeothersofmygeneration...”\nDefensivetone:Multiplephrasesinprotestation. “IfeelIshouldexplain”\nDigressions:Statementthatveersoff-topic. “Iwilldothatinaminute.Bytheway...”\nHedginglanguage:Multiplephrasesthatindicateuncertaintyorvague- “it seems that”, “it appears to be”, “I think”,\nness. “maybe”,“sortof”\nInconsistencies:Twoormorecontradictingstatementsoreventsthatdo “I am a nobody. But look! There is a plane\nnotaddup. drawingmynameinthesky.”\nSelectivememory:Explicitadmissionthatnarratormayhaveforgotten “Itwassolongago,it’shardtoremember”,“My\ndetails. memoryisnotwhatitusedtobe”\nStatementofpotentialdisbelief:Explicitadmissionthatnarrativesounds “Youmightnotbelieveme,but...”,“whathap-\nunlikely. penednextmightseemstrange”",
    "char_length": 1445
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 9,
    "text": "Table1: Examplesofverbalticsexhibitedbyintra-narrationallyunreliablenarrators.\n3.2 Inter-narrationalUnreliability eredinter-textuallyunreliable:\nInthisform,thenarratorisunreliablefromasec- Naïf : Blindtowrongs. Naiveobserverwho\nondarypointofviewasinthefollowingtwocases: lacks the social savvy, maturity, or awareness to\nunderstand the complexity of their environment.\nSame-unreliable-character-over-time :\nForexample: “Iacceptedtheassignmentwillingly.\nThe narrator is reflecting on events in the distant\nDimly, I heard the people around me muttering –\npastwhenhe/sheexhibitstraitsofunreliabilityand\ntalking about some danger? I ignored them and\nthepresent-daynarratordoesnotindicatechange\nwenttotheotherroom.” Inthissnippet,thenarrator\nwithinthenarrativesnippet(i.e.,thecurrentvoice\nactsblindlywithoutunderstandingthesituation.\nof the narrator has traits of unreliability). For ex-\nample: “Iusedtobeacrazyman. I’dwaitinline Madman : Highlyemotional. Narrator,often\neachday,desperatelyhopingthattheywouldletme with a frantic voice, who feels deep positive or\nin. Weee,thoseweregoodtimes.” Inthissnippet, negativeemotionstowardothersandismaddened\nthenarratordescribeshisdistantpastasunreliable by perceived torture or alienation. For example:\nwith “I used to be a crazy man...” His last state- “Myheartbeatwildly. Ittookmygreateststrengthto\nment,“Weee,thoseweregoodtimes”,indicateshis turnandwalkaway. Howcouldhe? Mybestfriend,",
    "char_length": 1427
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 10,
    "text": "perspectivehasnotchangedovertime. abetrayer?!” Inthissnippet,thenarratorreveals\nOther-character-contradiction : An- deepnegativefeelings,perceivedalienation,anda\nother character contradicts the narrator, typically frantictonerevealedthroughstylisticchoices.\nin the form of direct dialogue. For example: “I Pícaro : Triestobecunning. Sociallyaware\nthoughttheofferfromHenry’swasincredible. AsI rogue or antihero who experiences the rise and\npickedupapentosign,Iheardthejudge’svoice: fall of fortune while attempting to improve their\nhehadenteredtheroomthroughthefardoorand prospects and cleverly justifying their chaotic\nwastalkingtotwowell-dressedmen. “Whatscam- worldview. For example: “The school teacher\nmers these men from Henry’s have become,” he scoldedmeandtookawaythepaperairplane. As\nwassaying.” Inthissnippet,thenarratorbelieves soonasherbackwasturned,Iwhippedoutafresh\nhehasreceivedagoodoffer,butanothercharacter, sheetofpaper,determinedtobemorestealthythis\na judge, has a contradicting perspective that the time. Allthewhile,Ikeptoneeyeonthegirlwho\nofferisascam. Thereaderdoesnotknowwhich hadreportedme.” Thisnarratorexperiencesafall\ncharacterunderstandsthesituationbest,leavingthe of fortune when his paper airplane is taken away.\nnarrator’sreliabilityindoubt. Hetriestoimprovehisprospectsbymakinganew\nairplaneandshowscunningwhenhestealthilytries\n3.3 Inter-textualUnreliability toavoidbeingcaughtagain.",
    "char_length": 1415
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 11,
    "text": "Inthisform, ifthenarratorfitsthedescriptionof Clown : Flipsthenarrative. Narratorwhoof-\noneofthefollowingunreliablecharactertropes,as fersreinterpretationsthatrepackageinternaland/or\ndefinedbyRigganJr(1978),thenarratorisconsid- external conflict in a new light, potentially from\nCorpus #Samples Avg Min Max Opinion2 (Reviews) (Ott et al., 2011, 2013). We\nFiction 499 194.31 24 924 intendtofirstlearnhowtoclassifynarratorsfrom\nTrain/Valid 373 194.74 24 514 afictionaldomainandthengeneralizethisknowl-\nTest 126 193.06 48 924\nedge to other textual domains. To this end, we\nBlogposts 106 315.31 114 1050\nSubreddit 112 396.88 73 858 additionally collect about 500 narrative snippets\nReviews 100 157.43 53 460 fromstoriesfromProjectGutenberg(Fiction).3\nAlltextsamplesarewritteninfirst-person(hand-\nTable 2: TUNA statistics, including the total number\nverified)andrangefrom24to1050tokens. Sam-\nofsamplesandtheaverage,minimum,andmaximum\nples from Blog post, Subreddit, and Review con-\nnumberoftokensineachsampleperdomain. Thefirst\ntaintheentireoriginalwrittentextandarearguably\nrow of Fiction is the combination of Train/Valid and\nTestsubsets(rows2and3respectively). complete narratives. We note that Fiction sam-\nplesarenarrativesnippetsanddonotnecessarily\ncontaincompletestorieswithfullydevelopedbe-\nginnings, middles, and endings. Table 2 shows\ncorporastatistics. Additionaldetails,suchashow\nsnippetsareselectedfromthesourcecorporaare\ngiveninAppendixD.1.\nWedesignanannotationstudy, determinedex-",
    "char_length": 1491
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 12,
    "text": "emptbytheInstitutionalReviewBoard,andask10\nhumanannotatorswithundergraduateorgraduate\ndegreesinEnglishliteraturetoreadanddetermine\nthe intra-narrational, inter-narrational, and inter-\nFigure2: Distributionofresolvedlabels. Forintra-nar\ntextual unreliabilities of each narrative. We note\n(left): # narratives with (A) verbal tics or (R) none\nthat this is a time-consuming task: each sample\n(reliable). For inter-nar (middle): # narratives with\ntakes annotators roughly 5 minutes each to read,\n(A)“sameunreliablecharacterovertime”,(B)“other\nanalyze, and annotate. Because the 3 tasks focus\ncharacter contradiction”, or (R) none. For inter-tex\n(right): # narratives with (A) naïf, (B) madman, (C) ondifferentaspectsofthenarrative,annotatorsre-\npícaro,(D)clown,or(R)none. port having to re-evalutate the narrative for each\ntask. For 817 narratives, each annotated at least\ntwice,weestimatethestudytook172hours. See\nbehindafacadethatallowsthemtosaywhatever\nAppendixBforadditionaldetails.\ntheywant. Forexample: “Theycalledmeacoward.\nAnnotatorsaregiventhedefinitionsandexam-\nWhatho! Isawmyselfratherasmyownliberator.”\nplesofthethreeformsofunreliabilityasdescribed\nThisnarratordescribesasocietalview(thattheyare\ninSection3. Foreachform,theyaretaskedwith\nacoward)andmakesitcleartheyhaveadifferent,\nchoosingthemostrelevantunreliablelabel. Ifnone\nreinterpretedview(thattheyarealiberator).\nfit,theymaydecidethatthenarratorisreliablefor\nthatform. Forexample,forinter-textualunreliabil-\n3.4 The TUNADataset",
    "char_length": 1493
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 13,
    "text": "ity,theannotatorisaskedtochooseonelabelfrom\nSince there are no currently available resources “naïf”,“madman”,“pícaro”,“clown”,or“none: re-\nfor classifying unreliable narrators, we build an liable”. See Appendix B.1 for an outline of the\nexpert-annotated dataset, Texts with Unreliable instructionsgiventotheannotators.\nNarrators(TUNA),containingtextswithlabeled Each text sample is annotated by a minimum\nintra-narrationally, inter-narrationally, and inter- of two expert annotators. For these pairs of ini-\ntextually unreliable narrators. We collect short tialresults,wecalculateinter-annotatoragreement\ntextsamplescontainingfirst-personnarratorsfrom withCohenKappa’sscoreandobservesubstantial\nmultiple textual domains, including personal ac- agreement(LandisandKoch,1977)acrossallsam-\ncountsfromPersonaBank(Blogpost)(Lukinetal., ples: intra-narrationalκ = 0.75,inter-narrational\n2016), posts from r/AITA1 (Subreddit) (Vijjini\n2TheReviewdatasetcontainsrealandfake(deceptive)ho-\net al., 2024), and hotel reviews from Deceptive\ntelreviewsandisintendedforthetaskofidentifyingdeceptive\nreviews.SincetheReviewstaskdiffersfromidentifyingunre-\n1PostsarescrapedbetweenApril2020andOctober2021 liablenarrators,weonlycollectrealreviewsforourdataset.\nfromhttps://www.reddit.com/r/AmItheAsshole/ 3https://www.gutenberg.org/\nκ = 0.71, inter-textual κ = 0.73. We improve tings, fine-tuning using Parameter-Efficient Fine-\nlabelconsistencybyresolvingdisagreeinglabels: Tuning with Low-Rank Adaptation (LoRA) (Hu",
    "char_length": 1497
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 14,
    "text": "annotatorsparticipateinrobustconversations4 re- etal.,2022),andcurriculumlearning(CL)which\ngarding differing labels and choose the best one. trainsmodelsfirstoneasyandthenhardersamples.\nStatisticsforthedistributionofresolvedlabelsare For CL, the training dataset is divided into\ngiven in Figure 2 and additional information, in- easysamples(Subset-Easy)anddifficultsamples\ncludinganumericalbreakdownofcounts,isgiven (Subset-Difficult). We define difficulty of a sam-\ninAppendixC. ple based on how ambiguous it is. Specifically,\nTo encourage thoughtful choices, annotators foreachtypeofunreliability(i.e.,intra-narrational,\nwrite short descriptions listing observations and inter-narrational, inter-textual), weobservesome\nbriefexplanationsforwhytheydemonstrateunre- samplesmightcontaintraitsofmorethanonelabel.\nliability. All resolved labels have corresponding Forexample,indifficultsamples,anarratorwhois\ndescriptions; hence, each narrative has three de- predominantlyamadmanmightalsoexhibitsome\nscriptions(1perunreliability). Wecalculateacross pícaro-likeorclown-liketraits. Hence,forthissam-\nalldescriptionsanaverageof21.2tokens,witha ple,inadditiontomadman,pícaroorclownarealso\nmaximumof299tokensinagivendescription. See incorrect but reasonable candidates for the label.\nAppendixAforexamples. Wehypothesizethatsampleswithfewercandidates\nare easier to classify because there are fewer po-\n4 IdentifyingUnreliableNarrators\ntential choices for the final label. Samples with",
    "char_length": 1476
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 15,
    "text": "multiplecandidatesaremorechallengingbecause\n4.1 TaskDefinition\neachcandidatehasanarguable,albeitpotentially\nGivenn,atextnarratedbyafirst-personnarrator, weak,claimtobeingchosenasthefinallabel.\nwe classify narrators for intra-narrational, inter-\nBased on this motivation, we create (Subset-\nnarrational, and inter-textual unreliability as fol-\nEasy) and (Subset-Difficult). For this, the LLM\nlows. Forintra-narrationalunreliability, wewant\nisqueriedtoproducealistofcountsforthenum-\ntodeterminen ∈ {A,R}whereAcorrespondsto\nberoftraitsforeachlabel. Forexample,forinter-\nn having verbal tics and R corresponds to n not\ntextualunreliabilitytheLLMgeneratesalistsuch\nhavingverbaltics(intra-narrationallyreliable). For\nas, [A:<NUM>, B:<NUM>, C:<NUM>, D:<NUM>]\ninter-narrationalunreliability,wewanttodetermine\nwhere A, B, C, D respectively correspond to naïf,\nn ∈ {A,B,R}whereAcorrespondstonhavinga\nmadman, pícaro, and clown, and NUM is the to-\n“samereliablecharacterovertime”,B corresponds\ntal number of traits present in the narrative for\ntonhavingan“othercharactercontradiction”,and\nthe given label. Candidates are labels with a NUM\nRcorrespondston ∈/ {A,B}(inter-narrationally\nvalue > 0. The training samples are ranked ac-\nreliable). For inter-textual unreliability, we want\ncordinglyinorderoftheleasttothemostnumber\nto determine n ∈ {A,B,C,D,R} where A, B,\nofcandidates. Thereorderedsetisdividedinhalf\nC,D correspondstonhavinganaïf,madman,pí-\nintoSubset-EasyandSubset-Difficult. AnLLMis",
    "char_length": 1484
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 16,
    "text": "caro,orclown,respectively,andRcorrespondsto\nfirstfine-tunedonSubset-EasyandthenonSubset-\nn ∈/ {A,B,C,D} (inter-textually reliable). See\nDifficultusingLoRAadapterswith8-bitquantiza-\nFigure1foranexamplewiththelistofclasses.\ntionfor3epochsanddefaultPEFTconfiguration.\n4.2 Methods\n5 Experiments\nWe seek methods that deal with the complexi-\ntiesofclassifyingunreliablenarratorsbylearning ExperimentsareperformedonInstructmodelsfor\nfrom snippets from Fiction and testing in an out- Llama3.1-8B, Llama3.3-70B, Mistral-7B, Phi3-\nof-domain manner on real-world domains. For medium, GPT-4o mini, and o3-mini (reasoning\nthis purpose, we try zero-shot and few-shot set- model). WealsocompareresultswithsmallerLM\nclassifiers, BERT and ModernBERT. Setup and\n4Annotators either meet via video-call or exchange de-\npromptsaredescribedinAppendixD.WeuseFic-\ntailed messages. For disagreeing labels, they discuss their\nchoicesandselectafinalresolvedlabel. Iftheyareunable tiontraining/validationsamplesformodeltraining\ntoagree,athirdannotatordecidestheresolvedlabel,given and development and the (remaining) narratives\ntheirarguments. Timespentperdiscussion: simpletexts≈\nfromFiction,Blogposts,Subreddit,andReviews\n2minutes,sampleswithverycomplicatednarrators≈15-20\nminutes. as testing samples. In this way, we test on Fic-\ntioninanin-domainmannerandontheremaining\ndatasetsinanout-of-domainmanner.\n5.1 Results\nTable 3 presents performances of CL, fine-tuned,\nzero-shot, and few-shot methods where macro-",
    "char_length": 1485
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 17,
    "text": "averagedF1scoresareprovidedforeachdomain\n(usingLlama3.1-8B).Table4presentstheperfor-\nmanceofLLMsaveragedacrossdomains,andTa-\nble5showstheperformanceofLMclassifiers.\nWe notice six key takeaways. First, generally\nspeaking, allmethodsandmodelsperformbetter\nfortheintra-narrationaltaskthanfortheothertwo\ntasks. Similarly,theyperformbetterfortheinter- Figure3: Breakdownofcorrectlypredicted(green)vs.\nnarrationaltaskthanforinter-textual. Thisfinding incorrectly predicted (blue) unreliable narrators. Top\nindicates the intra-narrational task is easiest, and row: with respect to the narrator’s gender ∈ {female,\nmale, other}. Middle row: with respect to narrative\ntheinter-textualtask(requiringmoreabstractinfer-\nstyle∈{conversational,descriptive}. Bottomrow: with\nences) is most difficult for LLMs. Appendix E.2\nrespecttonarrativesentimenttone∈{positive,negative,\nshows an example demonstrating how the inter-\nneutral}. ResultsarefromLlama3.1-8Bexperiments.\ntextualtaskrequiresadeeperunderstandingofthe\nnarrator’sstateofmind,makingitmoredifficult.\nSecond, methods using training samples (i.e., LLMs. Tounderstandtheseobservations,wenote\nCL,fine-tuning,few-shot)outperformthezero-shot thatforFiction(in-domainexperiment),LMsgive\nmethod,indicatingthattrainingdatadoesimprove resultscomparabletoourzero-shotmethod;how-\nLLMperformance. AppendixE.3showssamples ever, for all the other test sets (out-of-domain ex-\nwhere incorrect labels are predicted in zero-shot periment),theperformanceoftheLMsdrastically",
    "char_length": 1499
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 18,
    "text": "andcorrectlabelsarepredictedinfew-shotbecause drops. Hence,wedeterminethatLMsarelesscapa-\nthemodellearnsfromtheshots. blethanLLMsofgeneralizingknowledgelearned\nThird, for most cases, CL outperforms fine- fromonedomaintootherdomains.\ntuning,indicatingthatmoresophisticatedwaysof Weprovideindividualperformancebreakdowns\nleveragingthetrainingdataispromisingforbetter of the remaining LLMs for each domain in Ap-\nperformance. pendix E (including a breakdown of class-wise\nFourth, in Table 3, we observe that out-of- scores in Table 9) and an error analysis of incor-\ndomain performances, especially those whose rectlyclassifiednarratorsinAppendixE.1.\nmethodsusemoretrainingdata(i.e.,CLandfine-\ntuning), are not better but good compared to in- 6 Analysis\ndomainperformances. Thisresultindicatesthatit\nis possible to learn from the Fiction text domain Inthissectionweanalyzeunreliabilityclassifica-\nandapplythatknowledgetootherreal-worldtext tion with respect to various narrative properties:\ndomains. Wemakesimilarobservationsforother narrator’sgender,numberofcharacters,narration\nmodels(notshownhereduetospaceconstraints). style,andoverallnarrativesentiment. Fortheseex-\nFifth,Table4showsCLimprovesperformance periments,weuseCLoutputsforonemodelfrom\nof smaller models but not larger ones. E.g., each open-source LLM family (3 total models).\nLlama3.3-70B few-shot performs competitively WeuseLlama3.3-70Btoautomaticallyinferthese",
    "char_length": 1426
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 19,
    "text": "withCLandfine-tuning,indicatingthatasmodel narrativeproperties(thecompletepromptsandan\nsizeincreases,learningfromfewersamplesyields erroranalysisaregiveninAppendixF.1andF.2).\ncomparablepredictivecapabilitiestolearningwith\nmoresamples. RQ1: Doesthegenderofthenarratoraffectthe\nFinally,forexperimentswithLMclassifiers,we prediction? Acrossalltestingsamples,wecount\nobserveaveragevaluesacrossalltestsetsareless 125 female, 215 male, and 43 other/ambiguous\nthanaveragevaluesforCLandfine-tunedmethods. narrators. The first row of Figure 3 shows the\nTheseresultsindicatethatLMsdonotoutperform percentages of female, male, and other narrators\nCL Fine-tuned Zero-Shot One-Shot Three-Shot\nIntra-nar Fiction 58.51±1.93 50.09±1.96 45.17±1.83 52.67±2.00 51.72±2.12\nBlogpost 53.94±2.22 50.63±2.27 45.56±1.80 29.33±4.48 40.54±0.73\nSubreddit 50.04±2.21 49.00±2.05 47.41±1.32 52.03±2.38 48.87±1.86\nReview 67.17±2.16 55.85±2.35 58.46±2.29 60.22±2.20 52.81±2.25\nInter-nar Fiction 34.59±1.82 34.63±2.26 16.20±2.19 15.97±1.19 17.09±1.26\nBlogpost 35.92±2.47 28.73±1.80 23.15±2.92 22.19±1.40 27.46±1.47\nSubreddit 30.91±1.80 25.59±1.90 30.97±1.77 22.65±1.35 21.68±1.37\nReview 35.29±1.66 36.59±2.18 25.85±1.79 25.67±3.11 25.37±3.10\nInter-tex Fiction 27.42±1.87 28.59±1.87 18.22±2.38 24.00±1.55 23.54±1.69\nBlogpost 19.58±1.78 18.99±1.34 24.23±2.79 28.59±1.75 24.35±1.56\nSubreddit 13.49±1.55 10.85±1.31 12.95±1.21 12.01±1.11 10.71±1.14\nReview 16.72±0.67 17.54±1.35 15.75±1.31 20.32±1.08 19.30±2.08",
    "char_length": 1472
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 20,
    "text": "Table3: BreakdownofunreliabilityF1(macro)scoresforeachdomainforLlama3.1-8B.Improvementsonleftare\nstatisticallysignificantcomparedtoresultsonrightrow-wisewithp<0.05(Droretal.,2018).\nCL Fine-tuned Zero-Shot One-Shot Three-shot\nIntra-nar Llama3.1-8B 57.42±2.13 51.39±2.16 49.15±1.81 48.56±2.76 48.48±1.74\nLlama3.3-70B 51.26±2.12 51.28±2.09 54.20±1.65 63.89±2.28 61.41±1.91\nMistral-7B 55.76±1.70 56.46±2.11 56.79±2.05 50.87±1.96 52.99±2.24\nPhi3-medium 53.75±2.14 52.18±2.36 60.00±2.22 44.70±1.69 44.86±1.49\nGPT-4omini — — 47.88±2.05 50.51±1.67 51.77±2.25\no3-mini — — 42.22±1.97 43.47±2.00 44.32±2.04\nInter-nar Llama3.1-8B 34.18±1.94 31.39±2.03 24.04±2.17 21.62±1.76 22.90±1.80\nLlama3.3-70B 33.49±2.31 30.32±1.29 29.11±1.63 31.23±1.72 34.02±2.23\nMistral-7B 31.15±1.45 25.75±0.44 19.49±1.36 33.07±1.92 31.29±1.86\nPhi3-medium 22.32±1.49 35.76±1.81 25.23±1.88 23.42±1.71 24.66±1.73\nGPT-4omini — — 28.15±1.49 31.48±1.70 26.00±1.52\no3-mini — — 32.18±1.90 28.79±0.91 27.40±1.59\nInter-tex Llama3.1-8B 19.30±1.47 18.99±1.47 17.79±1.92 21.23±1.37 19.48±1.62\nLlama3.3-70B 21.04±1.69 21.02±1.64 28.52±1.96 30.80±1.81 28.23±1.89\nMistral-7B 29.68±2.01 24.38±1.29 20.23±1.51 18.35±1.43 17.12±1.35\nPhi3-medium 25.00±1.51 26.24±1.82 27.56±1.70 18.84±1.84 16.41±1.38\nGPT-4omini — — 17.84±1.41 20.66±1.42 19.98±1.38\no3-mini — — 16.65±1.14 15.44±0.33 15.84±1.54\nTable4: UnreliabilityF1(macro)scoresforcombineddomainsforallmodelfamiliesandsizes. Resultsonleftare\nstatisticallysignificantcomparedtoresultsonrightrow-wise.",
    "char_length": 1496
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 21,
    "text": "BERT ModernBERT inter-textualtasks,other/ambiguouscharactersare\nIntra-nar Fiction 48.42 49.48 predictedmorecorrectlythaneitherfemaleormale\nAvg 17.77 39.94 narrators, indicating that performance improves\nInter-nar Fiction 31.37 38.46 whenthenarratorisnotspecifiedasfemaleormale.\nAvg 25.76 27.07\nInter-tex Fiction 12.46 14.71\nAvg 11.12 16.98 RQ2: How does the narration style change\nthe difficulty of the prediction? The middle\nTable5: UnreliabilityF1(macro)scoresforFictionand\nrow of Figure 3 shows that narratives written in\ncombineddomainsforsmallerLMclassifiers.\na conversational style tend to perform slightly\nbetter than those written in a descriptive style\nclassified w.r.t. unreliable narrators correctly vs. for intra-narrational unreliability. This could be\nincorrectly by Llama3.1-8B for 5 runs across because it might be easier to detect the verbal\nall testing samples. Figure 5 in Appendix F.3 tics within a conversational tone. However, for\nshows results from other models. We observe inter-narrationalandinter-textualtasks,narratives\nacross all model families that male narrators written in a descriptive tone perform better.\nare predicted correctly more frequently than Figure5inAppendixF.3showsresultsfromother\nfemale narrators. For inter-narrational and models.\nforminganalysisaregiveninAppendixF.\n7 Conclusion\nWe propose using automatic methods to classify\nintra-narrationally, inter-narrationally, and inter-\ntextually unreliable narrators. Borrowing defini-",
    "char_length": 1477
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 22,
    "text": "tionsfromnarratologywedefinebinaryandmulti-\nclassclassificationtasks,annotatenarrativesfroma\ndiversedomainoftexts,andevaluatetheabilityof\nLLMstoperformtheseclassificationtasksinzero-\nFigure4: Numberofcharactersvs. numberofsamples. shot,few-shot,fine-tuned,andcurriculumlearning\nAllSamples(solidblack)isthedistributionofallnar-\nsettings. Weobservethatthesetasksareverytricky\nrativeswithrespecttothenumberofcharacters. Blue,\nforLLMstosolveandofferourfindingsasacall\ngreen,andorangesolidlinesshowcorrectpredictions,\nfor future work to further investigate the use of\nandcorrespondingdashedlinesshowincorrectpredic-\nNLPmethodstoidentifyunreliablenarrators.\ntions. ResultsarefromMistralexperiments.\n8 Limitations\nFirstly,thisworkfocusesonshorttexts(nolonger\nRQ3: Howdoestheoverallnarrationsentiment than1050tokenseach),someofwhichdonotcon-\naffect the prediction? The last row of Figure 3 tain complete beginnings, middles, and endings.\ndemonstratesthatnarrativeswritteninanegative Weencouragefutureworktoconsiderthistaskfor\ntone perform better than narratives written in a longer-lengthtexts,suchasfull-lengthshortstories\npositive tone for intra-narrational unreliability. orbooks. Secondly,wenotethatallsamplesinour\nThis result is likely a consequence of negative datasetsarewritteninEnglish. Asthedefinitions\ntonesoftenharboringmultipleverbaltics,resulting ofunreliabilityareapplicabletoworksofotherlan-\nin an easier prediction. For inter-narrational and guages,werecommendfutureworkexploringthis",
    "char_length": 1493
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 23,
    "text": "inter-textual unreliabilities, narratives written taskonotherlanguages. Thirdly,forRQ1inSec-\nin a positive tone result in significantly better tion6,welimitouranalysistoonlyfemale,male,\npredictions than narratives written in a negative andother/ambiguousgenders. Finally,weobserve\ntone. SeeFigure7inAppendixF.3forresultsfrom thatthesizeofthedatasetisrelativelysmalldueto\nothermodels. thehighcostofhigh-qualityannotations.\nAcknowledgments\nRQ4: Are narratives with multiple characters\ntrickier to predict? Figure 4 shows the majority Wearegratefulforthesuggestionsfromouranony-\nof narratives contain 1-5 characters. Within this mousreviewers,andwethankHaoyuanLi,Anvesh\nrange,correctpredictionsforunreliabilities(solid Rao Vijjini, Somnath Basu Roy Chowdhury, and\nblue,green,yellow)peakatnarrativeswith1and Amartya Banerjee for their discussions and valu-\n3 characters. For intra-narrational classification, ableinsights. Thisworkwassupportedinpartby\nthereareconsistentlymorecorrect(solidblue)than NSFgrantIIS2047232.\nincorrect(dottedblue)predictions,indicatingthe\nnumberofcharactersdoesnotchangethedifficulty\nof the narratives to classify. For inter-narrational References\nand inter-textual classification, the number of in-\nAngela Almela, Rafael Valencia-García, and Pascual\ncorrectlypredictednarratives(dottedgreenandyel- Cantos.2013. Seeingthroughdeception: Acompu-\nlow) surpasses the number of correctly predicted tationalapproachtodeceitdetectioninspanishwrit-",
    "char_length": 1464
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 24,
    "text": "tencommunication. LinguisticEvidenceinSecurity,\nnarratives(solidgreenandyellow)whenthenum-\nLawandIntelligence,1(1):3–12.\nber of characters ≥ 2, suggesting that narratives\nwithmultiplecharactersaretrickertopredictthan DavidBamman,BrendanO’Connor,andNoahASmith.\nnarrativeswithonlythenarrator. SeeFigure8and 2013. Learning latent personas of film characters.\nIn Proceedings of the 51st Annual Meeting of the\nFigure9inAppendixF.3forothermodelresults.\nAssociationforComputationalLinguistics(Volume\nAdditionaldetailsregardingourmethodsofper- 1: LongPapers),pages352–361.\nYoshua Bengio, Jérôme Louradour, Ronan Collobert, andComputationalIntelligence(CSCI),pages416–\nand Jason Weston. 2009. Curriculum learning. 419.IEEE.\nIn Proceedings of the 26th annual international\nconferenceonmachinelearning,pages41–48. Monika Fludernik. 2000. Unreliable narration. stu-\ndienzurtheorieundpraxisunglaubwürdigenerzäh-\nWayneCBooth.1961. Therhetoricoffiction. Univer- lens in der englischsprachigen literatur. Poetica,\nsityofChicagoPress. 32(1/2):251–255.\nFaezeBrahmanandSnigdhaChaturvedi.2020. Mod- TommasoFornaciari,FedericoBianchi,MassimoPoe-\nelingprotagonistemotionsforemotion-awarestory- sio, Dirk Hovy, et al. 2021. Bertective: Language\ntelling. In Proceedings of the 2020 Conference on models and contextual information for deception\nEmpiricalMethodsinNaturalLanguageProcessing detection. In Proceedings of the 16th Conference\n(EMNLP),pages5277–5294. of the European Chapter of the Association for",
    "char_length": 1484
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 25,
    "text": "Computational Linguistics: Main Volume. Associ-\nFaezeBrahman,MengHuang,OyvindTafjord,Chao\nationforComputationalLinguistics.\nZhao, Mrinmaya Sachan, and Snigdha Chaturvedi.\n2021. “let your characters tell their story”: A PerKroghHansen.2007. Reconsideringtheunreliable\ndatasetforcharacter-centricnarrativeunderstanding. narrator. Semiotica,165(1/4):227–246.\nIn Findings of the Association for Computational\nLinguistics: EMNLP2021,pages1734–1752. Sanchaita Hazra and Bodhisattwa Prasad Majumder.\n2024. To tell the truth: Language of deception\nJudeeKBurgoonandDavidBBuller.1994. Interper-\nand language models. In Proceedings of the 2024\nsonal deception: Iii. effects of deceit on perceived\nConference of the North American Chapter of the\ncommunication and nonverbal behavior dynamics.\nAssociationforComputationalLinguistics: Human\nJournalofNonverbalBehavior,18:155–184.\nLanguage Technologies (Volume 1: Long Papers),\npages8506–8520,MexicoCity,Mexico.Association\nMax Cannings. 2023. Reading unreliable narra-\nforComputationalLinguistics.\ntion. The Transformative Power of Literature\nand Narrative: Promoting Positive Change: A\nQiangHe,SongyangjunZhang,YuliangCai,WeiYuan,\nConceptual Volume in Honour of Vera Nünning,\nLianboMa,andKepingYu.2025. Asurveyonex-\n86:131.\nploringrealandvirtualsocialnetworkrumors: State-\nof-the-artandresearchchallenges. ACMComputing\nSeymourBenjaminChatman.1990. Comingtoterms:\nSurveys.\nTherhetoricofnarrativeinfictionandfilm. Cornell\nUniversityPress.",
    "char_length": 1473
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 26,
    "text": "TheresaHeyd.2006. Understandingandhandlingun-\nreliablenarratives: Apragmaticmodelandmethod.\nSnigdhaChaturvedi,MohitIyyer,andHalDaumeIII.\nSemiotica,162:217–243.\n2017. Unsupervised learning of evolving relation-\nships between literary characters. In Proceedings\nEdwardHu,YelongShen,PhillipWallis,ZeyuanAllen-\nof the AAAI Conference on Artificial Intelligence,\nZhu, Yuanzhi Li, Shean Wang, and Weizhu Chen.\nvolume31.\n2022. Lora: Low-rankadaptationoflargelanguage\nmodels. ICLR.\nAlex Sebastião Constâncio, Denise Fukumi Tsunoda,\nHelenadeFátimaNunesSilva,JocelaineMartinsda\nTenghao Huang, Faeze Brahman, Vered Shwartz,\nSilveira,andDeborahRibeiroCarvalho.2023. De-\nand Snigdha Chaturvedi. 2021. Uncovering im-\nception detection with machine learning: A sys-\nplicit gender bias in narratives through common-\ntematicreviewandstatisticalanalysis. PLoSONE,\nsenseinference. InFindingsoftheAssociationfor\n18(2):e0281323.\nComputational Linguistics: EMNLP 2021, pages\nJonathan Culler. 1997. Literary theory: A very short 3866–3873.\nintroduction. OxfordUniversityPress.\nMohitIyyer,AnupamGuha,SnigdhaChaturvedi,Jor-\nGregoryCurrie.1995. Unreliabilityrefigured:Narrative danBoyd-Graber,andHalDauméIII.2016. Feuding\ninliteratureandfilm. TheJournalofAestheticsand familiesandformerfriends: Unsupervisedlearning\nArtCriticism,53(1):19–29. fordynamicfictionalrelationships. InProceedings\nof the 2016 Conference of the North American",
    "char_length": 1409
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 27,
    "text": "Rotem Dror, Gili Baumer, Segev Shlomov, and Roi Chapter of the Association for Computational\nReichart.2018. Thehitchhiker’sguidetotestingsta- Linguistics: HumanLanguageTechnologies, pages\ntisticalsignificanceinnaturallanguageprocessing. 1534–1544.\nIn Proceedings of the 56th annual meeting of the\nassociationforcomputationallinguistics(volume1: Janina Jacke. 2018. Unreliability and narrator types.\nLongpapers),pages1383–1392. on the application area of> unreliable narration<.\nJournalofLiteraryTheory,12(1):3–28.\nJHP Eloff et al. 2015. A big data science\nexperiment–identity deception detection. In 2015 Woori Jang and Seohyon Jung. 2024. Evaluating\nInternationalConferenceonComputationalScience llm performance in character analysis: A study\nof artificial beings in recent korean science fic- Proceedingsofthe18thAnnualSIGdialMeetingon\ntion. In Proceedings of the 4th International DiscourseandDialogue,pages360–369.\nConference on Natural Language Processing for\nDigitalHumanities,pages339–351. William Edward Riggan Jr. 1978. Pícaros, Madmen,\nNaïfs, and Clowns: The Unreliable First-Person\nAliJarrahiandLeilaSafari.2023. Evaluatingtheeffec-\nNarrator. Ph.D.thesis,IndianaUniversity.\ntivenessofpublishers’featuresinfakenewsdetection\nonsocialmedia. MultimediaToolsandApplications,\nHamid Reza Saeidnia, Elaheh Hosseini, Brady Lund,\n82(2):2913–2939.\nMaralAlipourTehrani,SanazZaker,andSabaMo-\nlaei.2025. Artificialintelligenceinthebattleagainst\nEvgeny Kim and Roman Klinger. 2019. Frowning",
    "char_length": 1487
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 28,
    "text": "disinformationandmisinformation: asystematicre-\nfrodo, wincing leia, and a seriously great friend-\nviewofchallengesandapproaches. Knowledgeand\nship: Learning to classify emotional relationships\nInformationSystems,pages1–20.\nof fictional characters. In Proceedings of the 2019\nConference of the North American Chapter of the\nJustyna Sarzynska-Wawer, Aleksandra Pawlak, Julia\nAssociationforComputationalLinguistics: Human\nSzymanowska, Krzysztof Hanusz, and Aleksander\nLanguageTechnologies,Volume1(LongandShort\nWawer.2023. Truthorlie: Exploringthelanguage\nPapers),pages647–653.\nofdeception. PloSONE,18(2):e0281179.\nLazarusKwao,YangYang,JieZou,andJingMa.2025.\nAsurveyofapproachestoearlyrumordetectionon Shashank Srivastava, Snigdha Chaturvedi, and Tom\nmicrobloggingplatforms: Computationalandsocio- Mitchell.2016. Inferringinterpersonalrelationsin\npsychological insights. Wiley Interdisciplinary narrative summaries. In Proceedings of the AAAI\nReviews: Data Mining and Knowledge Discovery, ConferenceonArtificialIntelligence,volume30.\n15(1):e70001.\nEstée Van der Walt et al. 2018. Identity deception\nJRLandisandGGKoch.1977. Themeasurementof\ndetection on social media platforms. Ph.D. thesis,\nobserveragreementforcategoricaldata. Biometrics,\nUniversityofPretoria.\n33(1):159174.\nAnvesh Rao Vijjini, Faeze Brahman, and Snigdha\nStephanie Lukin, Kevin Bowden, Casey Barackman,\nChaturvedi. 2022. Towards inter-character\nand Marilyn Walker. 2016. PersonaBank: A cor-\nrelationship-drivenstorygeneration. InEMNLP.",
    "char_length": 1501
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 29,
    "text": "pusofpersonalnarrativesandtheirstoryintention\ngraphs. In Proceedings of the Tenth International\nAnvesh Rao Vijjini, Rakesh R Menon, Jiayi Fu,\nConferenceonLanguageResourcesandEvaluation\nShashankSrivastava,andSnigdhaChaturvedi.2024.\n(LREC’16), pages 1026–1033, Portorož, Slovenia.\nSocialgaze: Improvingtheintegrationofhumanso-\nEuropeanLanguageResourcesAssociation(ELRA).\ncial norms in large language models. In Findings\nVera Nünning. 2015. Conceptualising (un) reliable of the Association for Computational Linguistics:\nnarration and (un) trustworthiness. Unreliable EMNLP2024,pages16487–16506.\nNarration and Trustworthiness: Intermedial and\nInterdisciplinaryPerspectives,pages1–28. KathleenWall.1994. “Theremainsoftheday”andits\nchallenges to theories of unreliable narration. The\nGretaOlson.2003. Reconsideringunreliability:Fallible JournalofNarrativeTechnique,24(1):18–42.\nand untrustworthy narrators. Narrative, 11(1):93–\n109.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond,ClementDelangue,AnthonyMoi,Pier-\nMyleOtt,ClaireCardie,andJeffreyT.Hancock.2013.\nricCistac,TimRault,RemiLouf,MorganFuntow-\nNegativedeceptiveopinionspam. InProceedingsof\nicz,JoeDavison,SamShleifer,PatrickvonPlaten,\nthe2013ConferenceoftheNorthAmericanChapter\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nof the Association for Computational Linguistics:\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nHumanLanguageTechnologies,pages497–501,At-\nQuentinLhoest,andAlexanderRush.2020. Trans-",
    "char_length": 1474
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 30,
    "text": "lanta,Georgia.AssociationforComputationalLin-\nformers:State-of-the-artnaturallanguageprocessing.\nguistics.\nInProceedingsofthe2020ConferenceonEmpirical\nMethods in Natural Language Processing: System\nMyle Ott, Yejin Choi, Claire Cardie, and Jeffrey T.\nDemonstrations, pages 38–45, Online. Association\nHancock. 2011. Finding deceptive opinion spam\nforComputationalLinguistics.\nby any stretch of the imagination. In Proceedings\nof the 49th Annual Meeting of the Association\nfor Computational Linguistics: Human Language XinfengYuan,SiyuYuan,YuhanCui,TianheLin,Xin-\nTechnologies, pages 309–319, Portland, Oregon, taoWang,RuiXu,JiangjieChen,andDeqingYang.\nUSA.AssociationforComputationalLinguistics. 2024. Evaluating character understanding of large\nlanguagemodelsviacharacterprofilingfromfictional\nElaheRahimtoroghi,JiaqiWu,RuiminWang,Pranav works. In Proceedings of the 2024 Conference on\nAnand,andMarilynWalker.2017. Modellingpro- EmpiricalMethodsinNaturalLanguageProcessing,\ntagonistgoalsanddesiresinfirst-personnarrative. In pages8015–8036.\nA ExamplesofUnreliableNarratorTypes newspapers.” As we had never stirred out of our\nhomesbefore,thedemeanourofthemanstruckus\nSamples from the training set are given in Sec-\ndumbwithwonder. Bethetopiceversotrivial,he\ntionsA.1,A.2,A.3. Samplesfromthetestingssets\nwouldquotescience,orcommentontheVedas,or\naregiveninSectionsA.4,A.5,A.6.\nrepeat quatrains from some Persian poet; and as\nwe had no pretence to a knowledge of science or",
    "char_length": 1469
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 31,
    "text": "A.1 Intra-narrationalTrainingSample\ntheVedasorPersian,ouradmirationforhimwent\nVerbalTicsPresent:(Fiction)“Don’tyou’mais’\nonincreasing,andmykinsman,atheosophist,was\nme, sir! I had two trunks—deux troncs—when\nfirmly convinced that our fellow-passenger must\nI got aboard that wabbly old boat at Dover this\nhavebeensupernaturallyinspiredbysomestrange\nmorning, and I’m not going to budge from this\n“magnetism”or“occultpower,”byan“astralbody”\nwharf until I find the other one. Where did you\norsomethingofthatkind. Helistenedtothetritest\nlearnyourFrench,anyway? Can’tyouunderstand\nsayingthatfellfromthelipsofourextraordinary\nwhenIspeakyourlanguage?”\ncompanion with devotional rapture, and secretly\ntookdownnotesofhisconversation. Ifancythat\nExplanation: Defensivetonethroughout. Digres- the extraordinary man saw this, and was a little\nsion: “WheredidyoulearnyourFrenchanyway?” pleasedwithit.”\nA.2 Inter-narrationalTrainingSamples\nExplanation: Thenewfriendcontradictswhatthe\nSameUnreliableNarratorOverTime:(Fiction) narratorbelievesisoccurringintheworld.\n“This is written from memory, unfortunately. If\nA.3 Inter-textualTrainingSamples\nI could have brought with me the material I so\ncarefullyprepared,thiswouldbeaverydifferent Naïf: (Fiction) “They went off and I got aboard\nstory. Whole books full of notes, carefully the raft, feeling bad and low, because I knowed\ncopied records, firsthand descriptions, and the verywellIhaddonewrong,andIseeitwarn’tno",
    "char_length": 1448
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 32,
    "text": "pictures—that’s the worst loss. We had some use for me to try to learn to do right; a body that\nbird’s-eyesofthecitiesandparks; alotoflovely don’tgetstartedrightwhenhe’slittleain’tgotno\nviews of streets, of buildings, outside and in, show—whenthepinchcomesthereain’tnothing\nand some of those gorgeous gardens, and, most tobackhimupandkeephimtohiswork, andso\nimportantofall,ofthewomenthemselves.” he gets beat. Then I thought a minute, and says\ntomyself,holdon;s’poseyou’dadonerightand\nExplanation: The narrator is reflecting back on give Jim up, would you felt better than what you\nevents in the past where narrator has admitted donow? No,saysI,I’dfeelbad—I’dfeeljustthe\nunreliability. There is no indication of change in samewayIdonow. Well,then,saysI,what’sthe\nreliabilityovertime. useyoulearningtodorightwhenit’stroublesome\nto do right and ain’t no trouble to do wrong, and\nOtherCharacterContradiction: (Fiction) “My thewagesisjustthesame? Iwasstuck. Icouldn’t\nkinsman and myself were returning to Calcutta answer that. So I reckoned I wouldn’t bother no\nfromourPujatripwhenwemetthemaninatrain. moreaboutit, butafterthisalwaysdowhichever\nFromhisdressandbearingwetookhimatfirstfor comehandiestatthetime.”\nanup-countryMahomedan,butwewerepuzzledas\nweheardhimtalk. Hediscourseduponallsubjects Explanation: Narrator appears to have made a\nso confidently that you might think the Disposer mistake and has become a foil to a lamentable",
    "char_length": 1432
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 33,
    "text": "ofAllThingsconsultedhimatalltimesinallthat social condition. They clearly do not understand\nHedid. Hithertowehadbeenperfectlyhappy,as thecomplexityoftheirenvironment: “Well,then,\nwedidnotknowthatsecretandunheard-offorces saysI,what’stheuseyoulearningtodorightwhen\nwereatwork,thattheRussianshadadvancedclose it’stroublesometodorightandain’tnotroubleto\ntous,thattheEnglishhaddeepandsecretpolicies, do wrong, and the wages is just the same? I was\nthatconfusionamongthenativechiefshadcome stuck. Icouldn’tanswerthat.”\ntoahead. Butournewly-acquiredfriendsaidwith\naslysmile: “Therehappenmorethingsinheaven Madman: (Fiction) “You lie, cursed dog! What\nand earth, Horatio, than are reported in your a scandalous tongue! As if I did not know that it\nis envy which prompts you, and that here there A.4 Intra-narrationalTestingSample\nis treachery at work—yes, the treachery of the\nVerbalTicsPresent: (Subreddit) “The guy I\nchiefclerk. Thismanhatesmeimplacably;hehas\nbought the truck from patched it together for the\nplottedagainstme,heisalwaysseekingtoinjure\nsale at first small stuff like not vacuuming the\nme. I’ll look through one more letter; perhaps it\nAC system or armrest falling off the door from\nwillmakethematterclearer.”\ndouble sided tape, but then one day the throattle\ngot stuck wide open I pulled it out of gear killed\nExplanation: Narrator uses a frantic voice with theignitionpulledoverripapartthethroattlebody",
    "char_length": 1416
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 34,
    "text": "accusations and exclamation points and seems openandfoundaplasticcapcrammedinthere... I\nmaddened by perceived torture (the second texttheowneraboutitandhesaid“wrongnumber”\ncharacter has said things which the narrator does Iliveinametropolitanareaandhavebeenputting\nnotlike). Thenarratorhasstrongnegativefeelings off transferring title and racking up tolls at first I\ntowardsothersandappearstofeelalienatedfrom was vengefully self righteous but now I’m over\ntherestofthecharacters,includingthechiefclerk. thinkingit. AmItheasshole?”\nExplanation: Exampleofadmissionoffault/bias:\nPícaro: (Fiction) “I grew the greatest artist of\n“Iliveinametropolitanareaandhavebeenputting\nmy time and worked myself out of every danger\noff transferring title and racking up tolls at first\nwithsuchdexterity,thatwhenseveralmoreofmy\nI was vengefully self righteous but now I’m over\ncomradesranthemselvesintoNewgatepresently,\nthinkingit. AmItheasshole?”\nand by that time they had been half a year at the\ntrade, I had now practised upwards of five years,\nA.5 Inter-narrationalTestingSamples\nand the people at Newgate did not so much as\nknow me; they had heard much of me indeed, SameUnreliableNarratorOverTime: (Blog\nandoftenexpectedmethere,butIalwaysgotoff, post) “I got a haircut yesterday and I hate hate\nthoughmanytimesintheextremestdanger.” HATEit! Ikindofgotitdoneonimpulse(imean\nI needed it done anyway) so I wasn’t prepared\nwith photos or anything and I had to flip through",
    "char_length": 1458
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 35,
    "text": "Explanation: Narrator fits picaro with rise/fall\na magazine looking for what i wanted. I wanted\nof fortune and roguish characteristics. Seems\na short version of this basically. Like where the\nto approach problems cleverly and with clear\ntop layer curled into my chin. I found similar\nmotivations.\nenoughhaircutsinamagazineandtoldherwhatI\nwanted. Itlookedfinewetbutitdriedcompletely\nClown:(Fiction)“Therefore, mydearfriendand\nwrong. She cut it way too short in the front and\ncompanion, if you should think me somewhat\nits basically a shorter version of what I just had\nsparing of my narrative on my first setting\nWHICHISNOTWHATIWANTED.Becausemy\nout—bearwithme,—andletmegoon,andtellmy\nhair is f****** THICK so short hair is f******\nstorymyownway:—Or,ifIshouldseemnowand\nPOOFY. And I dunno I just think I look really\nthentotrifleupontheroad,—orshouldsometimes\nstupid now. It’s just completely wrong and I had\nputonafool’scapwithabelltoit,foramomentor\nher layer the back, which by the way, she didn’t\ntwoaswepassalong,—don’tflyoff,—butrather\neven do that right. Just uuuuuugh I should have\ncourteouslygivemecreditforalittlemorewisdom\njust gotten my bangs trimmed or something and\nthanappearsuponmyoutside;—andaswejogon,\nidkIwanttocrynow. AndI’mnotevendepressed\neitherlaughwithme,oratme,orinshortdoany\nabout that. Just being on campus for a week has\nthing,—onlykeepyourtemper.”\nmademefeelsof******shitty. Likeshittierthan\nIfeltshutupinmyroomallsummer. psIrealized",
    "char_length": 1459
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 36,
    "text": "Explanation: Narrator flips the narrative of his I’mscaredtowearlolitaoncampusnow. awesome\npast (“if you should think me somewhat sparing y/y:|”\nofmynarrativeonmyfirstsettingout—bearwith\nme,—andletmegoon,andtellmystorymyown Explanation: Narrator is recounting event from\nway”)andseemsintenttorepackageconflictina the past and demonstrates intra-narrational\nnewlight. unreliabilitywithoutindicatinggrowthorchange\novertime. they talked about it amongst themselves. I told\nthem I don’t understand why they were so angry\nOtherCharacterContradiction: (Review) “I withme. MomaskedmewhichIwouldlikesoI\nstayed at the Monaco-Chicago back in April. toldherifgiventheoptionIwouldlikethering.\nI was in town on business, and the hotel was Weallhavedaughterssoiunderstandwhymy\nrecommendedbyafriendofmine. Havingspenta sisters might also want the ring. However, how\nweekendthere,Ihavenoideawhatmyfriendwas canIbeheldaccountableforthefactthatmymom\ntalkingabout. Thecomplimentarymorningcoffee gavemethefirstchoiceandsoIchoose?\nwas weak; the fitness room was dimly lit; and I AITAHforchoosingtoinherittheringwhenmy\nthoughtI’dhavetohavemyclothesmailedbackto motherspecificallyaskedmewhichitemIwould\nmewhenIusedtheirsupposed’overnight’laundry prefer?”\nserviceforasuitIspilledsomewineon. Myroom\nwas adequate, but nowhere near what I’ve seen Explanation: Thenarrator’sexperienceexposes“a\nelsewhere at this price point. Recent renovation lamentable socialcondition” (sheis dealing with",
    "char_length": 1463
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 37,
    "text": "mustbeslangfor’everythingisstiffandsmellsof aging, possibly even dying, parents and is put in\nindustrialadhesive.’ Themattressinmyroomwas the “awkward and uncomfortable” situation of\nincrediblyfirm,andIsleptpoorly. WhenItravel, choosingherinheritanceinthemidstofbickering\nI expect an experience similar to or better than siblings). Doesournarratorlackthe“experience\nmyexperienceathome. Atmosthotels,Ireceive to fully understand the narrated events or the\nexcellentserviceandcomfortableaccomodations. complexityoftheirenvironment”perourrevised\nThiswasanexceptiontomyusual,andIwon’tbe naif definition? One could say yes. That she\nbackanytimesoon.” is surprised by all this drama suggests this is\nthe first time she is in this situation and so she\nExplanation: The friend who recommended the is inexperienced in this matter. Also, she is\nhotelisincontradictionwiththenarrator. struggling with understanding the complexity\nof her environment (arguing siblings): “I was\ntaken aback because I didn’t even know this was\nA.6 Inter-textualTestingSamples\nan issue with them but apparently they talked\nNaïf: (Subreddit) “My parents are 80 years old. about it amongst themselves. I told them I don’t\nLately they both have been having some health understandwhytheyweresoangrywithme. Mom\nissues and it appears they are finalizing/updating askedmewhichIwouldlikesoItoldherifgiven\ntheir Last Will & Testaments. I, (44f) am the the option I would like the ring.... how can I be",
    "char_length": 1461
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 38,
    "text": "youngestofthreegirls. Earlierthisyearmymother held accountable for the fact that my mom gave\ncameupforavisitandshewasstayingatmyhouse. methefirstchoiceandsoIchoose?”\nDuringherfirstnightshetoldmesomeofthehealth\nissuesmyfatherhasbeenexperiencing. Laterthat Madman: (Blog post) “Today I realized how\nnight she told me she had three items that were much I actually love her, and no not that crazy\nspecial to her (her wedding ring, a painting, and chickthatIfinallygotridof. Iwastalkingonthe\nsome china my father bought in Eqypt when he phonewithherandwehadrunoutofthingstotalk\nwas in the service). I don’t know if its relevant about so I had started singing Lips of an Angel.\nbut they are all worth roughly the same value, a She’doccasionallysingalongbutIdon’tthinkshe\nmodestsum, nothing overthe top. Sheasked me was paying much attention to it. But the whole\nwhich one I would like to inherit when the time damnsongIwaspicturingher. Thelyricsjustkept\ncame. Thewholeconversationwasawkwardand screaming out at me. I mean, not how the song\nuncomfortablebutintheendIselectedthewedding wasintended. Itsreallyabouttwopeoplebreaking\nring. upandthegirlcallingupherexandthey’retalking\nAfewmonthslater, mytwooldersistersandI about how they still have feelings for each other.\nwereoutatabarandthistopiccameup. Apparently But the way I took it in was how her boyfriend\ntheywereangrywithmeaboutchoosingthering. doesn’t like us talking but she kept talking to me",
    "char_length": 1446
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 39,
    "text": "Theysay“Whodoesthat? Whydidyouevenpick anywaysandallthesestupidfeelingsIhaveforher.\none?”. I was taken aback because I didn’t even Idon’tevenknow. I’mjustanidiot,Iguess. Butit\nknow this was an issue with them but apparently gottentothepointIstartedcrying. Ididn’tlether\nknowthatbecauseIalreadymadethingsawkward refusedtotakethegoodie-bag.\nenoughinthepastandIdidn’twanttobringitup\nHe had talked about it with the teacher and let\nagain. Because she only looks at me as a friend\nallofustakeslicesofhiscakeandpasseditaround\nandasmuchasitkillsme...thatsallwe’lleverbe.”\ntoeveryone. IpersonallydislikedcakesoIsaidno,\nalongwithsomefew2or3otherpeople.\nExplanation: Narrator is a madman who demon-\nHeunderstoodwherewewerecomingfromso\nstrateshighemotions. Heseemsmaddenedbythe\nhe didn’t take it to heart. After everyone had en-\nperceived torture of not being able to date a girl\njoyed their cake, the teacher had asked us all to\nhe thinks he is in love with. He has really strong\ngroupuptotakeapicture. Everyonestartedhud-\nfeelingsthatcanaffecthissanity(“Ialreadymade\ndlinginthemiddlebutsinceIdidn’tfeelcomfort-\nthingsawkwardenoughinthepast”).\nabletakingapicturewithabunchofpeople,Ijust\nkeptsittingonmyseatandpolitelyrefusedtotake\nPícaro:(Review)“Iwanttoissueatravel-warning\napicturewiththem.\nto folks who might sign up for the weekend deal\nthey offer through travelzoo from time to time: They just accepted it, it was all good until my",
    "char_length": 1427
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 40,
    "text": "Thedealsays’freebreakfast’includedintheprice. parents scolded me for not taking a picture with\nHowever, what they don’t tell you, is that the them(sincethepicturewaspostedonInstagram)\nbreakfastconsistsofacupofcoffeeandabisquit andshedidn’twanttheotherparentstothinkIwas\n(or two)! Moreover, you need to ask for these rudeorinconsiderate. Shetoldmetoapologizethe\n’tickets’ at the lobby when you check in - they nexttimeIsawhimandIagreed.\nwon’tgivethemtoyouautomatically! Westayed\nTime-skip to the day after, I went up to him\nthere over Christmas ’03, and we, and I noticed\nandapologizedifhethoughtIdidn’tlikehimand\nseveralguestswhoboughtthesamepackage,had\ntoldhimthatIfeltuncomfortablewithcrowdsof\na rather unpleasant experience! The hotel is nice\npeople, as well as accepting things that weren’t\nthough,ifyoudon’tconsidertheirlousyservice!”\nmine. Hedidn’tmindandsaiditwasalright,that\nhe understood how I felt but he said it in a really\nExplanation: The clever vibes stick out to me a\nsadvoicethatbrokemyheart. AITA?”\nlittle bit. Rather than just stating that “travelzoo”\nis lame, the narrator writes “I want to issue a\nExplanation: Narratorisaclownwhore-interprets\ntravel-warning.” Also, the air quotes around free\nthe situation. Instead of considering the events\nbreakfast and tickets also read to me as clever.\nas a time of celebration, the narrator focuses on\nAnd the exclamation, parenthetical, and slyness\nhis/herpersonalviewpoints(e.g.,refusingtotake",
    "char_length": 1456
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 41,
    "text": "in the following sentence also seems to suggest\nthegoodiebagbecausenarratordoesnotliketoac-\ncleverness: “what they don’t tell you, is that\nceptgifts,noteatingcakebecausenarratorperson-\nthe breakfast consists of a cup of coffee and a\nallydislikesit,andnotjoiningtheclassphotobe-\nbisquit (or two)!” The narrator also states in an\ncausenarratordidn’tfeelcomfortableincrowds).\nunderstated way that them and other guests who\nbought this package “had a rather unpleasant\nexperience!” with“rather”suggestingtryingtobe\nB AnnotationStudyDetails\nclevertoo. Andlastly,“Thehotelisnicethough,if\nyoudon’tconsidertheirlousyservice!” feelslike\nthelastbitingremarkattemptingcleverness. Wehire10expertworkerswhoareintheprocessor\nhavecompletedauniversitydegree(honorsbache-\nClown:(Subreddit)“Someguyinclass,whoI’m lor’s,master’s,PhD)inEnglishliteratureandhave\nsort-of close to, had planned his birthday and hadpreviousexperienceanalyzingnarrators. Work-\nwanted to celebrate it with all of us in the class- ersarepaid$7.25/hour(equivalenttothestatemin-\nroom. imumwage). Theyprovidewrittenconsentandun-\nHebroughtusallgoodie-bags,andevenbrought derstandingofthetaskbeforebeginningandmay\nacake. Atfirst,Iwasannoyed. BecauseIthought completeasmanynarrativesastheyareablewithin\nthiswaskindofexcessiveforabirthdaybutIkept asetnumberofhours. Theyarefreetostopatany\nquiet because I didn’t want to hurt his feelings. pointoftheprocess. Duringthestudy,nopersonal",
    "char_length": 1433
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 42,
    "text": "AndsinceIdislikedacceptinggiftsfromothers,I informationiscollectedfromtheannotators.\nB.1 InstructionsforAnnotators (c) Pícaro\nEachannotatorisgivenasetofnarrativesandalist (d) Clown\nofdefinitionsforintra-narrational,inter-narrational, (e) None: inter-textuallyreliable\nandinter-textualunreliabilities(sameasdefinitions\n6. InColumnH,pleaseleaveannotator’snotes.\nandexamplesgiveninSection3). Theyagreenot\nThisisaspaceforanyadditionalcomments\ntouseAIassistantswhilechoosinglabels. Toen-\nyoumighthave. Feelfreetouseitorleaveit\nsure consistency across labeling, annotators are\nblank.\ninstructed:\n“Classify narrators according to the given\nC AnnotatedLabelStatistics\ndefinitions. Focus on characteristics of the\nnarrator,notonthesituationdescribed. Classify\nWereportthedistributionoflabelschosenbythe\nusingdefiningcharacteristicswithinthenarrative\nhuman annotators for each text domain for intra-\nonly. Donotcreatehypotheticalstofillinmissing\nnarrational,inter-narrational,andinter-textualun-\ndetails. Assume the narrator is reliable unless\nreliabilitiesinTable6.\nunreliabletraitsarepresentinthenarrative.”\nD ExperimentalSetup\nAnnotatorsaretaskedwithlabelingeachnarra-\nWe describe licenses of source corpora in Sec-\ntiveinthefollowingsteps:\ntion D.1 and implementation in Section D.2. All\n1. InColumnC,readthenarrative. promptsareprovidedinSectionD.3.\n2. In Column D, list any observed verbal tics D.1 SourceCorporaDetails\n(thisisaspacefornotes,orenteringthecorre-\nWereportthelicenseofeachsourceofnarratives",
    "char_length": 1501
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 43,
    "text": "spondingletter):\nforTUNAinTable7. Alldataisusedforresearch\n(a) Admissionoffault/bias purposes only, consistent with their intended use.\nNarrativeswerecheckedtoensurethereisnoper-\n(b) Defensivetone\nsonally identifying information or offensive con-\n(c) Digressions\ntent. AllsamplesareinEnglish.\n(d) HedgingLanguage\nWe select snippets from the source corpora in\n(e) Inconsistencies\nthefollowingways. Fortrain-testsplits,snippets\n(f) SelectiveMemory areselectedatrandombecausewedesireclassbal-\n(g) StatementofPotentialDisbelief ancesthatarerepresentativeofeachdomain. We\ndo not use LLMs to pre-select snippets because\n3. InColumnE,selectthebestoptionforintra-\nthisprocesswouldmostlikelyfavorsnippetsthat\nnarrational unreliabilities (choose the corre-\nareeasiertoclassifyandwouldnotchoosetrickier\nspondingletter):\nsnippets. Forselectingdemonstrationexamplesin\n(a) Verbaltic(s)present few-shot methods, we acknowledge that a more\ncareful shot selection could potentially help the\n(b) None: intra-narrationallyreliable\nLLMmakebetterpredictions. However,thisselec-\n4. InColumnF,selectthebestoptionforinter- tionprocessrequirescarefulresearchthatanalyzes\nnarrational unreliabilities (choose the corre- narrativesfromtheperspectiveofvariouselements\nspondingletter): like characters, setting, etc. While this would be\na good direction for future work, it is out of the\n(a) Sameunreliablecharacterovertime\nscopeofthecurrentwork.\n(b) Othercharactercontradiction",
    "char_length": 1449
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 44,
    "text": "(c) None: inter-narrationallyreliable D.2 ImplementationDetails\nOur experiments are conducted using up to four\n5. InColumnG,selectthebestoptionforinter-\n48GB Nvidia RTX A6000 GPUs and 2 Nvidia\ntextualunreliabilities(choosethecorrespond-\nA100-80G GPUs. Open-source checkpoints for\ningletter):\nLlama, Mistral, Phi3, BERT, and ModernBERT\n(a) Naïf modelsareobtainedfromHuggingFace(Wolfetal.,\n(b) Madman 2020)library. API-basedGPTmodelsareobtained\nIntra-nar Inter-nar Inter-tex\nCorpus (A) (R) (A) (B) (R) (A) (B) (C) (D) (R)\nFiction 264 235 48 38 413 49 76 64 75 235\nTrain/Valid 180 193 41 31 301 37 59 49 50 178\nTest 84 42 7 7 112 12 17 15 25 57\nBlogposts 75 31 36 6 64 11 23 10 19 43\nSubreddit 97 15 18 63 31 29 28 15 24 16\nReviews 52 48 2 5 93 3 24 7 3 63\nTable6: Labelstatistics(numericalbreakdown)foreachtypeofunreliabilityacrossalltextdomains. Forintra-\nnarrationalunreliabilities: Totalnumberofnarrativeswith(A)verbalticsor(R)none(intra-narrationallyreliable).\nForinter-narrationalunreliabilities: Totalnumberofnarrativeswith(A)“Sameunreliablecharacterovertime”,(B)\n“Othercharactercontradiction”,or(R)none(inter-narrationallyreliable). Forinter-textualunreliabilities: Total\nnumberofnarrativeswith(A)Naïf,(B)Madman,(C)Pícaro,(D)Clown,or(R)none(inter-textuallyreliable).\nCorpora License Alias ModelName Size\nProjectGutenberg ProjectGutenbergLicense Llama3.1-8B meta-llama/\nMeta-Llama-3.1-8B-Instruct 8B\nPersonabank CreativeCommonsAttribution\n4.0InternationalLicense Llama3.3-70B meta-llama/",
    "char_length": 1492
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 45,
    "text": "Llama-3.3-70B-Instruct 70B\nAITA(Vijjinietal.,2024) CreativeCommonsAttribution\n4.0InternationalLicense Mistral-7B mistralai/\nMistral-7B-Instruct-v0.3 7B\nDeceptiveOpinion CreativeCommonsAttribution\n-NonCommercial-ShareAlike Phi3-medium microsoft/\n3.0UnportedLicense Phi-3-medium-4k-instruct 14B\nGPT-4omini gpt-4o-mini-2024-07-18 –\nTable7:Licensesforthesourcesofeachtextualdomain\no3-mini o3-mini-2025-01-31 –\ninTUNA.\nBERT-base google-bert/bert-base-uncased 110M\nModernBERT answerdotai/ModernBERT-base 150M\nfromOpenAIAPI.SeeTable8forcheckpointver-\nsionsandmodelsizes. Forallmodels,weuseatem- Table8: ModelcheckpointsfromHuggingFacelibrary\nperaturevalueof0.7andtop-pvalueof0.9(chosen andOpenAIAPI.\nafter experimentation with higher and lower val-\nues). Themodelo3-minireasoning_levelisleft\nat the default medium level. Inference time for a D.3 PromptsforExperiments\nsingleexperimentonanopensourcemodeltakes\nIn this section, we provide the templates and\napproximately 30 minutes. Fine-tuning a LoRA\nprompts used for zero-shot, one-shot, and three-\n(Huetal.,2022)adapterfor3epochstakesapprox-\nshotsettings.\nimately1hour. TrainingBERTandModernBERT\nmodelsfor3epochstakesapproximately1minute.\nInadditiontoutilizingHuggingFace,PEFT,Py- D.3.1 Templates\nTorchlibrariesformodelinferenceandfine-tuning,\nForzero-shotinference,weusethefollowing:\nwe utilize existing Python packages such as Py-\nTorch, pandas, re, scikit-learn, and statistics for\nZero-ShotTemplate\npre/post-processingofdataandanalysisofresults.",
    "char_length": 1494
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 46,
    "text": "F1(macro)scoresforallmethodsarecalculated ###SYSTEM:[SystemPrompt]\nusing a bootstrapping evaluation method. For a ###PROMPT:[UnreliabilityDefinition]\ntesting set containing m samples, we perform in- [ShotInstruction]\nference on all m samples 5 times to predict the ###INPUT:[Narrative]\nintra-narrational,inter-narrational,andinter-textual ###SOLUTION:\nlabels. Fromthese5runs,1000outputpredictions\narerandomlysampledwithreplacementandcom- For few-shot inference, we include shots after\nparedtothecorrespondinggoldlabels. the shot instruction. We notice best performance\nWeuseAIassistantstoassistwithminordebug- whenwerepeattheshotinstructionasecondtime\ngingandcoding. aftertheshots. Weusethefollowing:\nFew-ShotTemplate anobody. Butlook! Thereisaplanedrawingmy\nnameinthesky.”\n###SYSTEM:[SystemPrompt]\n• SelectiveMemory: Narratoracknowledgesthey\n###PROMPT:[UnreliabilityDefinition]\nmay have forgotten important details or their\n[ShotInstruction]\nmemory is faulty. Examples: “It was so long\n[Shots]\nago,it’shardtoremember”,“Mymemoryisnot\n[ShotInstruction]\nwhatitusedtobe”\n###INPUT:[Narrative]\n• Statement of Potential Disbelief: Narrator ac-\n###SOLUTION:\nknowledgesthenarrativemaysoundunlikely. Ex-\namples: “Youmightnotbelieveme,but”,“what\nD.3.2 SystemPrompts\nhappenednextmightseemstrange”\nWereplace[SystemPrompt]inthetemplateswith\nGiventhislistofverbalticsandanarrative,we\nthecorrespondingsystemprompt:\ndefinethefollowingoptions:\nIntra-narrational: <A>: Verbalticspresentinnarrative",
    "char_length": 1480
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 47,
    "text": "DetermineiftheINPUTnarrativecontainsanyver- <B>: Noverbalticspresentinnarrative\nbaltics.\nInter-narrational:\nInter-narrational:\nWe define the following types of unreliable nar-\nDetermine if the narrator in the INPUT narrative\nratorsbasedonanalternativecharacter’spointof\nisunreliablebasedonanothercharacter’spointof\nview:\nview.\n<A>: Sameunreliablenarratorovertime: Nar-\nInter-textual:\nrator is reflecting on his/her past self,\nDetermine if the narrator in the INPUT narrative\nwhoisunreliable,ANDthepresent-day\nfitsacharactertrope.\nnarratordoesnotindicatechangewithin\nD.3.3 Definitions narrativesnippet.\n<B>: Other character contradiction: Another\nWe replace [Unreliability Definition] in the\ncharacter contradicts narrator who has\nTemplatewiththecorrespondingsetofdefinitions:\ndemonstrated at least one form of intra-\nnarrationalunreliability.\nIntra-narrational:\n<C>: Neither: narratorisreliablefromdiffer-\nHereisalistofverbaltics:\nentcharacters’pointsofview.\n• Admissionoffault/bias: Narratordirectlystates\nInter-textual:\nthathe/shehasmademistakes,hasparticularbi-\nWedefinethefollowingtypesofunreliablenarra-\nases,doesnotknowallthedetails,orisreporting\ntorsbasedoncharactertropes:\ninformationfromanothercharacterwhoislikely\nunreliable. Examples: “Likeothersofmygener- <A>: Naïf: Narrator who is a foil to a\nation...”, “I tend to see things from a particular lamentable social condition and who\npointofview” lacksexperiencetofullyunderstandthe",
    "char_length": 1443
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 48,
    "text": "• Defensivetone: Narratorusesmultiplephrasesin narratedeventsorthecomplexityoftheir\nprotestation. Examples: “Letmemakeperfectly environment. (Defining characteristic:\nclear”,“Ishouldsay”,“Ishouldpointout”,“let Blindtowrongs)\nmemakeitimmediatelyclear”,“IfeelIshould <B>: Madman: Narrator, often with a frantic\nexplain” voice,whofeelsdeeppositiveornegative\n• Digressions: Narrator veers off-topic at least emotionstowardothersandismaddened\nonce. Examples: “I will do that in a minute. byperceivedtortureoralienation. (Defin-\nBytheway,...” ingcharacteristic: Highlyemotional)\n• Hedging language: Narrator uses phrases that <C>: Pícaro: Socially aware rogue or anti-\nindicate uncertainty or vagueness. Examples: hero who experiences the rise and fall\n“it seems that”, “it appears to be”, “I think”, of fortune while attempting to improve\n“maybe”,“sortof” theirprospectsandcunninglyjustifytheir\n• Inconsistencies: Narrator gives contradicting chaoticworldview. (Definingcharacter-\nstatements and/or events don’t add up. “I am istic: Triestobeclever)\n<D>: Clown: Narratorwhooffersreinterpreta- Iwasout-of-doors. Icouldnotremaininthehouse;\ntions that repackage internal and/or ex- it had felt too small for me, but now nature felt\nternalconflictinanewlight,potentially toolarge. Idimlysawthehugepileoftheschloss\nfrombehindafacadethatallowsthemto definedagainstthegraylight;sometimeswhenthe\nsaywhatevertheywant. (Definingchar- moonunveiledherselfitstartedoutclear,andblack,",
    "char_length": 1466
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 49,
    "text": "acteristic: Flipsthenarrative) andgrim. Iheardthewindmoanamongthetrees,\n<E>: None: Narratorisreliablebasedonchar- heardthegreatdogsbayingfromthekennels;from\nactertropes. an open window came rich, low, mellow sounds.\nOld Brunken was in the music-room, playing to\nD.3.4 Instruction\nhimselfuponthevioloncello.\nWereplace[Shot Instruction]intheTemplate SOLUTION2: <B>\nwiththecorrespondinginstruction:\nIntra-narrational:Doesthenarrativedemonstrate Inter-narrational:INPUT1: InduetimeIfound\nanyverbaltics? DONOTGIVEANYDESCRIP- my ghost, or ghosts rather, for there were two of\nTION.GenerateONLYTHECORRESPONDING them. UptillthathourIhadsympathizedwithMr.\nLETTER enclosed in angle brackets (’<A>’ or Besant’s method of handling them, as shown in\n’<B>’). “The Strange Case of Mr. Lucraft and Other Sto-\nInter-narrational:Whattypeofnarratorisgiven? ries.”IamnowintheOpposition. Wewillcallthe\nDONOTGIVEANYDESCRIPTION.Generate bungalowKatmaldâk-bungalow. ButTHATwas\nONLY THE CORRESPONDING LETTER en- thesmallestpartofthehorror. Amanwithasensi-\nclosed in angle brackets ([List of possible letters tivehidehasnorighttosleepindâk-bungalows. He\nenclosedinanglebrackets]). shouldmarry. Katmaldâk-bungalowwasoldand\nInter-textual: What type of narrator is given? rottenandunrepaired. Thefloorwasofwornbrick,\nDONOTGIVEANYDESCRIPTION.Generate thewallswerefilthy,andthewindowswerenearly\nONLY THE CORRESPONDING LETTER en- blackwithgrime. Itstoodonabypathlargelyused",
    "char_length": 1442
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 50,
    "text": "closedinanglebrackets(’<A>’or’<B>’or’<C>’ bynativeSub-DeputyAssistantsofallkinds,from\nor’<D>’or’<E>’). FinancetoForests;butrealSahibswererare. The\nkhansamah,whowasnearlybentdoublewithold\nD.3.5 Shots\nage,saidso.\nIn this section we show one example shot per SOLUTION1: <A>\nlabel. Duringinference,wereplace[Shots]inthe INPUT 2: “I suppose you would like to take\nTemplatewithoneorthreeshotsperlabel: themtotheCasinotoplayroulette? Well,excuse\nmyspeakingsoplainly,butIknowhowaddicted\nIntra-narrational: youaretogambling. ThoughIamnotyourmentor,\nINPUT1: Thisiswrittenfrommemory,unfortu- nor wish to be, at least I have a right to require\nnately. IfIcouldhavebroughtwithmethematerial that you shall not actually compromise me.” “I\nI so carefully prepared, this would be a very dif- have no money for gambling,” I quietly replied.\nferentstory. Wholebooksfullofnotes,carefully “Butyouwillsoonbeinreceiptofsome,”retorted\ncopiedrecords,firsthanddescriptions,andthepic- theGeneral,reddeningalittleashedivedintohis\ntures—that’stheworstloss. Wehadsomebird’s- writingdeskandappliedhimselftoamemorandum\neyesofthecitiesandparks; alotoflovelyviews book. From it he saw that he had 120 roubles of\nof streets, of buildings, outside and in, and some mine in his keeping. “Let us calculate,” he went\nofthosegorgeousgardens,and,mostimportantof on. “Wemusttranslatetheseroublesintothalers.\nall, of the women themselves. Nobody will ever Here—take100thalers,asaroundsum. Therest",
    "char_length": 1454
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 51,
    "text": "believehowtheylooked. Descriptionsaren’tany will be safe in my hands.” In silence I took the\ngood when it comes to women, and I never was money.\ngood at descriptions anyhow. But it’s got to be SOLUTION2: <B>\ndonesomehow;therestoftheworldneedstoknow INPUT 3: “I heard the sound of a stick and a\naboutthatcountry. shamblingstepontheflagsinthepassageoutside,\nSOLUTION1: <A> and the door creaked on its hinges as a second\nINPUT 2: It was a wild night. Driving clouds oldmanentered,morebent,morewrinkled,more\nkepthidingandrevealingthestormy-lookingmoon. agedeventhanthefirst. Hesupportedhimselfby\nasinglecrutch,hiseyeswerecoveredbyashade, ofmynarrativeonmyfirstsettingout—bearwith\nandhislowerlip,half-averted,hungpaleandpink me,—andletmegoon,andtellmystorymyown\nfromhisdecayingyellowteeth. Hemadestraight way:—Or, if I should seem now and then to tri-\nforanarm-chairontheoppositesideofthetable, fleupontheroad,—orshouldsometimesputona\nsatdownclumsily,andbegantocough. Theman fool’scapwithabelltoit,foramomentortwoas\nwiththewitheredarmgavethisnew-comerashort wepassalong,—don’tflyoff,—butrathercourte-\nglanceofpositivedislike;theoldwomantookno ouslygivemecreditforalittlemorewisdomthan\nnotice of his arrival, but remained with her eyes appears upon my outside;—and as we jog on, ei-\nfixedsteadilyonthefire.” ther laugh with me, or at me, or in short do any\nSOLUTION3: <C> thing,—onlykeepyourtemper.\nSOLUTION4: <D>\nInter-textual:INPUT1: TheywentoffandIgot INPUT 5: I first heard of Ántonia on what",
    "char_length": 1491
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 52,
    "text": "aboard the raft, feeling bad and low, because I seemedtomeaninterminablejourneyacrossthe\nknowed very well I had done wrong, and I see great midland plain of North America. I was ten\nitwarn’tnouseformetotrytolearntodoright; yearsoldthen;Ihadlostbothmyfatherandmother\nabodythatdon’tgetstartedrightwhenhe’slittle withinayear,andmyVirginiarelativesweresend-\nain’t got no show—when the pinch comes there ing me out to my grandparents, who lived in Ne-\nain’t nothing to back him up and keep him to his braska. I travelled in the care of a mountain boy,\nwork,andsohegetsbeat. ThenIthoughtaminute, Jake Marpole, one of the ‘hands’ on my father’s\nandsaystomyself, holdon; s’poseyou’dadone oldfarmundertheBlueRidge,whowasnowgoing\nright and give Jim up, would you felt better than Westtoworkformygrandfather. Jake’sexperience\nwhat you do now? No, says I, I’d feel bad—I’d oftheworldwasnotmuchwider.\nfeeljustthesamewayIdonow. Well,then,says SOLUTION5: <E>\nI,what’stheuseyoulearningtodorightwhenit’s\ntroublesometodorightandain’tnotroubletodo E AdditionalDetailsAboutClassification\nwrong,andthewagesisjustthesame? Iwasstuck. Results\nI couldn’t answer that. So I reckoned I wouldn’t\nWe show class-wise performance for combined\nbother no more about it, but after this always do\ntest domains in Table 9 and performance break-\nwhichevercomehandiestatthetime.\ndowns for each textual domain (akin to Table 3)\nSOLUTION1: <A>\nusing the remaining LLMs: Llama3.3-70B (Ta-\nINPUT 2: You lie, cursed dog! What a scan-",
    "char_length": 1491
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 53,
    "text": "ble10),Mistral-7B(Table11),Phi3-medium(Ta-\ndaloustongue! AsifIdidnotknowthatitisenvy\nble12),GPT-4omini(Table13),ando3-mini(Ta-\nwhichpromptsyou,andthatherethereistreachery\nble14). Furthermore,weprovideanerroranalysis\natwork—yes,thetreacheryofthechiefclerk. This\nof the classification tasks (Appendix E.1), exam-\nman hates me implacably; he has plotted against\nples showing how different tasks have different\nme, he is always seeking to injure me. I’ll look\ncomplexities(AppendixE.2),andexamplesofhow\nthroughonemoreletter;perhapsitwillmakethe\nLLMlearnfromsnippetstomakebetterpredictions\nmatterclearer.\n(AppendixE.3).\nSOLUTION2: <B>\nINPUT3: Igrewthegreatestartistofmytime\nE.1 ErrorsClassifyingUnreliableNarrators\nandworkedmyselfoutofeverydangerwithsuch\ndexterity,thatwhenseveralmoreofmycomrades WeanalyzetheLLMclassificationsbygenerating\nranthemselvesintoNewgatepresently,andbythat explanations(i.e.,weprompttheLLMstoexplain\ntime they had been half a year at the trade, I had theirchoices)andmakethefollowingobservations\nnowpractisedupwardsoffiveyears,andthepeople aboutincorrectlyclassifiedunreliablenarrators.\natNewgatedidnotsomuchasknowme;theyhad Forintra-narrationalunreliability,theLLMover-\nheardmuchofmeindeed,andoftenexpectedme predictsthepresenceofhedginglanguageandde-\nthere, butIalwaysgotoff, thoughmanytimesin fensivelanguageandisoverly-sensitivetophrases\ntheextremestdanger. thatannotatorsdonotclassifyaseitherverbaltic.\nSOLUTION3: <C> TheLLMalsostrugglestorecognizedigressions.",
    "char_length": 1488
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 54,
    "text": "INPUT 4: Therefore, my dear friend and com- Insomecases,theLLMstatesaverbalticbutmis-\npanion,ifyoushouldthinkmesomewhatsparing takenlydeterminesthatitisnotstrongenoughto\nclassifyasanunreliability. Intra-narrationalPrediction: A\nForinter-narrationalunreliability,theLLMtends Intra-narrationalGoldLabel: A\nto overpredict “other character contradiction” by Why? Themodeleasilyfindsatleastoneverbal\nanticipatinganothercharactermightcontradictthe tic (e.g., inconsistency in the first two sentences,\nnarratorwithoutexplicitevidencewithinthecon- hedginglanguage, admissionoffault/bias)inthe\ntext. Sometimes the LLM considers instances narrative.\nwhere the narrator contradicts themself or seems\nmanipulativeas“othercharactercontradiction.” Inter-textualPrediction: E\nFor inter-textual unreliability, the LLM strug- Inter-textualGoldLabel: D\ngles with ambiguous samples (i.e., samples that Why? Themodelmissescontextualinformation\ncontaincharacteristicsofmultipletypesofunreli- scatteredthroughoutthenarrativethatindicatesthe\nabilities). For these samples, the LLM seems to narratorisbouncingbetweenconflictinginterpreta-\nover-emphasize characteristics of less dominant tionsofgettingaspeedingticket.\nunreliabilities. Forexample,theLLMoftenover-\nE.3 EffectofLearningfromExamples\npredicts Madman for samples where the narrator\ndescribesemotions. Ontheotherhand,theLLM In this section, we show one sample for each\nsometimes ignores characteristics of a Madman type of unreliability where the model predicts an",
    "char_length": 1501
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 55,
    "text": "notedbytheannotatorsiftheLLMdescribesother incorrect label in the zero-shot setting, and the\nminorattributescorrespondingtoanotherunrelia- modellearnsfromexamplesinthefew-shotsetting\nbility. topredictthecorrectlabel.\nE.2 DemonstrationofTaskComplexities\nIntra-narrational: (Subreddit) “I’m (21M) a ju-\nThe following example demonstrates how the nior at an Ivy League school that gets really into\nintra-narrational task is more easily predicted holidays,andthestudentsocialcommitteespends\nby analyzing relatively explicit instances of atonofmoneyonthrowingHalloweenevents.\nverbal tics than the inter-textual task. We note Inparticular,there’sgoingtobeamassive,very\nthat the inter-textual task is more challenging expensive-to-hostsquidgameparty. It’sgoingto\nbecauseitrequiresadeeperunderstandingofthe besuperfancywithsquidgameconsumesandreal\nnarrator’sframe-of-thoughtandsituation. Model life-sizegamesandawesomefood,andthebudget\nresultsarefromtheCLmethodusingLlama3.1-8B. ishuge.\nIaskedforamuchsmalleramountforasimple\nBlog post: “I got pulled over this morning!! masqueradepartymyclubisthrowing. Everyoneis\nErr... Yesterday morning... On my way back to extremelyannoyedwithmefor“siphoningcommit-\nOwings Mills for my sorority retreat deal. Yeah. teefunds”awayfromthesquidgameparty. ButI\nTotallydidn’tnoticethecopslikeIusuallydo,and barelyaskedforanythingcomparedtowhatthey’re\napparently flew past him doing 85. And I didn’t spending. Idon’tseethebigdeal. Myfriendplan-",
    "char_length": 1467
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 56,
    "text": "slowdownwhenIgotto695(theyreallyneedto ningthesquidgamepartyisparticularlyirate.”\nupthespeedlimitto65overthereIswear),sohe 0-ShotPrediction: B\naskedmewhatmyexcusewas. ’Idon’thaveone 1-ShotPrediction: A\nSir.’ ’License and registration please.’ I sit there, GoldLabel: A\nwaiting for the ticket. He hands me everything Why? There are many examples of hedging\nback and says Slow down. That’s way too fast. language: “gets really into holidays”, “spends\nHave agood day.’ ’... You too officer.’ Yeah. So a ton of money”, “going to be a massive, very\nnever going over 65 on 695 ever again. Cruise expensive”,“superfancy”,“muchsmalleramount”\ncontrol... Buddy... howyoudoin? Toldmomand\ndad I was doing 70 in a 55 they said if I get a Inter-narrational: (Review) “I stayed at the\nticket,I’llmorethanlikelynothavecarinsurance. Monaco-Chicago back in April. I was in town\nGah. Either way, no more than 10 above. Doing on business, and the hotel was recommended by\nthe SPEED limit on the highways around here is a friend of mine. Having spent a weekend there,\ndangerous man. People almost hit me like, three I have no idea what my friend was talking about.\ntimeson695.” Thecomplimentarymorningcoffeewasweak;the\nfitnessroomwasdimlylit;andIthoughtI’dhave\nLlama3.1-8B (A) (B) (C) (D) (E)\nCL Intra-nar 69.67±1.02 50.30±1.54 – – –\nInter-nar 2.90±1.25 39.36±2.16 78.21±0.82 – –\nInter-tex 10.96±2.17 14.90±1.98 15.66±2.50 11.84±1.91 57.24±1.18\nFT Intra-nar 59.84±1.18 48.87±1.33 – – –",
    "char_length": 1465
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 57,
    "text": "Inter-nar 6.89±1.86 20.00±2.18 80.16±0.75 – –\nInter-tex 4.49±1.70 16.08±1.93 10.07±2.28 16.81±2.13 59.59±1.12\nZero-shot Intra-nar 29.77±1.40 5.80±1.22 – – –\nInter-nar 6.73±1.74 20.69±2.05 10.46±1.03 – –\nInter-tex 12.75±1.98 2.47±1.01 4.68±1.87 1.62±0.92 16.43±1.55\nOne-shot Intra-nar 29.56±1.37 7.38±1.35 – – –\nInter-nar 9.26±1.83 16.23±2.03 11.99±1.13 – –\nInter-tex 16.57±2.38 10.25±1.87 3.37±1.68 4.52±1.44 20.31±1.72\nThree-shot Intra-nar 30.03±1.34 4.52±1.09 – – –\ninter-nar 10.29±1.98 15.66±2.02 12.84±1.14 – –\ninter-tex 17.41±2.21 2.52±1.01 9.02±2.38 2.17±1.06 14.75±1.52\nTable9:Class-wiseF1(macro)scoresforcombinedtestdomainsforLlama3.1-8B.Forintra-nar:(A)→verbaltics,\n(B)→none. Forinter-nar: (A)→“Sameunreliablecharacterovertime”,(B)→“Othercharactercontradiction”,\n(C)→none. Forinter-texunreliabilities: (A)→Naïf,(B)→Madman,(C)→Pícaro,(D)→Clown,(C)→none.\nWemakethefollowingobservations: Forintra-nar,CLandFTmethodsimprovetheperformanceofbothclasses.\nForinter-nar,multi-shotsettingimprovesperformancefor‘sameunreliablenarratorovertime’andReliable;CL\nandFTimproves‘othercharactercontradiction’andReliable. Forinter-tex,CLandFTsubstantiallyimproves\nperformanceforMadman,Picaro,Clown,andReliable.\nLlama3.3-70B CL Fine-tuned Zero-Shot One-Shot Three-Shot\nIntra-nar Fiction 54.74±2.03 54.72±1.96 45.90±1.72 64.56±1.92 62.94±2.14\nBlogpost 49.34±2.22 49.48±2.13 53.04±2.33 64.65±2.26 62.74±2.22\nSubreddit 44.55±1.96 44.54±2.00 46.37±0.42 56.44±2.94 47.16±1.26",
    "char_length": 1459
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 58,
    "text": "Review 56.39±2.26 56.37±2.26 71.51±2.11 69.91±2.01 72.82±2.01\nInter-nar Fiction 43.47±3.21 35.81±2.39 27.48±2.41 23.40±1.58 24.23±1.72\nBlogpost 30.61±1.95 25.68±0.68 26.70±1.22 40.72±2.01 45.74±2.78\nSubreddit 28.57±3.50 27.84±1.88 28.27±1.32 31.38±1.90 28.29±1.81\nReview 31.32±0.57 31.94±0.22 33.98±1.59 29.44±1.41 37.84±2.60\nInter-tex Fiction 23.45±1.75 23.42±1.67 29.83±1.91 32.59±1.90 31.95±1.83\nBlogpost 24.63±1.83 24.61±1.76 35.64±2.29 42.54±2.39 33.63±2.05\nSubreddit 13.43±1.38 13.46±1.40 19.68±2.32 27.53±1.99 19.40±1.47\nReview 22.66±1.81 22.61±1.75 28.94±1.32 20.55±0.97 27.93±2.20\nTable10: BreakdownofunreliabilityF1(macro)scoresforeachdomainusingLlama3.3-70B.\ntohavemyclothesmailedbacktomewhenIused GoldLabel: B\ntheir supposed ’overnight’ laundry service for a\nWhy? Thefriendwhorecommendedthehotelis\nsuit I spilled some wine on. My room was ade-\nincontradictionwiththenarrator.\nquate,butnowherenearwhatI’veseenelsewhere\natthispricepoint. Recentrenovationmustbeslang\nInter-textual: (Blog post) “So last week, my 95\nfor’everythingisstiffandsmellsofindustrialad-\nyearoldGrandfatherfellandcrackedhisvertebrae..\nhesive.’ Themattressinmyroomwasincredibly\nLongstoryshort,itwasaroughroadlastweekwith\nfirm,andIsleptpoorly. WhenItravel,Iexpectan\ndr.ssayingthathewasluckytobealiveandtoday\nexperiencesimilartoorbetterthanmyexperience\nI receive a phone call from my sister saying that\nathome. Atmosthotels,Ireceiveexcellentservice\nhis kidneys had failed and that my Grandmother",
    "char_length": 1475
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 59,
    "text": "andcomfortable accomodations. Thiswas anex-\nandaunts,unclesandfatherhadmadethedecision\nceptiontomyusual,andIwon’tbebackanytime\ntopullhislifesupport(hehasbeenunresponsive\nsoon.”\na day after it happened). While we live 6 hours\n0-ShotPrediction: B\nawaynow-Iusedtoliveinthesametownasallof\n1-ShotPrediction: A myfamilyuntilIwentawaytocollege.. EVERY\nMistral CL Fine-tuned Zero-Shot One-Shot Three-Shot\nIntra-nar Fiction 54.66±2.06 56.76±2.04 54.91±2.13 49.74±1.98 53.36±2.08\nBlogpost 54.21±2.19 56.79±2.17 54.89±2.19 54.19±2.29 49.34±2.20\nSubreddit 46.43±0.41 49.92±2.12 48.83±1.80 47.20±1.33 51.54±2.51\nReview 67.73±2.14 62.35±2.13 68.54±2.06 52.34±2.24 57.73±2.17\nInter-nar Fiction 22.16±1.02 31.37±0.24 12.28±1.38 30.79±2.01 28.97±1.87\nBlogpost 38.73±1.42 25.07±0.54 18.63±1.60 35.70±1.93 33.06±1.63\nSubreddit 33.14±1.92 14.41±0.78 25.66±1.15 37.88±2.18 30.96±1.99\nReview 30.58±1.44 32.12±0.20 21.38±1.30 27.91±1.55 32.18±1.95\nInter-tex Fiction 32.43±2.02 29.89±1.69 21.76±1.75 19.35±1.56 18.80±1.49\nBlogpost 36.59±2.25 28.15±1.75 22.74±1.70 22.28±1.82 19.29±1.65\nSubreddit 22.53±1.80 9.08±0.92 15.78±1.50 16.03±1.49 13.29±1.27\nReview 27.15±1.98 30.40±0.82 20.63±1.08 15.73±0.84 17.11±0.97\nTable11: BreakdownofunreliabilityF1(macro)scoresforeachdomainforMistral-7B.\nPhi CL Fine-tuned Zero-Shot One-Shot Three-Shot\nIntra-nar Fiction 64.14±1.93 43.53±1.88 62.56±2.04 46.56±1.86 45.91±1.76\nBlogpost 53.42±2.23 36.93±2.46 55.37±2.25 43.71±1.52 46.31±1.88",
    "char_length": 1449
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 60,
    "text": "Subreddit 51.18±2.37 59.34±3.03 51.82±2.54 47.71±1.37 46.26±0.42\nReview 46.26±2.03 68.94±2.07 70.25±2.06 40.82±2.01 40.97±1.89\nInter-nar Fiction 29.41±2.30 46.54±2.75 18.45±1.55 13.65±1.45 16.08±1.39\nBlogpost 13.34±1.17 28.77±1.24 26.81±1.74 26.55±1.83 26.41±1.76\nSubreddit 23.62±1.18 31.35±1.41 25.16±1.12 28.53±1.81 27.93±1.69\nReview 22.89±1.32 36.38±1.84 30.49±3.10 24.94±1.73 28.20±2.06\nInter-tex Fiction 27.24±1.63 34.01±1.96 23.90±1.44 14.39±1.39 13.55±1.43\nBlogpost 26.62±1.40 30.90±2.11 28.42±1.78 20.37±1.68 18.38±1.42\nSubreddit 17.94±1.31 16.36±1.40 22.21±1.65 18.36±1.60 15.90±1.54\nReview 28.20±1.70 23.69±1.80 35.70±1.92 22.23±2.69 17.78±1.11\nTable12: BreakdownofunreliabilityF1(macro)scoresforeachdomainusingPhi3-medium.\nSundaywasspentatmyGrandparentshouseandI give all prompts used for inferring the properties\nhavesomanymemoriesofhimwhenIwasakid. ofnarratives(SectionF.1)andadditionalanalysis\nButIthinkthehardestpartformeismythinkingof results for Llama3.3-70B, Mistral-7B, and Phi3-\nmyGrandmotherandIwonder,Howdoyoudoit? medium(SectionF.3).\nHowdoyousaygoodbye? Howdoyoukissyour\nF.1 Prompts\nloveslipsforthelasttimeandknowthatyouwill\nneverbeabletodothatagain? Howdoyoushare Forouranalysisexperiments,wepromptLlama3.3-\nyourwholelifewithsomeonegothroughwars,6 70Bwiththefollowing:\nkidsandover50yearsandtheninonemomentitis\nAnalysisTemplate\nallgone. MyprayersarewithherbecauseIdon’t\nknowhowshecandothis” ###PROMPT:Considerthenarrative.\n0-ShotPrediction: E [RQ#]",
    "char_length": 1472
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 61,
    "text": "1-ShotPrediction: B ###INPUT:[Narrative]\n###SOLUTION:Finallabel:\nGoldLabel: B\nWhy? Narratorisamadmanbecauseofthestrong\nForeachresearchquestion,wereplace[RQ#]in\nemotions described at the loss of the grandfather.\ntheAnalysisTemplatewithoneofthefollowing:\nNarratorseemstofeeldeeppositiveemotionsfor\nthegrandparents • RQ1: Is the narrator female, male, other, or\nambiguous? STATE ONLY THE GENDER\nF DetailsofAnalysis ASALABEL.\nIn this section, we give additional information • RQ2: Isthestyleofnarration“conversational”\nabouthowweautomaticallydetermineproperties or“descriptive”? For“conversational”thenar-\nofthenarrativesfortheanalysisinSection6. We ratorischattytothereader. For“descriptive”\nGPT-4omini Zero-Shot One-Shot Three-Shot\nIntra-nar Fiction 45.48±1.90 56.29±2.03 54.66±2.11\nBlogpost 55.03±2.20 46.65±1.90 44.40±1.74\nSubreddit 49.33±2.14 46.97±0.38 54.71±2.85\nReview 41.67±1.96 52.12±2.37 53.31±2.29\nInter-nar Fiction 33.27±2.62 38.38±2.77 23.95±2.18\nBlogpost 23.81±1.23 25.42±1.28 22.14±1.05\nSubreddit 27.35±1.18 30.75±1.43 30.51±1.50\nReview 28.15±0.94 31.46±1.31 27.41±1.34\nInter-tex Fiction 21.07±1.51 28.00±1.95 26.22±1.86\nBlogpost 21.66±1.77 29.06±2.09 24.21±1.99\nSubreddit 11.90±1.17 9.81±1.31 13.81±1.35\nReview 16.73±1.17 15.75±0.32 15.69±0.32\nTable13: BreakdownofunreliabilityF1(macro)scoresforeachdomainusingGPT-4omini.\nZero-Shot One-Shot Three-Shot\nIntra-nar Fiction 41.84±1.93 45.07±1.96 43.08±1.97\nBlogpost 47.28±2.23 47.45±2.15 49.60±2.18\nSubreddit 39.87±1.79 42.12±1.94 42.70±1.97",
    "char_length": 1501
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 62,
    "text": "Review 39.89±1.91 39.25±1.96 41.88±2.03\nInter-nar Fiction 35.13±1.84 32.33±1.42 31.57±1.19\nBlogpost 27.20±1.63 23.83±0.62 24.94±1.25\nSubreddit 30.35±1.43 26.87±1.40 26.39±1.44\nReview 36.02±2.71 32.12±0.20 32.16±0.20\nInter-tex Fiction 21.99±1.73 22.81±1.68 22.85±1.85\nBlogpost 21.66±1.72 16.16±1.37 22.48±1.71\nSubreddit 13.88±1.69 14.13±1.55 16.13±1.65\nReview 16.65±1.14 15.44±0.33 17.84±1.54\nTable14: BreakdownofunreliabilityF1(macro)scoresforeachdomainusingo3-mini.\nthenarratorprimarilydescribesthesettingor For style, in general, if a narrative begins with\nsituation. STATEONLYTHESTYLEASA description of the narrator or if the sample con-\nLABEL. tainsobviousverbaltics(e.g.,multipleexamples\nofhedginglanguage),thesampleistypicallyclas-\n• RQ3: Isthenarrationtoneprimarily“positive”\nsifiedbytheLLMasconversational.\nor “negative” or “neutral”? STATE ONLY\nForsentiment,sometimestheLLMpredictsthe\nTHETONEASALABEL.\nwrongsentimentifthenarratorspeakssarcastically.\n• RQ4: Including the narrator, how many ex-\nF.3 AnalysisResultswithOtherModels\nplicit characters play a role in the narrative?\nInthissection, weprovideadditionalanalysisre-\nSTATE ONLY THE NUMBER OF CHAR-\nsultsforLlama3.1-8B,Mistral,andPhifornarrator\nACTERSASANINTEGERLABEL.\ngender (Figure 5), narrative style (Figure 6), nar-\nF.2 ErrorsPromptingforAnalysis\nrative tone (Figure 7), and number of characters\nWe hand-verify 200 narratives to ensure the in- (Figures8,9).\nferred properties of narratives are comparable to",
    "char_length": 1477
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 63,
    "text": "humanjudgement. Weobservefewerthan15mis-\nclassifications(minimumaccuracyof92.50%)for\neachtaskandnoticethefollowing.\nForgender,somenarratorswithambiguousgen-\ndersareincorrectlypredictedMaleorFemaledue\ntocontextcluescreatingbiasforthatgender(e.g.,\nambiguousnarratorironingasuitispredictedMale,\nor ambiguous narrator getting mani/pedi is pre-\ndictedFemale).\nFigure7: Breakdownofcorrectlypredicted(green)vs.\nFigure5: Breakdownofcorrectlypredicted(green)vs.\nincorrectly predicted (blue) unreliable narrators with\nincorrectly predicted (blue) unreliable narrators with\nrespecttonarrativesentimenttone∈{positive,negative,\nrespecttothenarrator’sgender∈{female,male,other}.\nneutral}. ResultsarefromLlama3.1-8B(toprow),Mis-\nResultsarefromLlama3.1-8B(toprow),Mistral(mid-\ntral(middlerow),andPhi(bottomrow)experiments.\ndlerow),andPhi(bottomrow)experiments.\nFigure 8: Number of characters vs. number of sam-\nFigure6: Breakdownofcorrectlypredicted(green)vs. ples (Llama3.1-8B experiments). All Samples (solid\nincorrectlypredicted(blue)unreliablenarratorswithre- black)isthedistributionofallnarrativeswithrespect\nspecttonarrativestyle∈{conversational,descriptive}. tothenumberofcharacters. Blue, green, andorange\nResultsarefromLlama3.1-8B(toprow),Mistral(mid- solidlinesshowcorrectpredictions,andcorresponding\ndlerow),andPhi(bottomrow)experiments. dashedlinesshowincorrectpredictions.\nFigure9: Numberofcharactersvs. numberofsamples\n(Phiexperiments). AllSamples(solidblack)isthedis-",
    "char_length": 1467
  },
  {
    "paper_id": "classify_narrator_with_llms",
    "chunk_id": 64,
    "text": "tributionofallnarrativeswithrespecttothenumberof\ncharacters. Blue,green,andorangesolidlinesshowcor-\nrectpredictions,andcorrespondingdashedlinesshow\nincorrectpredictions.",
    "char_length": 170
  }
]