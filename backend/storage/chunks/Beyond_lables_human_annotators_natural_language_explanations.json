[
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 0,
    "text": "Beyond Labels: Empowering Human Annotators with Natural Language\nExplanations through a Novel Active-Learning Architecture\nBingshengYao IshanJindal LucianPopa\nRensselaerPolytechnicInstitute IBMResearch IBMResearch\nYannisKatsis SayanGhosh LihongHe\nIBMResearch UNCChapelHill IBMResearch\nYuxuanLu ShashankSrivastava YunyaoLi†\nNortheasternUniversity UNCChapelHill Apple\nJamesHendler DakuoWang∗\nRensselaerPolytechnicInstitute NortheasternUniversity\nAbstract\nReal-world domain experts (e.g., doctors)\nrarely annotate only a decision label in their\nday-to-dayworkflowwithoutprovidingexpla-\nnations. Yet, existing low-resource learning\ntechniques,suchasActiveLearning(AL),that\naimtosupporthumanannotatorsmostlyfocus\nonthelabelwhileneglectingthenaturallan-\nguageexplanationofadatapoint. Thiswork\nproposes a novel AL architecture to support\nexperts’ real-world need for label and expla-\nnation annotations in low-resource scenarios.\nOurALarchitectureleveragesanexplanation-\ngeneration model to produce explanations\nguided by human explanations, a prediction\nmodelthatutilizesgeneratedexplanationsto-\nward prediction faithfully, and a novel data\ndiversity-based AL sampling strategy that\nbenefitsfromtheexplanationannotations. Au-\ntomated and human evaluations demonstrate\ntheeffectivenessofincorporatingexplanations\nFigure 1: Our dual-model AL system architecture at\nintoALsamplingandtheimprovedhumanan-\nnotationefficiencyandtrustworthinesswithour everyiteration: 1)theALdataselectorchoosesafew",
    "char_length": 1485
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 1,
    "text": "unlabeled examples; 2) human annotators provide an\nALarchitecture. Additionalablationstudiesil-\nexplanationandlabelforeachdatainstance;3)theanno-\nlustrate the potential of our AL architecture\ntatedexplanationsareusedtofinetunetheexplanation-\nfor transfer learning, generalizability, and in-\ngenerationmodel;4)theannotatedlabelsandgenerated\ntegrationwithlargelanguagemodels(LLMs).\nexplanationsareusedtofinetunethepredictionmodel.\nWhileLLMsexhibitexceptionalexplanation-\nThen,humanscanreviewthepredictedlabelsandgen-\ngeneration capabilities for relatively simple\ntasks,theireffectivenessincomplexreal-world eratedexplanationsforunlabeleddataandstartthenext\niteration. Greenarrowsindicatethetrainingtarget.\ntaskswarrantsfurtherin-depthstudy.\n1 Introduction 2021)demonstrateastonishingperformanceonvar-\nious NLP tasks, including Question Answering\nState-of-the-art(SoTA)languagemodels(Devlin (QA) and Question Generation (QG) (Rajpurkar\net al., 2019; Radford et al., 2019; Winata et al., et al., 2016; Duan et al., 2017; Kocˇiský et al.,\n2018; Yao et al., 2022), Natural Language Infer-\n∗†d.wang@northeastern.edu Corresponding Author.\nWorkdonewhileYunyaowasatIBMResearch. ence (NLI) (Bowman et al., 2015; Wang et al.,\n3202\ntcO\n32\n]LC.sc[\n2v01721.5032:viXra\n2018), etc. Despite the superior generative capa- 2)Apredictionmodelthatacceptsthedatacon-\nbilities, the lack of faithful explainability within tentandthegeneratedexplanationsforprediction.",
    "char_length": 1443
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 2,
    "text": "these“blackboxes”mayleadtomistrustoftheir We integrate AL to reduce human annotation\npredictions(Lipton,2018),wherehumans,onthe effortsandestablishhumantrustworthinessbyac-\notherhand,candevelopintermediaterationalesto tivelyengaginghumansinthetrainingprocess. We\nfacilitatethedecision-makingprocess. design a novel data diversity-based AL sampling\nstrategytoselectthemostrepresentativeexamples\nThelackofexplainabilityanduntrustworthiness\nby exploiting the explanation annotations, which\nofmodelsismagnifiedintherealworld(Drozdal\nis analogous to the prevalent core-set (Sener and\netal.,2020),wheredomainexpertsrarelyonlyan-\nSavarese,2017)strategy. OurALarchitectureaims\nnotateadecisionlabelintheirdailyworkflowwith-\ntosupportlow-resourcemodelpredictionsandAI\noutprovidingexplanations(i.e.,clinicaldiagnoses\ntrustworthinessbyexplicitlygeneratingnaturallan-\nby clinicians) (Zhang et al., 2023), and humans\nguageexplanations. Specifically,werequestlabel\nneed explanations to understand and trust model\nand free-form explanation annotations for a very\npredictions(Zhangetal.,2021). Therefore,afew\nlimitednumberofexamples(e.g.,3or10)selected\napproacheswereproposedtoretrospectivelyana-\nbyourALsamplingstrategyateveryALiteration.\nlyzetheprobabilitydistributionwithinthemodel\nSubsequently,thegeneratedexplanationsserveas\noraskmodelstogenerateexplanationsalongwith\ninputforthefinalprediction,demonstratingthepo-\npredictions (Ribeiro et al., 2016; Lundberg and\ntentialfortheseexplanationstosupportthemodel’s",
    "char_length": 1498
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 3,
    "text": "Lee,2017;Yuetal.,2019;Rajagopaletal.,2021;\npredictionsfaithfully.\nChenetal.,2021),despite,theformerisstillvery\ndifficultforlaymentounderstandwhilethelatter\nWeconducttwoALsimulationswithdifferent\namounts of samplings and iterations on a large-\nexplanationsarenotfaithfultowardpredictions.\nscale NLI dataset with human-annotated expla-\nAs researchers looked into the quality (Car-\nnations to justify incorporating explanations in\nton et al., 2020; Yao et al., 2023) of human-\nALdataselectioncanconsistentlyoutperformran-\nannotatednaturallanguageexplanations(Camburu\ndom, traditional data diversity-based, and model\net al., 2018; Rajani et al., 2019; Aggarwal et al.,\nprobability-based sampling strategies. We make\n2021), they discovered numerous issues in exist-\nthecodepublicallyavailable1.\ningdatasets(Gevaetal.,2019;Chmielewskiand\nA human evaluation of perceived validity, ex-\nKucker,2020;Narangetal.,2020;Sunetal.,2022),\nplainability,andpreferenceofthegeneratedexpla-\nsuch that the human annotations are of low qual-\nnations among our system, a SoTA explanation-\nityandsignificantinconsistency. Furthermore,the\ngenerationsystem,andhuman-annotatedexplana-\never-increasing costs in terms of labor, finances,\ntionsshowsthat,despitehumanexplanationsbeing\nandtimeforlarge-scale,high-qualitydataannota-\nrankedhighest,explanationsgeneratedbyoursys-\ntionsremainapersistentchallengefortheresearch\ntemarepreferredovertheSOTAsystem. Addition-\ncommunity. This challenge has given rise to var-",
    "char_length": 1483
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 4,
    "text": "ally,weconductthreeablationstudiestoexplore\nious methodologies to reduce reliance on human\nthecapabilityandpotentialofourproposedALar-\nannotations,suchasActiveLearning(AL)(Settles,\nchitectureintransferlearning,generalizability,and\n2009). ALisahuman-in-the-loopframeworkthat\nincorporating large language models (LLMs) for\nutilizesALsamplingstrategiestoiterativelyselect\nexplanationgenerationtofurtherreducehumanef-\nasmallnumberofrepresentativeexamples,request\nforts. LLMsdemonstrateexceptionalexplanation-\noracleannotations,andsubsequentlyfine-tunethe\ngeneration capabilities on relatively simple tasks.\nmodelusingtheannotateddata. However,priorAL\nHowever,theireffectivenessinhandlingcomplex\nworkspredominantlyfocusonlabelsandoverlook\nreal-worldtaskswarrantsin-depthstudy.\nthefactthatreal-worldscenariosoftenneedboth\nlabelsandnaturallanguageexplanations. 2 RelatedWork\nIn this work, we propose a dual-model AL ar-\n2.1 DatasetswithNaturalLanguage\nchitectureforhumanannotationoflabelsandex-\nExplanations\nplanations, drawing inspiration from the human\ndecision-makingprocess. Oursystemconsistsof:\nWiegreffeandMarasovic(2021)conductedacom-\n1)Anexplanation-generationmodelguidedby\n1https://github.com/neuhai/\nhuman-providedexplanations explanation-enriched-active-learning\nprehensive review of 65 datasets with explana- Fuetal.,2013;SchröderandNiekler,2020;Ren\ntionsandprovideda3-classtaxonomy: highlights, et al., 2021) of sampling strategies provide two",
    "char_length": 1450
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 5,
    "text": "free-text, and structured. Among the large-scale high-level selection concepts: data diversity and\ndatasetswithfree-textexplanations,e-SNLI(Cam- model probability. We propose a novel data\nburu et al., 2018) is a prominent one, which ex- diversity-based strategy that leverages human-\ntended the Stanford Natural Language Inference annotatedexplanationstoselectdata. Ourdatase-\n(SNLI) corpus (Bowman et al., 2015), a classifi- lectorsharesasimilarconceptwiththeestablished\ncationtasktodeterminetheinferencerelationbe- data-based clustering strategies (Xu et al., 2003;\ntweentwotextualcontexts(premiseandhypothe- NguyenandSmeulders,2004)andcore-set(Sener\nsis): entailment, contradiction, or neutral. The e- andSavarese,2017)thataimtoselectthemostrep-\nSNLIdataset(examplesareshowninAppendixA) resentativedatawhilemaximizingdiversity. Com-\ncontainshuman-annotatedfree-formexplanations paredwithmodelprobability-basedstrategies,data\nfor549,367examplesintrain,9,842invalidation, diversity-basedonesaremodel-agnosticandneed\nand9,824intestsplit. much less computing resources, whereas the for-\nAnother popular group of datasets extended mer requires inference on unlabeled examples to\nthe Commonsense QA (CQA v1.0 and v1.11 calculateprobability.\nversions) datasets (Talmor et al., 2019), includ- In addition to AL, Marasovic et al. (2022) in-\ning two variants of Cos-E dataset (CoS-E v1.0 troducesafew-shotself-rationalizationsettingthat",
    "char_length": 1430
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 6,
    "text": "and CoS-E v1.11 (Rajani et al., 2019)) and the asks a model to generate free-form explanations\nECQA (Aggarwal et al., 2021) dataset. Many re- andthelabelssimultaneously. Similarly,Bhatetal.\ncentworks(Narangetal.,2020;Sunetal.,2022) (2021)proposesamulti-taskself-teachingframe-\nhavefoundexplanationsinCoS-Etobenoisyand work with only 100 train data per category, and\nlow-quality,andthus,Aggarwaletal.(2021)care- Braggetal.(2021)providesguidanceonunifying\nfullydesignedandfollowedtheexplanationannota- evaluationforfew-shotsettings.\ntionprotocolstocreatedECQA,whichisofhigher\nqualitycomparedwithCoS-E. 2.3 NaturalLanguageExplanation\nInthispaper,weleveragethee-SNLIdatasetas Generation\nthe benchmark dataset for our AL simulation ex-\nDifferent approaches have been explored to en-\nperimentbecause1)theclassificationtaskispop-\nhance the model’s explainability by asking them\nular and representative, 2) the massive data size\nto generate natural language explanations. Some\nensures data diversity, and 3) explanations for a\nclassificationtaskmayprovidemoreeffectivehelp ofthem(Talmoretal.,2020;Tafjordetal.,2021;\nLatcinnik and Berant, 2020) propose systems to\ncomparedtoCQAtaskwheretrainingandtesting\ngeneratetextexplanationsforspecifictasks. Dalvi\ndatamaybeunrelated. Weadditionallyconductan\netal.(2022)proposea3-foldreasoningsystemthat\nablationstudyontheECQAdatasettoexplorethe\ngeneratesareasoningchainandasksusersforcor-\ngeneralizabilityofourproposedALarchitecture.",
    "char_length": 1464
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 7,
    "text": "rection. Otherrecentworks(Paranjapeetal.,2021;\nLiuetal.,2022;Chenetal.,2022)exploredifferent\n2.2 ActiveLearningforDataAnnotation\nprompt-based approaches to generate additional\nOwningtothepaucityofhigh-quality,large-scale information for the task and examine the robust-\nbenchmarks for a long tail of NLP tasks, learn- nessandvalidity. Webelievethatourdual-model\ningbettermethodsforlow-resourcelearningisac- system provides and uses explanations explicitly\nquiring more attention, such as Active Learning towards prediction, while the self-rationalization\n(AL)(Sharmaetal.,2015;Shenetal.,2017;Ash settingfallsshort. HaseandBansal(2022)argues\netal.,2019;TesoandKersting,2019;Kasaietal., thatexplanationsaremostsuitableasinputforpre-\n2019; Zhang et al., 2022). AL iteratively 1) se- dicting,andKumarandTalukdar(2020)designeda\nlectssamplesfromtheunlabeleddatapool(based systemtogeneratelabel-wiseexplanations,which\non AL sampling strategies) and queries their an- is aligned with our design hypothesis. Neverthe-\nnotationfromhumanannotators,2)fine-tunesthe less,thereexistotherworks(Wiegreffeetal.,2021;\nunderlyingmodelwithnewlyannotateddata,and Marasovicetal.,2022;Zelikmanetal.,2022)that\n3)evaluatesmodelperformance. exploretheuseofself-rationalizationsetting. We\nAfewALsurveys(Settles,2009;Olsson,2009; includetheself-rationalizationsettinginourhuman\nevaluationoftheexplanationqualityinSection4.4. Explanation-generationModel:\nTrainingInput explain:whatistherelationshipbetween",
    "char_length": 1477
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 8,
    "text": "3 Dual-ModelALSystem [hypothesis]and[premise]choice1:entailmentchoice2:\nneutralchoice3:contradiction\nTrainingTarget [humanannotatedexplanations]\n3.1 SystemArchitecture\nModelGeneration [generatedfree-formexplanation]\nFigure 1 illustrates our proposed dual-model AL\nPredictionModel:\nframework. The system comprises three primary TrainingInput question: whatistherelationshipbe-\nmodules: 1) an explanation-generation model tween [hypothesis] and [premise] choice1: entailment\nchoice2:neutralchoice3:contradiction<sep>because\nthattakesthedata,fine-tunesonhuman-annotated\n[generatedfree-formexplanation]\nexplanations,andgeneratesfree-formexplanations; TrainingTarget [humanannotatedlabel]\nModelPrediction [predictedcategory]\n2)apredictionmodelthatacceptsthedatacontent\nandthegeneratedexplanationsasinput,fine-tunes Table 1: The prompt-based input templates for both\non human-provided labels, and predicts the final modelsinoursystem,withthee-SNLI(Camburuetal.,\nlabel; 3) an AL data selector that selects a set 2018)datasetasanexample.\nofrepresentativeexamplesintermsoftheseman-\ntheoriginaltaskcontent. Forthee-SNLIdataset,\nticsimilaritybetweeneachunlabeleddatatextand\nthetaskcontentbecomes“whatistherelationship\nlabeleddata’shumanexplanations. TheALdatase-\nbetween”thehypothesisandpremisesentences;\nlectorplaysacrucialroleinfindingasmall,highly\n2)“choiceN”isfollowedbycandidateanswers,\nrepresentativesetofsamplesateveryiteration,and\nwhere N ∈ [1,3] for the e-SNLI dataset corre-",
    "char_length": 1474
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 9,
    "text": "furtherdetailsofourALselectorareinSection3.2.\nsponds to entailment, neutral, and contradiction.\nIneachALiteration,afterthedataselectorsam-\nWepassthechoicestotheexplanation-generation\nples unlabeled examples for human annotations,\nmodel,expectingthatitwilllearntogeneratefree-\nwefirstfine-tunetheexplanation-generationmodel\ntextexplanationsthatmayreflectpotentialrelation-\nsupervisedbyhuman-providedfree-formexplana-\nshipsbetweenthedatacontentandthetask;\ntions. Then,weinstructthismodeltogenerateex-\n3)forthepredictionmodel,anadditionalprompt\nplanationsforthesamesetofdata. Subsequently,\n“because:” isfollowedbytheexplanationsgener-\nwefine-tuneapredictionmodelusingthedatacon-\natedbytheexplanation-generationmodel. Weuse\ntent and explanations generated by the previous\naspecialtokentoseparatetheoriginaltaskcontent\nmodel as input, supervised by human-annotated\nandtheexplanation.\"\nlabels. Thefine-tuningprocessteachesthepredic-\ntionmodeltorelyontheexplanationsforpredic- 3.2 ALDataSelector\ntions(Yaoetal.,2023). Additionally,wefine-tune\nthepredictionmodelwithmodel-generatedexpla- Algorithm1OurDataDiversity-basedALSelector\nnationsinsteadofhuman-annotatedonesforbetter Variables:\nD ⇒unlabeleddataintrainsplit\nalignment during inference, especially when no train\nD ⇒previously-annotateddata\nprev\nhumanannotationsareavailable. AftereachALit- ddata⇒datacontentasastringofd (fore-SNLI,itisthe\np p\neration,weevaluatetheframeworkonastandalone premiseandhypothesis",
    "char_length": 1457
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 10,
    "text": "dexp⇒previously-annotatedfree-formexplanationofd\nevaluationdatasplit. p p\nx⇒numberofdatatobeselectedeachiteration\nBoththeexplanation-generationmodelandthe n =len(D ); n =len(D )\ntrain train prev prev\nprediction model can be any SoTA sequence-to- forD i ∈D train do\nifiteration==0then\nsequence models, such as BART (Lewis et al., score = 1 · (cid:80) similarity(ddata,ddata)\n2020) and T5 (Raffel et al., 2020). In this work, else di ntrain dp∈Dtrain i p\nweutilizeT5asthebackboneforbothmodelsand score di = np 1 rev · (cid:80) dp∈Dprev similarity(d i data,de p xp)\ndesignaprompt-basedinputtemplateforbothmod- endif\nendfor\nels,asshowninTable1,inspiredbyafewexisting D′ =rankD byscore\ntrain train\nworks(SchickandSchütze,2021;Gaoetal.,2021; D = selectxdata fromD′ withequalintervals\nselected train\nZhouetal.,2023). Toelucidatehoweachprompt HumanannotationonD selected\nD −=D ;D +=D\naddressesadifferentpartofdatacontent: train selected prev selected\n1) “explain:” and “question:” are the leading According to recent surveys of AL (Settles,\npromptsintheexplanation-generationmodeland 2009; Olsson, 2009; Fu et al., 2013; Schröder\nthepredictionmodel,respectively,indicatingdif- and Niekler, 2020; Ren et al., 2021), there are\nferent tasks for both models and are followed by two primary approaches for AL data selection:\nmodelprobability-basedanddatadiversity-based\napproaches. Modelprobability-basedapproaches,\nfirstly,aimtoselectexamplesaboutwhichthemod-\nelsareleastconfident. Theseapproachesinvolve",
    "char_length": 1493
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 11,
    "text": "conductinginferenceonunlabeleddataateveryit-\neration,whichconsumesmoretimeandcomputing\nresources. Unlikedatadiversity-basedapproaches,\ntheyarenotmodel-agnostic,whichmayaffectthe\neffectivenessofthesamplingstrategiesdepending\nonthemodelinuse.\nSecondly,datadiversity-basedapproacheslever- Figure 2: Preliminary experiment result of our dual-\nagevariousdatafeatures,suchasdatadistribution modelsystemone-SNLI(Camburuetal.,2018)dataset.\nandsimilarity,toselectarepresentativesetofex-\neachunlabeledexampleandrankalltheunlabeled\namplesfromthecandidatepoolwhilemaximizing\ndata in terms of the average similarity score. To\ndiversity. Thispaperintroducesadatadiversity-\nselectthemostrepresentativedatainthecandidate\nbasedALselectionstrategythatsharesaconcept\npoolwhilemaximizingdiversity,wechooseexam-\nsimilar to traditional data-based clustering strat-\nplesfromtherankeddatalistwithequalintervals.\negy Nguyen and Smeulders (2004) and core-set\nstrategy. However,ourstrategydiffersfromtradi- Notethatinthefirstiteration,sincenopreviously\nannotatedexplanationsareavailable,wecompare\ntionalstrategiesbecauseoursincorporateshuman-\nthesimilaritybetweenthedatacontent.\nannotatedexplanationsforselection. Morespecif-\nically, ourdata selectoraimsto chooseexamples\n4 Evaluation\nthat are representative of the unlabeled data pool\nintermsofaveragesimilaritytohuman-annotated\nWeconducttheALsimulationexperimentwiththe\nexplanations of all previously-labeled data while\ne-SNLI (Camburu et al., 2018) dataset. The pri-",
    "char_length": 1493
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 12,
    "text": "maximizingthediversityofnewly-selecteddata.\nmaryobjectiveistojustifythatourproposeddual-\nWe assume that human-annotated explana- model framework, when combined with human-\ntionscontributesignificantlytothemodel’spre- annotated explanations in AL data selection, can\ndictionandconveymoreinformationthanthe effectivelyidentifymorerepresentativeandhelpful\noriginaldatacontentalone. Theseexplanations datafromareasonablylarge-scaledataset.\ncan reveal underlying relationships between con- Giventhate-SNLIdatasetcomprisesasubstan-\nceptsinthedatacontentandtherelationsbetween tial 549,367 examples in the train split, we per-\nthedatacontentandchoices. Forinstance,inthe formed a preliminary experiment to determine a\ne-SNLI dataset, the data content consists of the reasonable number of candidate data for the AL\nconcatenationofhypothesisandpremisesentences. simulation. This approach aims to save time and\nLater, we construct a baseline selector in the AL computing resources. Our goal is to identify an\nsimulation experiment (Sec. 4.2) with the same idealcandidatedatasizethatwouldnotintroduce\nsetup, except that it only compares the similarity potentially biased feature distributions or signifi-\nbetweendatacontent. Additionally,weincluderan- cantlydegrademodelperformancewhencompared\ndombaselineandprobability-basedbaselinestrate- to fine-tuning on the full dataset. We employ the\ngies. Our results demonstrate that using human- pre-trainedT5-base(Raffeletal.,2020)astheback-",
    "char_length": 1475
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 13,
    "text": "annotated explanations for data selection consis- boneforalltheexperimentsandprovidethehyper-\ntently leads to improved prediction performance parametersinAppendixC.\ncomparedtousingdatacontentalone.\n4.1 PreliminaryExperiment\nHerewedelveintothedetailsofourdata-based\nAL data selector (shown in Algorithm 1). For Theexpectedoutcomeoftheaforementionedpre-\neach unlabeled data instance, we use sentence- liminary experiment is 1) to determine the upper\ntransformers(ReimersandGurevych,2019)tocal- bound of performance and observe how the per-\nculatethesemanticsimilaritybetweenitsdatacon- formanceofourdual-modelsystemgraduallyde-\ntent and every previously annotated explanation. creasesaswereducetheamountoftrainingdata,\nThen, we take the averaged similarity scores for and2)toidentifyasuitablecandidatedatasizefor\ntheALsimulation.\nWe also randomly sample the same amount of\ndata for each category in the preliminary experi-\nmenttominimizepotentialbiasintroducedbyun-\neven distribution, especially when the sampling\nsize per iteration is very small. Specifically, we\nselect eight different sampling amounts per cate-\ngoryfromthee-SNLItrainingsplit,rangingfrom\n[10,50,100,500,1500,3000,5000]andthecom-\npletedatapercategory. Sincethee-SNLIdataset (a)Setting1:9examplesperiteration+20iterations\nconsists of three categories: entailment, neutral,\nandcontradiction,thetotalsamplingsizeineach\nsettingbecomes[30,150,300,1500,4500,9000,\n15000,and549,367(fulltrainsplit)],respectively,\nasshowninFigure2.",
    "char_length": 1491
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 14,
    "text": "Foreachsamplingsetting,weconductthreetri-\nals to obtain an averaged result. In eachtrial, we\nfine-tunetheexplanationgenerationmodelandthe\npredictionmodelonceandconductahyperparame-\ntersearch. Theframeworkisthenevaluatedonthe\n(b)Setting2:30examplesperiteration+15iterations\ntestsplitofe-SNLI(9,824examples).\nFigure3: ResultsofALSimulationexperimentonour\nThepreliminaryexperimentresultsareshownin\nDual-modelsystemwithdifferentdataselectors.\nFigure2,wherethebluedotdenotestheaveraged\npredictionaccuracy(inpercentages)ateachsetting,\nformanceforoursandthebaselinedataselectors\nandtheredbarindicatesthestandarddeviationof\nat every iteration. During each trial, we start by\naccuracy among three trials. Notably, with more\nrandomly selecting 3,000 examples per category\nthan1,500datapercategory,theperformancedrop\nfromthecompletetraindataset,thenusethesame\ncompared to the full train split is inconspicuous datatoconductALsimulationswithdifferentdata\n(84.08%to87.02%),whilethestandarddeviation\nselectorsinourdual-modelframework. Thisway,\nisbelow0.5%. Thisobservationindicatesthatus- wecanensuretheperformancedifferencesduring\ning1%oftheoriginaltrainingdatasizeonlyleads each trial are not due to different unlabeled data\ntoaperformancedropofmerely3%. Additionally, poolsbuttoactualdifferencesintheperformance\nwe found that even with only 10 data points per\nof the AL data selectors. For the evaluation, we\ncategory(30dataintotal),oursystemstillachieves\nrandomlysample300examplespercategory(900",
    "char_length": 1486
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 15,
    "text": "anaverageaccuracyof45%,althoughthedeviation\nintotal)fromthetestsplitofe-SNLIeverytrialand\nisrelativelysignificant. Furthermore,whenweex-\nevaluatewiththesametestdataaftereachiteration.\ntendthetrainingdatasizefrom100to500dataper\nThe AL simulation comprises two settings,\ncategory(300to1500intotal),areasonablyappli-\nwhere we simulate annotating 180 and 450 data\ncablesettinginreal-worldscenarios,theaccuracy\ninstances, respectively. These two levels of data\ncanreachover80%accuracy,showingpromising\nannotationsreasonablymimicreal-worldscenarios\nresultsconsideringthattheamountoftrainingdata\nwhereusershavelimitedbudgets,annotators,and\nismuchsmallerthanthesizeofevaluationsamples.\ndata for annotation. Specifically, we experiment\nwiththefollowingtwosettings:\n4.2 SimulationExperiment: EvaluationSetup\n1)Foreveryiteration,select3examplespercat-\nBasedonthefindingsfromthepreliminaryexper- egory(9intotal)with20iterations,whichresults\niment, we decide to use 3,000 examples per cat- in180examplesaltogether;\negory (9,000 in total) as the candidate unlabeled 2)Foreveryiteration,select10examplespercat-\ndatapoolfortheActiveLearningsimulation. egory(30intotal)with15iterations,whichresults\nInspired by the few-shot evaluation guid- in450examplesaltogether.\nance (Bragg et al., 2021), we conduct 80 trials OurALsimulationexperimentinvolvesourdata\nforeachALsettingandcalculatetheaveragedper- selector, two baselines, and an additional model",
    "char_length": 1431
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 16,
    "text": "probability-based selector. Our data selector, de- Yes/NoCount Label Exp. Exp.→Label TrustworthyAI\nscribed in Section 3.2, is a novel data diversity- Ground-truth 83/7 86/4 87/3 78/12\nDual-model(ours) 64/26 68/22 48/42 35/55\nbased sampling strategy that leverages human- Self-rationalization 42/48 67/23 51/39 21/69\nannotatedexplanations. Forcomparison,weusea\nTable2: Humanevaluationresults.\nrandomdataselectorasthebasicbenchmarkand\nanothertraditionaldatadiversity-basedalgorithm\na SoTA few-shot explanation-generation system,\nthatsharesthesameprocedureswithours,except\ntheself-rationalizationbaseline(Marasovicetal.,\nthatitonlycomparesthesimilaritybetweeneach\n2022), andthehumanground-truth, werecruited\nunlabeleddata’scontentandthepreviously-labeled\nthreehumanparticipantstoconductahumaneval-\ndata’scontent,notusingthehuman-annotatedex-\nuation following the prior literature (Xu et al.,\nplanations. The probability-based selector con-\n2022). The self-rationalization baseline is a T5-\nductsinferenceonunlabeleddataandselectsexam-\nbasemodel,whichusesthesameinputtemplateof\npleswiththeleastprobabilityateveryiteration. We\nourexplanation-generationmodelshowninTable1\nfixthesamesetofhyperparameters(AppendixC).\nbutasksthemodeltogenerateboththelabeland\nWorthnotingthatourdataselectordoesnotuse\nexplanationsimultaneously.\ntask content in previously labeled examples; in-\nWe leverage AL setting 1 described in Sec-\nstead,weexclusivelyrelyonhuman-annotatedex-",
    "char_length": 1454
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 17,
    "text": "tion 4.2 to fine-tune our system with a total of\nplanationstodemonstratetheirgreaterutilitycom-\n180 examples over 20 epochs and use the same\nparedtotaskcontent. Inthefirstiteration,bothours\n180examplestofine-tunetheself-rationalization\nandthedatadiversitybaselineperformidentically\nbaseline. Bothsystemsareusedtoinferthecom-\nbecausenopreviouslyannotateddataisavailable.\npletetestsplitofe-SNLIafterfine-tuning;then,we\n4.3 SimulationExperiment: Result randomlysample80examplesforthehumanstudy.\nForeachdatainstance,theraterispresentedwith\nThe AL simulation results are presented in Fig-\nthe textual content of the premise and hypothesis\nure3. Toexplainthediagramsindetail,eachdotis\noftheoriginaldatapairedwiththreesetsoflabels\ntheaverageaccuracyon80trialsateveryiteration\nforeachdataselector. Thegreen/yellow/red/blue andexplanationsfromoursystem,baselinesystem,\ndotsdenoteourdataselector/datadiversity-based andthehuman-annotatedground-truthfromthee-\nbaseline/randomselector/modelprobability-based SNLI dataset. Participants who are not aware of\nthesourceofeachlabel-explanationpairareasked\nselector, respectively. We observe that our data\ntoanswerfourquestionswith[Yes/No]:\nselectorconsistentlymaintainsanadvantageover\nthetraditionaldata-basedsamplingbaseline,while 1)IsthePredictioncorrect?\nthe traditional one consistently beats the random 2)IstheExplanationitselfacorrectstatement?\nbaselinebyasignificantmargin. Additionally,we 3)RegardlessofwhethertheAIPredictionandExplanation",
    "char_length": 1481
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 18,
    "text": "observethatthemodelprobability-basedselector iscorrectornot,cantheExplanationhelpyoutounderstand\noutperformstherandombaselineinbothsettings. whyAIhassuchPrediction?\nTo summarize, our data selector outperforms 4) Will you trust & use this AI in real-world decision-\nboth baselines in every iteration for both AL set- making?\nToensureinter-coderconsistency,wefirstcon-\ntings,indicatingthatusinghuman-annotatedex-\nducta30-mintutorialsessiontoeducateallthree\nplanations in the data selector with our dual-\nparticipants with ten examples to build a consen-\nmodel AL framework is more beneficial than\nsus among them. In the actual experiment, each\nusing the data content alone. Even with only\nof the three participants is then asked to rate 30\n180 and 450 data to be annotated in each setting,\ndatainstances(20uniqueonesand10sharedones),\noursystemcanachieve55%and72%accuracyon\nwhichmakeupatotalof70datainstances,and360\naverage,respectively. Weanticipatethatourexper-\nratings(3rater*30instances*4questions). Wefirst\nimentwillreachasimilarperformancearound85%\ncalculated the Inter-Rater Reliability score (IRR)\nasshowninFigure2butconvergemuchfasterthan\namongthemforeachofthefourquestions. With\ntherandomselectorifwecontinuetheALprocess.\ntheIRRscoreof(Q1: 1,Q2: 0.89,Q3: 0.98,Q4:\n4.4 HumanEvaluationSetupandResults 0.87),weareconfidentthatthethreecodershave\nToqualitativelyevaluatetheexplainabilityofthe thesamecriteriaforfurtherresultanalysis.",
    "char_length": 1436
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 19,
    "text": "generated explanations from our system against Ourquestionsallhavebinaryresponses,andwe\nrelyonChi-squareanalysis(ElliottandWoodward,\n2007)toexaminethestatisticalsignificanceofthe\nratinggroups’differences. AsshowninTable2,the\nparticipantsratedhumanground-truthexplanations\nhighest across all four dimensions. Between our\nsystemandthefew-shotself-rationalizationsystem\n(baseline), participants believe our systems’ pre-\ndictedlabelsaremorelikelytobecorrect,with64\n‘valid’ ratings out of 90 for our system versus 42\noutof90ratingsforthebaseline. Chi-squaretest\n(a)Setting1:9examplesperiteration+20iterations\nindicatessuchadifferenceisstatisticallysignificant\n(χ2(1) = 21.61,p < 0.01).\nWhenaskedwhethertheywouldtrusttheAIif\nthereweresuchAIsystemssupportingtheirreal-\nworlddecision-making,35outof90answered‘Yes’\nfor our system, and it is significantly better than\nthebaselinesystem(21‘Yes’outof90)(χ2(1) =\n12.17,p < 0.01). In comparison, 78 out of 90\ntimespeoplevotedthattheywouldtrustthehuman-\nannotatedexplanation’squality.\n(b)Setting2:30examplesperiteration+15iterations\nAsforQuestion2(“thevalidityofthegenerated\nexplanation”)andQuestion3(“whetherthegener- Figure4: AblationstudyresultsofALsimulationex-\natedexplanationissupportingitsprediction”),the perimentonourDual-modelsystemwithdifferentdata\nhumanevaluationfailstosuggeststatisticallymean- selectorsonECQAdataset.\ningfulresultsbetweenoursystemandthebaseline",
    "char_length": 1412
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 20,
    "text": "system (χ2(1) = 0.06,p = 0.89 for explanation ingALsimulation. Wefine-tunetheexplanation-\nvalidity, and χ2(1) = 0.41,p = 0.52 for explana- generation models on e-SNLI with the same two\nsettingsinthepreviousexperiment,averagethere-\ntion supporting prediction). In summary, human\nsulton15trialsofexperiments,andkeepconsistent\nparticipantsbelieveoursystemcanoutperformthe\nwitheveryotherhyper-parameters.\nbaseline system on the label prediction’s quality\nTheablationresultsareshowninFigure6ofAp-\nand the trustworthiness of AI dimensions. Still,\npendixB.Theblue/redlinesdenotetheexplanation-\nthereisalargespacetoimproveashumanevalua-\ngenerationmodelisfine-tunedone-SNLIwitheach\ntorsbelievetheground-truthlabelandexplanation\nsettinginSection4.2correspondingly. Weobserve\nqualityismuchbetterthaneitherAIsystem.\nthattheexplanation-generationmodelconsistently\nprovided helpful explanations, leading to an im-\n4.5 AblationStudy1: TransfertoMulti-NLI\nprovementinthesystem’spredictionperformance,\nWeconductanablationstudywithtransferlearn- with accuracy reaching more than 65%. In addi-\ningthroughALsimulationfrome-SNLItoMulti- tion,theexplanation-generationmodelfine-tuned\nNLI (Williams et al., 2018). This study explores onmoredatacanperformbetter,suggestingthatit\nwhethertheexplanation-generationmodeltrained hadlearnedtogeneratemorehelpfulexplanations.\none-SNLIishelpfulforALonasimilartask.\n4.6 AblationStudy2: OurALFrameworkon\nThetransfer-learningablationstudyconsistsof\nECQA",
    "char_length": 1469
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 21,
    "text": "the following steps: 1) fine-tune an explanation-\ngenerationmodelusingourALframeworkonthee- WeadditionallyconductanALSimulationexperi-\nSNLIdataset;2)freezetheexplanation-generation mentonECQA(Aggarwaletal.,2021)(arecent\nmodelanduseittogenerateexplanationsintheAL datasetextendstheCommonsenseQAdatasetwith\nsimulationforMulti-NLI;3)fine-tunethepredic- high-qualityhuman-annotatedexplanations)with\ntionmodelforMulti-NLIateveryiteration. Unlike ourdataselector,randombaseline,andsimilarity-\nthee-SNLIexperiment,ourALdataselectionalgo- basedbaselinethatdoesnotuseexplanations. We\nrithmwillusemodel-generatedexplanationstose- complywiththesameexperimentsettingsforthee-\nlectexamplesateveryiterationinthetransferlearn- SNLIALsimulationsdescribedinSection4.2. The\none-SNLIandECQAdatasetstoexplorewhether\nwecanfurtherreducehumanannotationefforts.\nThe results are presented in Figure 5, where a\nhorizontal dotted line represents the benchmark\nof the explanation generation model fine-tuned\non human-annotated explanations in Section 4.3\nand4.6. TheLLM-ALframeworksignificantlyout-\nperformstheexplanationgenerationmodelguided\nbyhumanannotationinbothActiveLearningset-\n(a)e-SNLIDataset tings. However, we hypothesize the LLM’s ex-\nplanationgenerationcapabilitycanvaryfrom\ntasktotask. Itmaybehighlyefficientinrelatively\neasy tasks, such as e-SNLI and ECQA datasets,\nbothofwhicharetrainingdatasetsforFLAN-T5.\nYet,LLMsmaystruggletoprovidehelpfulexplana-\ntionsincomplexreal-worlddomain-specifictasks,",
    "char_length": 1485
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 22,
    "text": "wherehumanexperts’feedbackmaystillbeneces-\nsaryandpreferred. Thisleadstoanotherpotential\navenue for future work: exploring the capability\n(b)ECQADataset\nandlimitationsofleveragingLLMsforexplanation\ngenerationinreal-worldscenarios.\nFigure5: AblationstudyresultsofALsimulationex-\nperimentwithFLAN-T5-XLforexplanation(exp.) gen-\nerationinourDual-modelframeworkcomparedwith\n5 ConclusionandFutureWork\nbesthuman-annotatedexplanationsone-SNLI(top)and\nECQA(bottom)datasets.\nIn summary, this paper introduces a novel dual-\nresultsareshowninFigure4,whereourproposed model AL system designed to address the com-\ndataselectionstrategycanconsistentlyoutperform monreal-worldneedfordomainexpertstoprovide\nbothbaselinesinbothsimulationsettings. Interest- bothclassificationlabelsandnaturallanguageex-\ningly,thesimilarity-basedbaselineperformssim- planations. Oursystemcomprisesapurpose-built\nilarly to the random baseline, which could be be- datadiversity-basedALexampleselectorandtwo\ncauseusingdatacontentaloneisnotsufficientto sequence-to-sequence language models, one for\nselect more helpful and representative examples explanationgenerationandtheotherforlabelpre-\nwhileusinghuman-annotatedexplanationscanfa- diction. ThroughanALsimulationevaluationand\ncilitatebetterdataselectionconsistently. ahumanassessmentofthee-SNLIdataset,ourre-\nsultsdemonstratetheeffectivenessofexplanations\n4.7 AblationStudy3: LLMforExplanation inALsamplingwithoursystem. Theyconsistently",
    "char_length": 1453
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 23,
    "text": "Generation outperform both baselines, and the explanations\nThe recent prevalence of instructional-finetuned generatedbyoursystemarepreferredoverastate-\nlarge language models (LLMs) (Wei et al., 2021; of-the-artexplanation-generationsystem.\nChowdheryetal.,2022;Ouyangetal.,2022)with Our work lays a step-stone towards a human-\nexceptionalgenerationcapabilitiesoff-the-shelfen- centered interactive AI solution (it can be easily\nabledastraightforwardideauponourdual-model implementedasaninteractivesystemasillustrated\nframework: can LLMs generate natural lan- inFig7inAppendixD)thatsupportsdomainex-\nguage explanations that are on par or even perts for their data annotation tasks. Many real-\nof higher quality than human-annotated ones, worldtasksstillrequiredomainexpertstoreview\nto facilitate the prediction model fine-tuning pro- andannotateeachdatainstancewithadecisionand\ncess? Weconductablationexperimentstoleverage anexplanationforaccountabilitypurposes(e.g.,a\nFLAN-T5-XL(Chungetal.,2022)forexplanation lawyer reviewing and signing off on a legal doc-\ngeneration in our framework to substitute the T5 ument). We invite fellow researchers to join us\nmodel fine-tuned on human explanations (LLM- inadvancingthisresearchdirection,essentialfor\nAL,hereinafter). WeconducttheALsimulations supportingthisprevalentreal-worldrequirement.\n6 Limitations Oana-Maria Camburu, Tim Rocktäschel, Thomas\nLukasiewicz,andPhilBlunsom.2018. e-SNLI:Nat-",
    "char_length": 1438
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 24,
    "text": "In this paper, we demonstrate the effectiveness urallanguageinferencewithnaturallanguageexpla-\nof our framework on a representative large-scale nations. AdvancesinNeuralInformationProcessing\nSystems,31.\nclassificationdataset(e-SNLI),buttherearemany\notherNLPtasks,suchasquestionansweringand\nSamuel Carton, Anirudh Rathore, and Chenhao Tan.\ncommonsense reasoning. The generalizability of 2020. Evaluating and characterizing human ratio-\noursystemonotherNLPtasksremainsunexplored. nales. In Proceedings of the 2020 Conference on\nEmpiricalMethodsinNaturalLanguageProcessing\nAnotherlimitationisthatthisworkproposedadata\n(EMNLP),pages9294–9307,Online.Associationfor\ndiversity-basedALselectordesign. Webenchmark\nComputationalLinguistics.\nitwithatraditionaldatadiversity-basedselectoras\nwellasamodelprobability-baseddesigntodemon- HanxiongChen,XuChen,ShaoyunShi,andYongfeng\nZhang. 2021. Generate natural language ex-\nstratetheusefulnessofexplanations. Priorlitera-\nplanations for recommendation. arXiv preprint\nturehasproposedotherdesigns,suchasensemble\narXiv:2101.03392.\napproaches,whicharenotevaluatedinthispaper.\nHowardChen,JacquelineHe,KarthikNarasimhan,and\nAcknowledgements DanqiChen.2022. Canrationalizationimprovero-\nbustness? InProceedingsofthe2022Conferenceof\nThisworkwassupportedbytheRensselaer-IBM theNorthAmericanChapteroftheAssociationfor\nAI Research Collaboration (http://airc.rpi.edu), ComputationalLinguistics: HumanLanguageTech-\nnologies, pages 3792–3805, Seattle, United States.",
    "char_length": 1489
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 25,
    "text": "which is part of the IBM AI Horizons Network\nAssociationforComputationalLinguistics.\n(http://ibm.biz/AIHorizons).\nMichaelChmielewskiandSarahCKucker.2020. An\nmturkcrisis? shiftsindataqualityandtheimpacton\nReferences studyresults. SocialPsychologicalandPersonality\nScience,11(4):464–473.\nShourya Aggarwal, Divyanshu Mandowara, Vishwa-\njeetAgrawal,DineshKhandelwal,ParagSingla,and AakankshaChowdhery,SharanNarang,JacobDevlin,\nDinesh Garg. 2021. Explanations for Common- Maarten Bosma, Gaurav Mishra, Adam Roberts,\nsenseQA:NewDatasetandModels. InProceedings Paul Barham, Hyung Won Chung, Charles Sutton,\nof the 59th Annual Meeting of the Association for Sebastian Gehrmann, et al. 2022. Palm: Scaling\nComputationalLinguisticsandthe11thInternational language modeling with pathways. arXiv preprint\nJointConferenceonNaturalLanguageProcessing arXiv:2204.02311.\n(Volume1: LongPapers),pages3050–3065,Online.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nAssociationforComputationalLinguistics.\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nJordanTAsh,ChichengZhang,AkshayKrishnamurthy, Wang,MostafaDehghani,SiddharthaBrahma,etal.\nJohn Langford, and Alekh Agarwal. 2019. Deep 2022. Scalinginstruction-finetunedlanguagemodels.\nbatchactivelearningbydiverse,uncertaingradient arXivpreprintarXiv:2210.11416.\nlowerbounds. arXivpreprintarXiv:1906.03671.\nBhavanaDalvi,OyvindTafjord,andPeterClark.2022.\nMeghanaMoorthyBhat,AlessandroSordoni,andSub- Towardsteachablereasoningsystems. arXivpreprint",
    "char_length": 1481
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 26,
    "text": "habrataMukherjee.2021. Self-trainingwithfew-shot arXiv:2204.13074.\nrationalization. InProceedingsofthe2021Confer-\nenceonEmpiricalMethodsinNaturalLanguagePro- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\ncessing,pages10702–10712,OnlineandPuntaCana, Kristina Toutanova. 2019. BERT: Pre-training of\nDominicanRepublic.AssociationforComputational deepbidirectionaltransformersforlanguageunder-\nLinguistics. standing. InProceedingsofthe2019Conferenceof\ntheNorthAmericanChapteroftheAssociationfor\nSamuelR.Bowman,GaborAngeli,ChristopherPotts, ComputationalLinguistics: HumanLanguageTech-\nand Christopher D. Manning. 2015. A large anno- nologies,Volume1(LongandShortPapers),pages\ntatedcorpusforlearningnaturallanguageinference. 4171–4186,Minneapolis,Minnesota.Associationfor\nIn Proceedings of the 2015 Conference on Empiri- ComputationalLinguistics.\ncalMethodsinNaturalLanguageProcessing,pages\n632–642,Lisbon,Portugal.AssociationforCompu- Jaimie Drozdal, Justin Weisz, Dakuo Wang, Gaurav\ntationalLinguistics. Dass, Bingsheng Yao, Changruo Zhao, Michael\nMuller,LinJu,andHuiSu.2020. Trustinautoml:\nJonathanBragg,ArmanCohan,KyleLo,andIzBeltagy. exploringinformationneedsforestablishingtrustin\n2021. Flex: Unifying evaluation for few-shot nlp. automatedmachinelearningsystems. InProceedings\nAdvancesinNeuralInformationProcessingSystems, of the 25th international conference on intelligent\n34:15787–15800. userinterfaces,pages297–307.",
    "char_length": 1422
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 27,
    "text": "Nan Duan, Duyu Tang, Peng Chen, and Ming Zhou. fornaturallanguagegeneration,translation,andcom-\n2017. Questiongenerationforquestionanswering. prehension. InProceedingsofthe58thAnnualMeet-\nIn Proceedings of the 2017 Conference on Empiri- ingoftheAssociationforComputationalLinguistics,\ncalMethodsinNaturalLanguageProcessing,pages pages7871–7880,Online.AssociationforComputa-\n866–874, Copenhagen, Denmark. Association for tionalLinguistics.\nComputationalLinguistics.\nZacharyCLipton.2018. Themythosofmodelinter-\nAlanCElliottandWayneAWoodward.2007. Statisti- pretability: Inmachinelearning, theconceptofin-\ncalanalysisquickreferenceguidebook: WithSPSS terpretabilityisbothimportantandslippery. Queue,\nexamples. Sage. 16(3):31–57.\nYifanFu,XingquanZhu,andBinLi.2013. Asurvey JiachengLiu,AlisaLiu,XimingLu,SeanWelleck,Pe-\noninstanceselectionforactivelearning. Knowledge terWest,RonanLeBras,YejinChoi,andHannaneh\nandinformationsystems,35:249–283. Hajishirzi.2022. Generatedknowledgeprompting\nforcommonsensereasoning. InProceedingsofthe\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021.\n60thAnnualMeetingoftheAssociationforCompu-\nMakingpre-trainedlanguagemodelsbetterfew-shot\ntationalLinguistics(Volume1: LongPapers),pages\nlearners. In Proceedings of the 59th Annual Meet-\n3154–3169,Dublin,Ireland.AssociationforCompu-\ningoftheAssociationforComputationalLinguistics\ntationalLinguistics.\nandthe11thInternationalJointConferenceonNatu-\nralLanguageProcessing(Volume1: LongPapers),",
    "char_length": 1464
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 28,
    "text": "ScottMLundbergandSu-InLee.2017. Aunifiedap-\npages3816–3830,Online.AssociationforComputa-\nproachtointerpretingmodelpredictions. Advances\ntionalLinguistics.\ninneuralinformationprocessingsystems,30.\nMorGeva,YoavGoldberg,andJonathanBerant.2019.\nAnaMarasovic,IzBeltagy,DougDowney,andMatthew\nArewemodelingthetaskortheannotator? aninves-\nPeters.2022. Few-shotself-rationalizationwithnat-\ntigationofannotatorbiasinnaturallanguageunder-\nurallanguageprompts. InFindingsoftheAssocia-\nstandingdatasets. arXivpreprintarXiv:1908.07898.\ntion for Computational Linguistics: NAACL 2022,\npages410–424,Seattle,UnitedStates.Association\nPeter Hase and Mohit Bansal. 2022. When can mod-\nforComputationalLinguistics.\nels learn from explanations? a formal framework\nforunderstandingtherolesofexplanationdata. In\nSharan Narang, Colin Raffel, Katherine Lee, Adam\nProceedingsoftheFirstWorkshoponLearningwith\nRoberts,NoahFiedel,andKarishmaMalkan.2020.\nNaturalLanguageSupervision,pages29–39,Dublin,\nWt5?! training text-to-text models to explain their\nIreland.AssociationforComputationalLinguistics.\npredictions. arXivpreprintarXiv:2004.14546.\nJungoKasai,KunQian,SairamGurajada,YunyaoLi,\nHieu T Nguyen and Arnold Smeulders. 2004. Ac-\nand Lucian Popa. 2019. Low-resource deep entity\ntive learning using pre-clustering. In Proceedings\nresolutionwithtransferandactivelearning. InPro-\nof the twenty-first international conference on Ma-\nceedings of the 57th Annual Meeting of the Asso-\nchinelearning,page79.",
    "char_length": 1474
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 29,
    "text": "ciationforComputationalLinguistics,pages5851–\n5861,Florence,Italy.AssociationforComputational\nFredrik Olsson. 2009. A literature survey of active\nLinguistics.\nmachinelearninginthecontextofnaturallanguage\nprocessing.\nTomášKocˇiský,JonathanSchwarz,PhilBlunsom,Chris\nDyer,KarlMoritzHermann,GáborMelis,andEd-\nLongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,\nwardGrefenstette.2018. TheNarrativeQAreading\nCarrollWainwright,PamelaMishkin,ChongZhang,\ncomprehensionchallenge. TransactionsoftheAsso-\nSandhiniAgarwal,KatarinaSlama,AlexRay,etal.\nciationforComputationalLinguistics,6:317–328.\n2022. Traininglanguagemodelstofollowinstruc-\nSawanKumarandParthaTalukdar.2020. NILE:Natu- tions with human feedback. Advances in Neural\nrallanguageinferencewithfaithfulnaturallanguage InformationProcessingSystems,35:27730–27744.\nexplanations. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin- Bhargavi Paranjape, Julian Michael, Marjan\nguistics,pages8730–8742,Online.Associationfor Ghazvininejad, Hannaneh Hajishirzi, and Luke\nComputationalLinguistics. Zettlemoyer.2021. Promptingcontrastiveexplana-\ntionsforcommonsensereasoningtasks. InFindings\nVeronicaLatcinnikandJonathanBerant.2020. Explain- of the Association for Computational Linguistics:\ningquestionansweringmodelsthroughtextgenera- ACL-IJCNLP 2021, pages 4179–4192, Online.\ntion. arXivpreprintarXiv:2004.05569. AssociationforComputationalLinguistics.",
    "char_length": 1418
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 30,
    "text": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan AlecRadford,JeffreyWu,RewonChild,DavidLuan,\nGhazvininejad,AbdelrahmanMohamed,OmerLevy, DarioAmodei,IlyaSutskever,etal.2019. Language\nVeselin Stoyanov, and Luke Zettlemoyer. 2020. modelsareunsupervisedmultitasklearners. OpenAI\nBART:Denoisingsequence-to-sequencepre-training blog,1(8):9.\nColinRaffel,NoamShazeer,AdamRoberts,Katherine ManaliSharma,DiZhuang,andMustafaBilgic.2015.\nLee,SharanNarang,MichaelMatena,YanqiZhou, Activelearningwithrationalesfortextclassification.\nWeiLi,PeterJLiu,etal.2020. Exploringthelimits InProceedingsofthe2015ConferenceoftheNorth\noftransferlearningwithaunifiedtext-to-texttrans- AmericanChapteroftheAssociationforComputa-\nformer. J.Mach.Learn.Res.,21(140):1–67. tionalLinguistics: HumanLanguageTechnologies,\npages441–451,Denver,Colorado.Associationfor\nDheerajRajagopal,VidhishaBalachandran,EduardH ComputationalLinguistics.\nHovy,andYuliaTsvetkov.2021. SELFEXPLAIN:A\nself-explainingarchitectureforneuraltextclassifiers. YanyaoShen,HyokunYun,ZacharyLipton,YakovKro-\nInProceedingsofthe2021ConferenceonEmpirical nrod, and Animashree Anandkumar. 2017. Deep\nMethodsinNaturalLanguageProcessing,pages836– active learning for named entity recognition. In\n850, OnlineandPuntaCana, DominicanRepublic. Proceedings of the 2nd Workshop on Representa-\nAssociationforComputationalLinguistics. tionLearningforNLP,pages252–256,Vancouver,\nCanada.AssociationforComputationalLinguistics.\nNazneen Fatema Rajani, Bryan McCann, Caiming",
    "char_length": 1485
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 31,
    "text": "Xiong, and Richard Socher. 2019. Explain your- Jiao Sun, Swabha Swayamdipta, Jonathan May, and\nself! leveraginglanguagemodelsforcommonsense XuezheMa.2022. Investigatingthebenefitsoffree-\nreasoning. InProceedingsofthe57thAnnualMeet- formrationales. arXivpreprintarXiv:2206.11083.\ningoftheAssociationforComputationalLinguistics,\npages 4932–4942, Florence, Italy. Association for OyvindTafjord,BhavanaDalvi,andPeterClark.2021.\nComputationalLinguistics. ProofWriter: Generating implications, proofs, and\nabductivestatementsovernaturallanguage. InFind-\nPranavRajpurkar,JianZhang,KonstantinLopyrev,and ingsoftheAssociationforComputationalLinguis-\nPercyLiang.2016. SQuAD:100,000+questionsfor tics: ACL-IJCNLP2021,pages3621–3634,Online.\nmachinecomprehensionoftext. InProceedingsof AssociationforComputationalLinguistics.\nthe2016ConferenceonEmpiricalMethodsinNatu-\nralLanguageProcessing,pages2383–2392,Austin, Alon Talmor, Jonathan Herzig, Nicholas Lourie, and\nTexas.AssociationforComputationalLinguistics. JonathanBerant.2019. CommonsenseQA:Aques-\ntion answering challenge targeting commonsense\nNilsReimersandIrynaGurevych.2019. Sentence-bert: knowledge. InProceedingsofthe2019Conference\nSentenceembeddingsusingsiamesebert-networks. oftheNorthAmericanChapteroftheAssociationfor\nInProceedingsofthe2019ConferenceonEmpirical ComputationalLinguistics: HumanLanguageTech-\nMethodsinNaturalLanguageProcessing.Associa- nologies,Volume1(LongandShortPapers),pages",
    "char_length": 1446
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 32,
    "text": "tionforComputationalLinguistics. 4149–4158,Minneapolis,Minnesota.Associationfor\nComputationalLinguistics.\nPengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao\nHuang,ZhihuiLi,BrijBGupta,XiaojiangChen,and AlonTalmor,OyvindTafjord,PeterClark,YoavGold-\nXinWang.2021. Asurveyofdeepactivelearning. berg,andJonathanBerant.2020. Leap-of-thought:\nACMcomputingsurveys(CSUR),54(9):1–40. Teaching pre-trained models to systematically rea-\nson over implicit knowledge. Advances in Neural\nMarco Tulio Ribeiro, Sameer Singh, and Carlos InformationProcessingSystems,33:20227–20237.\nGuestrin.2016. \"whyshoulditrustyou?\"explaining\nthepredictionsofanyclassifier. InProceedingsof Stefano Teso and Kristian Kersting. 2019. Explana-\nthe22ndACMSIGKDDinternationalconferenceon toryinteractivemachinelearning. InProceedingsof\nknowledgediscoveryanddatamining,pages1135– the2019AAAI/ACMConferenceonAI,Ethics,and\n1144. Society,pages239–245.\nTimo Schick and Hinrich Schütze. 2021. Exploiting Alex Wang, Amanpreet Singh, Julian Michael, Felix\ncloze-questionsforfew-shottextclassificationand Hill,OmerLevy,andSamuelBowman.2018. GLUE:\nnatural language inference. In Proceedings of the Amulti-taskbenchmarkandanalysisplatformfornat-\n16thConferenceoftheEuropeanChapteroftheAsso- urallanguageunderstanding. InProceedingsofthe\nciationforComputationalLinguistics: MainVolume, 2018 EMNLP Workshop BlackboxNLP: Analyzing\npages 255–269, Online. Association for Computa- and Interpreting Neural Networks for NLP, pages",
    "char_length": 1471
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 33,
    "text": "tionalLinguistics. 353–355,Brussels,Belgium.AssociationforCom-\nputationalLinguistics.\nChristopher Schröder and Andreas Niekler. 2020.\nA survey of active learning for text classifica- Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin\ntion using deep neural networks. arXiv preprint Guu, Adams Wei Yu, Brian Lester, Nan Du, An-\narXiv:2008.07267. drewMDai,andQuocVLe.2021. Finetunedlan-\nguagemodelsarezero-shotlearners. arXivpreprint\nOzan Sener and Silvio Savarese. 2017. Active learn- arXiv:2109.01652.\ning for convolutional neural networks: A core-set\napproach. arXivpreprintarXiv:1708.00489. SarahWiegreffeandAnaMarasovic.2021. Teachmeto\nexplain: Areviewofdatasetsforexplainablenatural\nBurrSettles.2009. Activelearningliteraturesurvey. languageprocessing. InThirty-fifthConferenceon\nNeuralInformationProcessingSystemsDatasetsand Eric Zelikman, Jesse Mu, Noah D Goodman, and\nBenchmarksTrack(Round1). YuhuaiTonyWu.2022. Star: Self-taughtreasoner\nbootstrappingreasoningwithreasoning.\nSarahWiegreffe,AnaMarasovic´,andNoahA.Smith.\n2021. Measuring association between labels and ShaoZhang,JianingYu,XuhaiXu,ChangchangYin,\nfree-textrationales. InProceedingsofthe2021Con- YuxuanLu,BingshengYao,MelanieTory,LaceM\nferenceonEmpiricalMethodsinNaturalLanguage Padilla,JeffreyCaterino,PingZhang,etal.2023. Re-\nProcessing,pages10266–10284,OnlineandPunta thinkinghuman-aicollaborationincomplexmedical\nCana,DominicanRepublic.AssociationforCompu- decisionmaking: Acasestudyinsepsisdiagnosis.",
    "char_length": 1473
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 34,
    "text": "tationalLinguistics. arXivpreprintarXiv:2309.12368.\nAdinaWilliams,NikitaNangia,andSamuelBowman. Shujian Zhang, Chengyue Gong, Xingchao Liu,\n2018. A broad-coverage challenge corpus for sen- PengchengHe,WeizhuChen,andMingyuanZhou.\ntenceunderstandingthroughinference. InProceed- 2022. ALLSH:Activelearningguidedbylocalsen-\ningsofthe2018ConferenceoftheNorthAmerican sitivityandhardness. InFindingsoftheAssociation\nChapter of the Association for Computational Lin- forComputationalLinguistics: NAACL2022,pages\nguistics: Human Language Technologies, Volume 1328–1342, Seattle, United States. Association for\n1 (Long Papers), pages 1112–1122, New Orleans, ComputationalLinguistics.\nLouisiana.AssociationforComputationalLinguis-\ntics. ZhanZhang,YeginGenc,DakuoWang,MehmetEren\nAhsen, and Xiangmin Fan. 2021. Effect of ai ex-\nGentaIndraWinata,AndreaMadotto,ZhaojiangLin, planations on human perceptions of patient-facing\nRosanneLiu,JasonYosinski,andPascaleFung.2021. ai-poweredhealthcaresystems. JournalofMedical\nLanguagemodelsarefew-shotmultilinguallearners. Systems,45(6):64.\nInProceedingsofthe1stWorkshoponMultilingual\nRepresentation Learning, pages 1–15, Punta Cana, Yangqiaoyu Zhou, Yiming Zhang, and Chenhao Tan.\nDominicanRepublic.AssociationforComputational 2023. FLamE:Few-shotlearningfromnaturallan-\nLinguistics. guageexplanations. InProceedingsofthe61stAn-\nnualMeetingoftheAssociationforComputational\nYingXu,DakuoWang,MoYu,DanielRitchie,Bing-\nLinguistics (Volume 1: Long Papers), pages 6743–",
    "char_length": 1492
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 35,
    "text": "shengYao,TongshuangWu,ZhengZhang,TobyJia-\n6763, Toronto, Canada. Association for Computa-\nJunLi,NoraBradford,BrandaSun,etal.2022. Fan-\ntionalLinguistics.\ntasticquestionsandwheretofindthem: Fairytaleqa–\nan authentic dataset for narrative comprehension.\nACL’22.\nZhaoXu,KaiYu,VolkerTresp,XiaoweiXu,andJizhi\nWang.2003. Representativesamplingfortextclassi-\nficationusingsupportvectormachines. InEuropean\nconferenceoninformationretrieval,pages393–407.\nSpringer.\nBingsheng Yao, Prithviraj Sen, Lucian Popa, James\nHendler, and Dakuo Wang. 2023. Are human ex-\nplanationsalwayshelpful? towardsobjectiveevalua-\ntionofhumannaturallanguageexplanations. arXiv\npreprintarXiv:2305.03117.\nBingshengYao,DakuoWang,TongshuangWu,Zheng\nZhang, Toby Li, Mo Yu, and Ying Xu. 2022. It\nis AI’s turn to ask humans a question: Question-\nanswer pair generation for children’s story books.\nIn Proceedings of the 60th Annual Meeting of the\nAssociationforComputationalLinguistics(Volume\n1: Long Papers), pages 731–744, Dublin, Ireland.\nAssociationforComputationalLinguistics.\nMoYu,ShiyuChang,YangZhang,andTommiJaakkola.\n2019. Rethinking cooperative rationalization: In-\ntrospective extraction and complement control. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9thInternationalJointConferenceonNaturalLan-\nguageProcessing(EMNLP-IJCNLP),pages4094–\n4103,HongKong,China.AssociationforComputa-\ntionalLinguistics.\nAppendix\nA e-SNLIExamples\nTable3illustratesanexampledataofeachcategory",
    "char_length": 1501
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 36,
    "text": "in the e-SNLI dataset. Every data instance con-\ntainsapremiseandhypothesisalongwithahuman\nannotatedlabelandfree-formexplanation.\nPremise: Thischurchchoirsingstothemassesasthey\nsingjoyoussongsfromthebookatachurch.\n(a) Active Learning on Mulit-NLI using explanation-\nHypothesis: Thechurchisfilledwithsong.\ngenerationmodelfrome-SNLIwithSetting1\nLabel: entailment\nHuman-annotatedexplanation: “Filledwithsong”is\narephrasingofthe\"choirsingstothemasses.\nPremise: Amanplayinganelectricguitaronstage.\nHypothesis: Amanisperformingforcash.\nLabel: neutral\nHuman-annotatedexplanation: Itisunknownifthe\nmanisperformingforcash.\nPremise: Acouplewalkhandinhanddownastreet.\nHypothesis: Acoupleissittingonabench.\nLabel: contradiction\nHuman-annotatedexplanation: Thecouplecannotbe\nwalkingandsittingathesametime. (b) Active Learning on Mulit-NLI using explanation-\ngenerationmodelfrome-SNLIwithSetting2\nTable3: Sampledataofeachcategoryine-SNLI(Cam-\nFigure6: ResultsofTransferLearningAblationStudy\nburuetal.,2018)dataset.\nofALSimulationexperimentonourDual-modelsystem\nB TransferLearningAblationStudy from e-SNLI to Multi-NLI. Setting 1/2 refers to the\nDiagrams settingsforActiveLearningSimulationinSection4.2.\nFigure 6 shows the results of our Ablation Study of hyper-parameters is: batch_size_per_GPU =\nresultsdescribedinSection4.5. Theexplanation- 2;learning_rate = 1e−4;input_max_length =\ngenerationmodelisfine-tunedfromALone-SNLI 512;target_max_length = 64",
    "char_length": 1439
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 37,
    "text": "dataset with two different AL settings, then we We conduct a hyper-parameter search for the\nfreeze the explanation-generation model to train numberoffine-tuningepochsforeachamountof\nthe prediction model in AL simulation for Multi- sampledexamples,detailsareshowninTable4.\nNLIdatasetundertwosettings. Setting1/2refers\nto the settings for Active Learning Simulation in #oftraindata\nepochforM epochforM\nSection4.2.\npercategory/total RG P\n10/30 25 100\nC SystemEnvironmentand 50/150 25 250\nHyper-Parameters 100/300 10 250\n500/1500 5 50\nThecomputingresourceofalltheexperimentswe 1500/4500 5 50\n3000/9000 5 25\nconductedinthispaperhas128GigabytesofRAM.\n5000/15000 5 25\nInaddition,weuse2NVIDIATeslaV100GPUfor\nFull 1 1\nthe preliminary experiment and 8 NVIDIA Tesla\nV100GPUfortheALsimulationexperiment. Table4: Fine-tuningepochsofeachmodelinourdual-\nmodelsystemwithdifferentdataamountsettings.\nC.1 PreliminaryExperiment\nForthePreliminaryexperimentdescribedinSec-\nC.2 ALSimulationExperiment\ntion 4.1, we leverage the same set of fine-\ntuning hyper-parameters other than the num- For both of the AL Simulation settings we ex-\nber of fine-tuning epochs for the explanation- perimented in Section 4.2, we leverage the same\ngeneration model (denotes as M ) and the pre- set of hyper-parameters for fine-tuning our dual-\nEG\ndiction model (denotes as M ). The same set model AL system: batch_size_per_GPU =\nP\n2;learning_rate = 1e−4;M _train_epoch =\nEG\n20,M _train_epoch = 250;input_max_length =\nP",
    "char_length": 1479
  },
  {
    "paper_id": "Beyond_lables_human_annotators_natural_language_explanations",
    "chunk_id": 38,
    "text": "512;target_max_length = 64\nD ProposalforanInteractiveSystem\nOurproposeddual-modelsystemcanbeeasilyim-\nplementedasaninteractivehuman-centeredAIsys-\ntemforsupportingdomainexpertsandhumanan-\nnotatorsinlabelingbothlabelsandexplanations.\nFigure7: Ourproposeddual-modelsystemcanbeim-\nplementedasaninteractiveAL-baseddataannotation\nsystemtospeedupusers’annotationproductivity. Such\nasystemcansimplyhaveaninterfacewithfouroutput\nfunctions(i.e., displayunlabeleddata, displayALse-\nlecteddata,displaygenerated-explanation,anddisplay\npredictedlabeled)andoneinputfunction(i.e.,annotate\nlabelandexplanationfortheunlabeleddata.",
    "char_length": 614
  }
]