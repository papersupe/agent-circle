[
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 0,
    "text": "Predicting Difficulty and Discrimination of Natural Language Questions\nMatthewA.Byrd ShashankSrivastava\nUniversityofNorthCarolinaatChapelHill\nmatthew_a_byrd@outlook.com,ssrivastava@cs.unc.edu\nAbstract theabilitiesofrespondents. WhileIRThasitsin-\nceptioninpsychometricsandhastraditionallybeen\nItem Response Theory (IRT) has been exten-\nusedwithhumanrespondents,recently,ithasbeen\nsively used to numerically characterize ques-\nexploredforanalyzingpredictionsfroman‘artifi-\ntion difficulty and discrimination for human\ncialcrowd’ofMLmodels (Prudêncioetal.,2015;\nsubjects in domains including cognitive psy-\nchology and education (Primi et al., 2014; Plumedetal.,2016;Martínez-Plumedetal.,2019;\nDowning,2003). Morerecently,IRThasbeen Lalor et al., 2019; Vania et al., 2021; Rodriguez\nused to similarly characterize item difficulty etal.,2021).\nand discrimination for natural language mod-\nWhile it can be helpful to know which ques-\nels across various datasets (Lalor et al., 2019;\ntionsaredifficult/discriminatory,itcanbeequally\nVaniaetal.,2021;Rodriguezetal.,2021). In\nimportanttobeabletodetermineaquestion’sdif-\nthis work, we explore predictive models for\ndirectly estimating and explaining these traits ficulty/discrimination parameters without having\nfor natural language questions in a question- touseitinatestingenvironment(asisrequiredto\nanswering context. We use HotpotQA for il- estimateIRTparameters). Somerecentwork,such",
    "char_length": 1429
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 1,
    "text": "lustration. Ourexperimentsshowthatitispos- as Ha et al. (2019), has explored using features\nsibletopredictbothdifficultyanddiscrimina-\nderived from the text of a question to predict the\ntion parameters for new questions, and these\ndifficulty in the context of multiple-choice medi-\ntraitsarecorrelatedwithfeaturesofquestions,\ncal exams. While others (Benedetto et al., 2020)\nanswers,andassociatedcontexts.Ourfindings\nhave used tf-idf features to predict the difficulty\ncan have significant implications for the cre-\nationofnewdatasetsandtestsontheonehand of questions as measured by IRT. We differ from\nand strategies such as active learning and cur- these works in two ways: Firstly, while Ha et al.\nriculumlearningontheother. (2019);Benedettoetal.(2020)bothpredictthedif-\nficultyofitemsforhumans,weareinterestedinpre-\n1 Introduction\ndictingthedifficulty(anddiscrimination)ofitems\nTheuseofquestionansweringfortestinglearning for QA models. Secondly, we choose a question-\noftenreliesoncharacterizingquestionsonaspects answeringdataset,HotpotQA(Yangetal.,2018),\nsuch as difficulty and discrimination1. For exam- asourtestbed. Weutilizethisdatasettogeneratea\nple, ordering questions by difficulty can enable richandvariedfeaturesetacrosseachitem’sques-\ncurriculum learning (Bengio et al., 2009). Simi- tion,answer,andassociatedcontexts. Wecanthen\nlarly,discriminationisusedinstandardizedexams employthesefeaturestoanalyzeourdifficultyand",
    "char_length": 1437
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 2,
    "text": "suchastheSATtoensurethatquestionsarevaried discriminationpredictions,givingusinsightsinto\nenough to discriminate between high-ability and bothourunderlyingQAmodelandfactorsthatcan\nlow-ability respondents. Item Response Theory increasethedifficulty/discriminationofaquestion.\n(IRT) (Wright and Stone, 1979; Lord, 1980) has Ouranalysisshowssignificantvariationsamong\nbeen a widely applied framework to jointly esti- questionsandrevealssomesurprisingpatterns. We\nmatesuchparametersforquestions(oritems)and show that it is possible to predict both difficulty\nanddiscriminationofnaturallanguagequestions,\n1Bydifficulty,werefertohowlikelyarespondentistoan-\nsweraquestioncorrectly,whereasbydiscriminationwerefer whichcanhavemultipleapplicationsineducation\ntothevalueofaquestioninidentifyingagivenlevelofability andpedagogy. Additionally,weseethatdifferent\ninrespondents.Aquestionlike‘2+2=?’haslowdifficulty\nsurface-levelfeaturesareassociatedwithhighdis-\nbutpotentiallyhighdiscrimination,sincearespondentwho\nanswersincorrectlyislikelytohavenoarithmeticability. criminationandhighdifficulty,whichcaninform\n119\nProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics\nVolume2:ShortPapers,pages119-130\nMay22-27,2022(cid:13)c2022AssociationforComputationalLinguistics\nnew evaluation methods and the creation of new of a crowd of human respondents. For this, we\ndatasets. Further,weidentifyattributesforpredict- train 148 instances of DFGN (Qiu et al., 2019)",
    "char_length": 1466
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 3,
    "text": "ing difficulty and discrimination that are general modelsonHotpotQA’strainset.3 Toensurediver-\nenoughtobeadaptedtovariousQAdatasets.2 sity,weuniformlysamplethenumberoftraining\nepochsfrom1to15andsamplethefractionofthe\n2 IRTAnalysisofHotpotQA\ntrainingdatausedformodeltrainingfromU(0,1).\nOtherwise,eachmodelwastrainedwiththehyper-\nIRTbackground: Webeginbysummarizingthe\nparametersdescribedinQiuetal.(2019). Next,we\n1PL and 2PL models from IRT, which form the\ngenerateanitem-responsematrixindicatingwhich\nbasisofourlateranalysis. The1PL(1Parameter\nquestionsfromtheHotpotQAdevseteachmodel\nLogistic)modeldescribestheprobabilityofrespon-\nanswered correctly (i.e., the model’s answer ex-\ndenticorrectlyansweringthej’thitem(question)\nactlymatchedthecorrectanswer). Weremoveany\nintermsofscalar-valuedparametersforquestion\nquestions that received no correct answers or no\ndifficulty (d ) and respondent ability (θ ). These\nj i\nincorrectanswers. Thisisdoneasduringtheesti-\nparameters are estimated from data y ∈ {0,1}\nij\nmationprocess,thesequestionstendtowards(+/-)\nfor a set of i, j pairs. Here, y = 1 indicates a\nij\ninfinityintheirdifficultyparameters,aswell,their\ncorrectanswer. The1PLmodelisdescribedby:\ndiscrimination parameter estimate tends towards\n1 zero(unabletodistinguishbetweenhighandlow\np(y = 1|θ ,d ) =\nij i j\n1+e−(θi−dj) performingmodels). Ourfinaldatasetisasubset\nof 4,000 questions (2,000 train, 1,000 dev, and\nThe2PLmodelextendsthe1PLbyaddingascalar-\n1,000test). Finally,wefitthe1PLand2PLmod-",
    "char_length": 1499
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 4,
    "text": "valuedparameterα ,whichrepresentsthediscrim-\nj elsontheforesaiditem-responsematrixusingthe\ninationofthej’thitem. Intuitively,thisparameter\nvariational IRT training procedure from Natesan\ndenoteshowsharplytheprobabilityofanswering\netal.(2016).\na question correctly changes as the ability of the\nrespondentincreases. The2PLmodelisdescribed 2.2 AnalysisofEstimatedParameters\nby:\n1\np(y = 1|θ ,d ,α ) =\nij i j j\n1+e−αj(θi−dj)\nDatasetdescription: WechoseHotpotQAforour\nanalysissinceitissignificantlymorecomplexthan\nother datasets such as SQuAD (Rajpurkar et al.,\n2016)duetothequestionsrequiringmulti-hoprea-\nsoning and having more complex language. In\nHotpotQA,eachquestionispairedwithtwopara-\ngraphsconsidered‘gold’contextsandseveralother Figure1:2PLdiscriminationvs1PLdifficultyforquestions.\nparagraphs considered ‘distractor’ contexts. The\nanswer to each question is a span in one of the Figure 1 shows a scatter-plot of estimated dif-\ngoldcontexts,butcorrectlyansweringthequestion ficulty and discrimination values for individual\nrequires combining information from both ‘gold’ questions. We note that some discrimination val-\ncontexts. uesasymptoticallyapproach0. Thisoccurswhen\nsomequestionsreceiveveryfewormanycorrect\n2.1 EstimatingIRTParameters\nanswers;thesequestionscannotdiscriminatehigh-\nWeestimatetheIRTparametersforthequestions performingfromlow-performingmodels. Wealso\nin HotpotQA’s dev set (7,405 questions). How- notethatsomequestionshavenegativediscrimina-",
    "char_length": 1469
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 5,
    "text": "ever,collectinghumanresponsesforeachquestion, tion,i.e.,asamodel’sabilityincreases,itsprobabil-\nwhichisnecessarytoestimateIRTparameters,is ityofansweringthequestioncorrectlydecreases.\ninfeasible. Motivated by Lalor et al. (2019), we Thisisprimarilyaresultofsomeofthehighestper-\ncreate an artificial crowd of QA models in place\n3WechooseDFGNduetoitscompetitiveperformanceon\n2Code,models,anddataforallexperimentsareavailable theHotpotQAleaderboard,thenumberofmodelswetrainis\nathttps://github.com/ByrdOfAFeather/pred_irt primarilydrivenbycomputationallimits.\n120\nis2.27. Wefurtherexplorehowthesefactorsaffect\npredictingthedifficultyvaluesinsection4.\n3 PredictingIRTParameters\nWenextdiscusspredictivemodelsfordiscrimina-\ntionanddifficultyusingfeaturesfromthequestion,\nanswer,andassociatedcontext. First,wedescribe\nour feature set, then provide an ablation study, a\nfeatureimportancestudy,andfinallyqualitatively\nanalyzethepredictionsofourbestmodel.\nFigure2:All3000questionsfromourtrain/devsetasUMAP-\nreducedBERTembeddings,color-codedbydifficulty(darker 3.1 FeatureDesign\nismoredifficult).WefindthatclustersproducedbyKMeans\nWe experiment with two categories of fea-\n(K=20)naturallyclustertogetherquestionsthataresimilar\ninhowtheyareaskedortopicsthatareaskedabout.Welabel tures: human-centricandmachine-centricfeatures.\nsomeclustersaccordingtothesetypes. Wespeciallymark\nFor human-centric features, we considered (1)\nC.1,C.2,andC.3. C.1andC.2haveuniformityinthetype",
    "char_length": 1460
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 6,
    "text": "counting-basedLexical&Syntacticfeaturesex-\nofquestionbeingasked,aswellaslowervariancethanother\nclusters. C.3isuniformintopicbutcanvaryinthetypeof tracted for both questions and answers like Con-\nquestion.\ntentWords, Type-token ratio, Avg. Word Length,\nComplex Words (> 3 syllables); (2) Semantic-\nformingmodelsgivingananswerwhichiseithera Ambiguityfeaturesmeasuringaquestion’soran-\nsubspanoforcontainstheground-truthanswerof swer’sambiguity(Haetal.,2019);and(3)Read-\nquestionsthatwereotherwiseansweredcorrectly ability features based on measures like Fleisch\nby lower-performing models. Overall, there is a Kincaidindex. Morefeaturedetailscanbefound\nweakpositivecorrelationbetweendiscrimination inAppendixC.Formachine-centricfeatures,we\nanddifficulty(ρ=0.04). considered(1)ContextualEmbeddingsforques-\nTovisualizeanycorrelationbetweentheseman- tionsandanswersfromBERT(Devlinetal.,2019);\nticandsyntacticinformationofquestionsandtheir (2)n-gramOverlapCountsbetweenthequestion\nrespectivedifficultylevels,weclusteredquestions andanswer,andbetweenquestion/answerandthe\nbased on their BERT embeddings using KMeans gold/distractor paragraphs; and (3) POS Counts\n(K=20)clustering(2DUMAPreductionshownin fromtheStanfordTagset(Toutanovaetal.,2003)\nFigure2). Throughmanuallyexaminingandlabel- forthequestionandanswer.\ningtheclusters,wefoundthatmanyclusterscould\n3.2 QuantitativeAnalysisandAblation\nbedescribedwithaspecificstyle(e.g.,yes/noques-",
    "char_length": 1434
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 7,
    "text": "tions)orgeneraltopic. Someclusters,suchasC.3, Table 1 and Table 2 show the regression perfor-\nhave a large variety in the phrasing of questions manceofourmodelsforpredictingtheIRTdiffi-\nbeingaskedandthepotentialanswersinbothsyn- culty/discriminationparametersofthequestionsin\ntacticandsemanticfeatures. Forexample,bothQ: our dev/test sets using the feature sets described\nKhushiEkRoagisbroadcastbyacompanybased before. Thereportedresultsareaveragedovera10-\noutofwhere? A:DubaiandQ:ToCatchaPreda- foldcross-validation. Wenotethatthebestmodels\ntorwasdevotedtoimpersonatingpeoplebelowthe forbothdifficultyanddiscriminationshowsignif-\nageofconsentforwhichinNorthAmericavaries icant (ρ < 0.10) predictive performance (R2 of\nbywhat? A:jurisdictionareinC.3. 0.17and0.13)againstourbaseline(Mean).\nOtherclusters,suchasC.1andC.2,(yes/noclus- Thebestperformanceisachievedinbothtasks\nters), only vary in topic rather than the type of byconsideringallfeatures. Inbothcases,thereis\nquestion. In particular, for these clusters, the es- asignificantdifference(ρ < 0.1)inperformance\ntimateddifficultyhassignificantlylowervariance betweenusinganysinglesetandusingallfeatures,\nthantheotherclusters(ρ=0.02, ρ=0.04respec- exceptthebest-performingBERTfeatureset. We\ntively),indicatingthattheseyes/noquestionstend also note that features derived from the answer\nto be consistent in their difficulty. The standard are typically better at capturing difficulty, while",
    "char_length": 1442
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 8,
    "text": "deviationvaluesforC.1andC.2are1.08and1.19 features derived from the question better predict\nrespectively,theaveragestandarddeviationvalue the discrimination parameters. However, the per-\n121\nFeatures Dev Dev Test Test Features Dev Dev Test Test\nMSE R2 MSE R2 MSE R2 MSE R2\nAll 5.14 0.11 4.72 0.17 All 9.08 0.13 9.14 0.13\nAll(Q) 5.43 0.07 5.10 0.10 All(Q) 9.32 0.10 9.50 0.09\nAll(A) 5.41 0.08 5.05 0.11 All(A) 9.59 0.08 9.98 0.04\nBERT(Q) 5.41 0.07 4.99 0.12 BERT(Q) 9.02 0.11 9.27 0.11\nBERT(A) 5.25 0.10 5.05 0.11 BERT(A) 9.52 0.08 9.64 0.08\nH.C.(Q) 5.62 0.01 5.38 0.05 H.C(Q) 9.76 0.04 9.86 0.06\nH.C.(A) 5.45 0.06 5.20 0.08 H.C(A) 10.09 0.03 10.31 0.02\nLex.&Syn.(Q) 5.62 0.01 5.37 0.05 Lex.&Syn.(Q) 9.75 0.04 9.86 0.06\nLex.&Syn.(A) 5.47 0.03 5.36 0.06 Lex.&Syn.(A) 10.13 0.01 10.21 0.03\nRead.(Q) 5.80 0.00 5.71 0.00 Read.(Q) 10.08 0.01 10.17 0.03\nRead.(A) 5.63 0.02 5.48 0.03 Read.(A) 10.13 0.02 10.31 0.01\nSem.Ambiguity(Q) 5.76 0.01 5.55 0.02 Sem.Ambiguity(Q) 10.05 0.02 10.16 0.03\nSem.Ambiguity(A) 5.81 0.01 5.68 0.00 Sem.Ambiguity(A) 10.21 0.00 10.47 0.00\nP.O.S.(Q) 5.37 0.05 5.23 0.08 P.O.S.(Q) 9.96 0.04 10.10 0.03\nP.O.S.(A) 5.60 0.01 5.28 0.07 P.O.S.(A) 9.78 0.03 9.82 0.06\nA/Q/COverlap 5.39 0.05 4.92 0.13 A/Q/COverlap 9.56 0.06 9.63 0.08\nMean 5.82 0.00 5.69 0.00 Mean 10.21 0.00 10.53 0.00\nTable1:Resultsforpredictingthe1PLdifficultyparameters. Table2:Resultsforpredictingthe2PLdiscriminationparam-",
    "char_length": 1407
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 9,
    "text": "BERT(Q)andBERT(A)usetheBERTembeddingsforthe eters. The setup is the same as in table 1. BERT (Q) has\nquestion/answerrespectively. H.C.(Q)/(A)arethehuman- thehighestperformance. However,thedifferenceinperfor-\ncentricfeaturesforthequestion/answerrespectively.A/Q/C mancewhenusingBERT(Q)comparedtousingAllisnot\nOverlapisusingonlytheoverlapcountsbetweenquestion, statisticallysignificant.SeeAppendixDforsignificancetests.\nanswer,andcontexts.\nFeature Change Interval Corr.\ninMSE\nformance of All (Q) and All (A) for both the dis- #CommasA. 0.06 ±0.02 0.10\n#ComplexWordsA. 0.05 ±0.01 -0.04\ncriminationanddifficultyisweakerthanusingall\n#NNPA. 0.05 ±0.02 -0.16\nfeatures. Sincethedifferenceisnotstatisticallysig- #SNPA/G.C. 0.02 ±0.01 0.04\nnificant,itisunclearhowmuchpredictivepoweris #CommasQ. 0.01 ±0.01 -0.11\naddedwhenconsideringbothanswerandquestion\nTable3:Featureimportancesfordifficultyparameters(allfea-\nfeaturesinthesepredictions. turesconsidered).A.referstoafeaturecapturinginformation\nThefeaturesthatfocusonhumandifficultyare from the answer, Q. refers to a feature capturing informa-\ntionfromthequestion.A/G.C.referstoafeaturemeasuring\namongthelesseffectivefeaturesets,indicatingthat\noverlapbetweentheanswerandgoldcontexts.\nthehumandifficultyfeaturesofaquestiondonot\nfullycapturedifficultyforQAmodels. Weprovide Feature Change Interval Corr.\ndetailsofmodelsandtheirtrainingandtheexper- inMSE\n#CDA. 0.25 ±0.03 0.17\niment setup in Appendix A; as well, significance\n#CommasQ. 0.08 ±0.02 -0.11",
    "char_length": 1491
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 10,
    "text": "testscanbefoundinAppendixD. Avg.Sense/AdverbA. 0.01 ±0.02 -0.03\nTable4: Featureimportancesfordiscriminationparameters\n3.3 FeatureImportanceStudy\n(allfeaturesconsidered)\nWe estimated feature importance by permuting\neachfeatureindividuallyandmeasuringthechange\ndatawillbecapableofansweringthesequestions.\ninMSEonthedevset. Welistfeaturesthatcaused\nWefindasimilarpositivePearsonscore(ρ = 0.14)\nachangeinMSEofatleast.01intables3and4.\nbetweenthedifficultyandthenumberofcardinal\nWepointoutthatforpredictingthediscrimina-\ndigits in the answer. While this weakness of the\ntion, the number of cardinal digits in the answer\nDFGNmodelcannotbeappliedtoanarbitraryQA\nwasthemostimportantindicatorofhighdiscrimi-\nmodel, the methodology used to determine this\nnation. Thepositivecorrelationbetweenthenum-\nweaknesscanbeappliedarbitrarily,whichcangive\nberofdigitsintheanswerandthediscrimination\nsolidgroundingtoclaimsaboutmodelweaknesses.\nofaquestionisexpected. Qiuetal.(2019)showed\nthat the DFGN model has a significant weakness\n4 QualitativeAnalysis\nin numeric operations. This gives questions with\nnumeric answers a high discrimination value as We qualitatively analyze the difficulty predic-\nDFGNmodelsarenaturallyinhibitedinthisregard, tions to understand the predictions of our best-\nandthusonlyafewmodelswiththemosttraining performing model. Similar to Figure 2, Figure 3\n122\nshows a UMAP scatterplot4 for questions on our\ntestsplitoftheestimatedIRTparameters. Inthis",
    "char_length": 1457
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 11,
    "text": "case, instead of color-coding by difficulty as in\nFigure 2, we instead color-code by the absolute\nerrorbetweenourpredictionsandthemeasureddif-\nficultyofeachquestion. WeagainapplyKMeans\n(k = 10) to our data with a smaller number of\nclustersduetothesmallersizeofthetestset. We\nhighlightCT.1,likeC.1andC.2ofFigure2, this\nclusterconsistsprimarilyofyes/noquestions. The\nFigure3:UMAPscatterplotofquestionscolorcodedbypre-\ndifficulty in CT.1 has significantly smaller vari-\ndictionerrorfordifficulty.(Testset)\nance in the estimated difficulties than the rest of\nthe clusters (ρ = 0.02). As well, the prediction\n5 Conclusion\nerror for CT.1 has significantly smaller variance\n(ρ=0.04)andhadthesmallestaverageprediction\nInthispaper,weexploredQAdatasetsthroughthe\nerror compared to the other clusters (0.68). This\nlens of Item Response Theory. We have demon-\nindicatesthatthemodelisabletorecognizewhen\nstrated a way to build regression models that can\nquestiongroupings,suchasyes/noquestions,have\ndescribethedifficultyanddiscriminationofaques-\nconsistentdifficulties(asdiscussedin2.1)andhas\ntion. We note that our work is limited in two im-\nconsistentlylowererrorwhenpredictingdifficulty\nportantways: firstly,weonlyusetheDFGNmodel\nforthesequestions. However,thepredictionerror\ninourartificialcrowd,whichmayhaveintroduced\ntends to vary more when the surface-level ques-\nabiasinwhichsomefactorsthatmakequestions\ntion types are not sufficient to characterize their\ndifficult/discriminatoryareonlyapplicabletothis",
    "char_length": 1499
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 12,
    "text": "difficulty.\nmodel. Secondly,weonlyexploretheHotPotQA\ndataset, which may further limit our analysis to\nWeexplorethisfurtherthroughasmallcounter-\nonlybeapplicabletoHotPotQAorsimilardatasets.\nfactualexperiment. Weareinterestedintakingan\nFutureworkcouldincorporatemultiplemodelsand\nitemwithhighpredictionerrorandslightlytweak-\ndatasetstoexploreamoreeasilygeneralizabledif-\ning it to understand how the model’s predictions\nficulty/discriminationpredictionpipeline. Wealso\ncan change with changes in the question and an-\nnote that our analysis here focused on QA. How-\nswer. Weselectedanitemwith>2absoluteerror\never,therearemanyNLPtasksinwhichthediffi-\nto performthis experiment. The questionwe use\ncultyordiscriminationofanitemmaybeimportant.\ninthisstudyis: WhichuniversityisthisAmerican\nOurworkherecouldnaturallyextendtothesedo-\nphilosopher, theologian, and Christian apologist\nmains. Finally,automaticallypredictingthesetraits\nwhosupportstheisticscience,professorat? with\nwithoutrelyingonuserresponsescanengendera\nananswerofBiolaUniversity. Thepredicteddif-\nhost of creative educational applications. Future\nficultywas−0.51. Wefoundthatsimplechanges\nworkcanalsoleveragesuchpredictivemodelsto\nto the question, such as using synonyms and re-\nexplore more efficient strategies for learning and\nmovingunnecessaryinformation,canincreasethe\nevaluation.\npredicteddifficultyupto−0.21. However,bymod-\nifyingtheanswer(andbynecessitythequestion)\ntobeeitheradateoryes,weachieveahigherdiffi-\nReferences",
    "char_length": 1487
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 13,
    "text": "cultyprediction(0.53and1.02,respectively). This\nfurtherindicatesthemodel’sbiastowardsyes/no Moez Ali. 2020. PyCaret: An open source, low-code\nmachinelearninglibraryinPython. PyCaretversion\nquestionsbeingofahigherdifficultyregardlessof\n2.2.\nthe style or topic of question being asked. Some\nofourchangesandtheircorrespondingpredictions LucaBenedetto,AndreaCappelli,RobertoTurrin,and\nPaoloCremonesi.2020. R2DE:aNLPapproachto\narelistedinAppendixE.\nestimatingIRTparametersofnewlygeneratedques-\ntions. In Proceedings of the Tenth International\nConference on Learning Analytics & Knowledge,\npages412–421.\n4Similar plots for the discrimination parameters are in-\ncludedinAppendixG Yoshua Bengio, Jérôme Louradour, Ronan Collobert,\n123\nand Jason Weston. 2009. Curriculum learning. PNatesan,RNandakumar,TMinka,andJDRubright.\nIn Proceedings of the 26th Annual International 2016. Bayesian prior choice in irt estimation us-\nConference on Machine Learning, ICML ’09, page ing mcmc and variational bayes. Front. Psychol. 7:\n41–48, New York, NY, USA. Association for Com- 1422.doi: 10.3389/fpsyg.\nputingMachinery.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nKristina Toutanova. 2019. BERT: Pre-training of R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,\ndeep bidirectional transformers for language under- D.Cournapeau,M.Brucher,M.Perrot,andE.Duch-",
    "char_length": 1441
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 14,
    "text": "standing. In Proceedings of the 2019 Conference esnay. 2011. Scikit-learn: Machine learning in\nof the North American Chapter of the Association Python. Journal of Machine Learning Research,\nfor Computational Linguistics: Human Language 12:2825–2830.\nTechnologies, Volume 1 (Long and Short Papers),\npages4171–4186,Minneapolis,Minnesota.Associ- Fernando Plumed, Ricardo Prudêncio, Adolfo\nationforComputationalLinguistics. Martínez-Usó, and Jose Hernandez-Orallo. 2016.\nMakingsenseofItemResponseTheoryinmachine\nStevenMDowning.2003. Itemresponsetheory:appli-\nlearning.\ncations of modern test theory in medical education.\nMedicalEducation,37(8):739–745. Caterina Primi, Kinga Morsanyi, Maria Anna Donati,\nandFrancescaChiesi.2014. ItemResponseTheory\nEileen B. Entin and George R. Klare. 1978. Some\nanalysisoftheCognitiveReflectionTest:Testingthe\ninter-relationships of readability, cloze and multi-\npsychometric properties of the original scale and a\nple choice scores on a reading comprehension test.\nnewlydeveloped8-itemversion,pages2799–2804.\nJournalofReadingBehavior,10(4):417–436.\nR. Prudêncio, J. Hernández-Orallo, and A. Martınez-\nR. Flesch. A new readability yardstick. Journal of\nUsó. 2015. Analysis of instance hardness in ma-\nappliedpsychology,32(3).\nchinelearningusingitemresponsetheory.\nR. Gunning. 1952. The Technique of Clear Writing.\nMcGraw-Hill,NewYork. Lin Qiu, Yunxuan Xiao, Yanru Qu, Hao Zhou, Lei\nLi, Weinan Zhang, and Yong Yu. 2019. Dynami-",
    "char_length": 1457
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 15,
    "text": "Le An Ha, Victoria Yaneva, Peter Baldwin, and Janet cally fused graph network for multi-hop reasoning.\nMee. 2019. Predicting the difficulty of multiple In Proceedings of the 57th Annual Meeting of the\nchoice questions in a high-stakes medical exam. Association for Computational Linguistics, pages\nIn Proceedings of the Fourteenth Workshop on 6140–6150,Florence,Italy.AssociationforCompu-\nInnovative Use of NLP for Building Educational tationalLinguistics.\nApplications, pages 11–20, Florence, Italy. Associ-\nationforComputationalLinguistics. PranavRajpurkar,JianZhang,KonstantinLopyrev,and\nPercy Liang. 2016. Squad: 100,000+ questions for\nJ. Kincaid, R. P. Fishburne, R. L. Rogers, and B. S. machinecomprehensionoftext.\nChissom. 1975. Derivation of new readability for-\nmulas (automated readability index, fog count and Pedro Rodriguez, Joe Barrow, Alexander Miserlis\nflesch reading ease formula) for navy enlisted per- Hoyle, John P. Lalor, Robin Jia, and Jordan Boyd-\nsonnel. Graber. 2021. Evaluation examples are not equally\ninformative: How should that change NLP leader-\nJohn P Lalor, Hao Wu, and Hong Yu. 2019. Learn-\nboards? InProceedingsofthe59thAnnualMeeting\ning latent parameters without human response pat-\nof the Association for Computational Linguistics\nterns: Item response theory with artificial crowds.\nand the 11th International Joint Conference on\nInProceedingsofthe2019ConferenceonEmpirical\nNatural Language Processing (Volume 1: Long\nMethodsinNaturalLanguageProcessing.",
    "char_length": 1491
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 16,
    "text": "Papers), pages 4486–4503, Online. Association for\nComputationalLinguistics.\nG. Harry Mc Laughlin. 1969. SMOG grading-a new\nreadabilityformula. JournalofReading,12(8):639–\nF.A.SmithandR.J.Senter.1967. Automatedreadabil-\n646.\nityindex. TechnicalReportAMRL-TR-6620.\nFrederic M. Lord. 1980. Applications of Item\nKristina Toutanova, Dan Klein, Christopher D. Man-\nResponse Theory to Practical Testing Problems.\nning, and Yoram Singer. 2003. Feature-rich part-\nRoutledge.\nof-speech tagging with a cyclic dependency net-\nFernando Martínez-Plumed, Ricardo B.C. Prudêncio, work. In Proceedings of the 2003 Conference\nAdolfo Martínez-Usó, and José Hernández-Orallo. of the North American Chapter of the Association\n2019. Item response theory in ai: Analysing forComputationalLinguisticsonHumanLanguage\nmachine learning classifiers at the instance level. Technology-Volume1,NAACL’03,page173–180,\nArtificialIntelligence,271:18–42. USA.AssociationforComputationalLinguistics.\nGeorgeA.Miller.1995. WordNet: Alexicaldatabase Clara Vania, Phu Mon Htut, William Huang, Dhara\nforEnglish. Commun.ACM,38(11):39–41. Mungra, Richard Yuanzhe Pang, Jason Phang,\n124\nHaokunLiu,KyunghyunCho,andSamuelR.Bow-\nman.2021. Comparingtestsetswithitemresponse\ntheory. InProceedingsofthe59thAnnualMeeting\nof the Association for Computational Linguistics\nand the 11th International Joint Conference on\nNatural Language Processing (Volume 1: Long\nPapers), pages 1141–1158, Online. Association for\nComputationalLinguistics.",
    "char_length": 1485
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 17,
    "text": "Benjamin D. Wright and Mark H. Stone. 1979. Best\ntestdesign. MesaPress.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-\ngio, William W. Cohen, Ruslan Salakhutdinov, and\nChristopher D. Manning. 2018. HotpotQA: A\ndataset for diverse, explainable multi-hop question\nanswering. InConferenceonEmpiricalMethodsin\nNaturalLanguageProcessing(EMNLP).\n125\nA Models&Training • FleschReadingEase-linearcombinationof\nwords/sentenceandsyllables/word(Flesch)\nFor the 1PL and 2PL prediction, we considered\nlinearmodelswithL1&L2regularization,random • Flesch Kincaid Grade Level - linear combi-\nforests,gradientboostedregressors,andbayesian nation of word/sentence and syllables/word\nridgemodels. Allhyperparameterswerekeptcon- (Kincaidetal.,1975)\nstant as the default in the sklearn package (Pe-\n• Automated Readability Index (ARI) - lin-\ndregosaetal.,2011). Weperformed10-foldcross-\near combination of characters/word and\nvalidationusingPyCaret(Ali,2020). Allmodels\nwords/sentence(SmithandSenter,1967)\nweretrainedonaconsumergradeprocessor.\n• Gunning Fog index - linear combination of\nB FeatureDefinitions\nwords/sentence and complex words/words.\n• Human-CentricFeatures Complex words are words with 3 syllabus\n– Lexical & Syntactic features: These (Gunning,1952)\nconsist primarily of counting features:\n• Coleman-Liau - linear combination of\nContentWords, Type-token ratio, Avg.\nletters/100 words and sentences/100\nWordLength,ComplexWords(> 3syl-\nwords.(EntinandKlare,1978)\nlables). Thesearecalculatedforboththe",
    "char_length": 1497
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 18,
    "text": "answerandquestion. Afulllistofthese\n• SMOG index - calculates the grade level\nfeaturescanbefoundinAppendixF\nby considering the number of complex\n– Semantic-Ambiguityfeatures: Weuse\nwords/sentence(Laughlin,1969)\nWordNet(Miller,1995)tocalculatethe\nambiguity of sentences, similar to Ha D SignificanceTests\net al. (2019). These are calculated for\nWeprovidesignificancetestsforthedifficultyand\nbothanswerandquestion.\ndiscriminationpredictionsintables5and6. Wesee\n– Readabilityfeatures: Weuseprevious\nthat the BERT features and using all features are\nwork (Kincaid et al., 1975; Gunning,\nabletobeatthebaselinewithstatisticalsignificance\n1952;Laughlin,1969)tomodeltheread-\n(ρ≤.1). NotethatwecompareusingMSErather\nabilityofaquestion/answer(e.g. Fleisch\nthanR2 asthebaselinealwayshasanR2 scoreof\nKincaid index). These are further ex-\n0. Wealsoprovideintable7thesignificancetests\npandedoninAppendixC.\nfor using all features against BERT features. We\n• Machine-CentricFeatures\nfindthatthebestperformingBERTfeaturesetdoes\n– Contextual Embeddings: We use the\nnothaveastatisticallysignificantimprovementin\nBERT-base model (Devlin et al., 2019)\nperformancewhencomparedtotheallfeatureset.\ntoobtainsentenceembeddingsforques-\nInthiscase,weuseR2 astheperformancemetric.\ntionsandanswers.\n– Overlap Counts: We count overlaps Features p\nbetween the question and answer of n- All 0.034\nBERT(Q) 0.211\ngrams up to n = 3. We also com-\nBERT(A) 0.078\npute overlap counts between the ques- H.C.(Q) 0.551",
    "char_length": 1476
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 19,
    "text": "tion/answer and the gold and distractor H.C.(A) 0.261\nA/QCon. 0.674\nparagraphs.\nP.O.S.(Q) 0.501\n– PartofSpeechCounts: WecountPOS P.O.S.(A) 0.523\ntags for tags from the Stanford NLP\nTable5: 1PLdifficultypredictions. P-valuesforfeatureset\ntagset (Toutanova et al., 2003) for both\nperformance(MSE)testedagainstthebaseline.\nthequestionandanswer.\nC ReadingDifficultyFeatures E CounterfactualResults\nWelistthereadingdifficultyfeaturesweusedinour • – Question(original): Whichuniversityis\nexperimentsandanoverviewoftheircalculations. this American philosopher, theologian,\nEachcalculationhasitsowncoefficientsthatcan and Christian apologist, who supports\nbefoundintheirrespectivecitations. theisticscience,professorat?’\n126\nFeatures p • ContentWordCountNoStopwords\nAll 0.007\nBERT(Q) 0.013\n• NounCount\nBERT(A) 0.098\nH.C.(Q) 0.165\n• NounIncidence\nH.C.(A) 0.726\nA/QCon. 0.831\nP.O.S.(Q) 0.656 • VerbCount\nP.O.S.(A) 0.174\n• VerbIncidence\nTable6:2PLdiscriminationpredictions.P-valuesforfeature\nsetperformance(MSE)testedagainstthebaseline. • AdjectiveCount\nFeatures p • AdjectiveIncidence\nBERT(Q)(Diff.) 0.042\nBERT(Q)(Discrim.) 0.769\n• AdverbCount\nBERT(A)(Diff.) 0.278\nBERT(A)(Discrim.) 0.089\n• AdverbIncidence\nTable7: 1PLand2PLDifficultyandDiscriminationpredic-\ntions.P-valuesforBERTperformance(R2)testedagainstall • NumberCount\nfeaturesperformance.\n• NumberIncidence\n– Answer: \"BiolaUniversity\" • TypeCount\n– Pred. Diff: −0.51\n• TypeTokenRatio\n• – Question: Whichschoolisthisphiloso-\n• CommaCount",
    "char_length": 1485
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 20,
    "text": "pher and theologian who supports sci-\nence,professorat? • CommaIncidence\n– Answer: \"BiolaUniversity\"\n• AverageWordLengthInSyllables\n– Pred. Diff: −0.21\n• ComplexWordCount\n• – Question: Whatwasthebirthdateofa\nprofessoratBiolaUniversitywhoisan • ComplexWordIncidence,\nAmerican philosopher, theologian, and\n• AverageSentenceLength\nChristianapologist,whosupportstheis-\nticscience?\n• NegationCount\n– Answer: March9,1948\n• NegationIncidence\n– Pred. Diff: 0.53\n• NegationInStem\n• – Question : Does Biola University have\naprofessorwhoisanAmericanphiloso- • NPCount\npher,theologian,andChristianapologist,\n• NPIncidence\nwhosupportstheisticscience?\n– Answer: yes\n• AverageNPLength\n– Pred. Diff: 1.02\n• NPCountWithEmbedding\nF LexicalFeatures\n• NPIncidenceWithEmbedding\nWelistourfulllistoflexicalfeatures,thesefeatures\n• AverageAllNPLength,\nareasubsetofthelexicalfeaturesusedinHaetal.\n(2019).\n• PPCount\n• WordCount • PPIncidence\n• ContentWordCount • PPsPerSentenceRatio\n• ContentWordIncidence • VPCount\n127\n• VPIncidence • NotInFirst4000Incidence\n• PassiveActiveRatio • NotInFirst5000Count\n• ProportionActiveVPs • NotInFirst5000Incidence\n• ProportionPassiveVPs • Imagability\n• AgentlessPassiveCount • ImagabilityFoundOnly\n• RelativeClausesCount • ImagabilityRatio\n• RelativeClausesIncidence • Familiarity\n• ProportionRelativeClauses\n• FamiliarityFoundOnly\n• PolysemicWordCount\n• FamiliarityRatio\n• PolysemicWordIncidence\n• Concreteness\n• AverageSenseNoContentWords\n• ConcretenessFoundOnly\n• AverageSenseNoNouns",
    "char_length": 1498
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 21,
    "text": "• ConcretenessRatio\n• AverageSenseNoVerbs\n• AgeOfAcquisition\n• AverageSenseNoNonAuxiliaryVerbs\n• AgeOfAcquisitionFoundOnly\n• AverageSenseNoAdjectives\n• AgeOfAcquisitionRatio\n• AverageSenseNoAdverbs\n• MeaningfulnessColoradoFoundOnly\n• AverageNounDistanceToWNRoot\n• MeaningfulnessPavioFoundOnly\n• AverageVerbDistanceToWNRoot,\n• NoImagabilityRating\n• Average Noun And Verb Distance To WN-\n• NoFamiliarityRating\nRoot\n• NoConcretenessRating\n• AnswerWordsInWordNetRatio\n• NoAgeofAcquisitionRating\n• AverageWordFrequencyAbs\n• ConnectivesCount\n• AverageWordFrequencyRel\n• ConnectivesIncidence\n• AverageWordFrequencyRank\n• AdditiveConnectivesCount\n• AverageContentFrequencyAbs\n• AverageContentFrequencyRel • AdditiveConnectivesIncidence\n• AverageContentFrequencyRank • TemporalConnectivesCount\n• NotInFirst2000Count • TemporalConnectivesIncidence\n• NotInFirst2000Incidence • CausalConnectivesCount\n• NotInFirst3000Count • CausalConnectivesIncidence\n• NotInFirst3000Incidence • ReferentialPronounCount,\n• NotInFirst4000Count • ReferentialPronounIncidence\n128\nG DiscriminationUMAPplots\nIn the following section, we provide the UMAP\nreductionplotsforthediscriminationparameters\n(darkerbeingmorediscriminatory),aswellasthe\nprediction error UMAP plot for our best model\n(darkermeaninghighererror).\nFigure6:QuestionBERTUMAPReductionVSDiscrimina-\ntionvalues,train/devset\nFigure4:AnswerBERTUMAPReductionVSDiscrimination\nvalues,train/devset\nFigure7:QuestionBERTUMAPReductionVSDiscrimina-\ntionvalues,testset",
    "char_length": 1489
  },
  {
    "paper_id": "Predicting_diff_disc_nlqs",
    "chunk_id": 22,
    "text": "Figure5:AnswerBERTUMAPReductionVSDiscrimination\nvalues,testset\nFigure8: QuestionBERTUMAPReductionVSPredicted\nDiscriminationvalues,testset\n129\nFigure9:QuestionBERTUMAPReductionVSDiscrimina-\ntionpredictionerror,testset\n130",
    "char_length": 221
  }
]